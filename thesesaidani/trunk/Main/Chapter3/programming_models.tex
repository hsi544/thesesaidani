Au vu des contraintes de programmation pour l'obtention de performances sur le processeur Cell et que nous avons mis en avant dans le chapitre précédent, plusieurs outils de programmation dédiés au processeur Cell ont vu le jour pour faciliter le passage d'un code série à un code totalement parallélisé sur cette architecture.
Dans ce chapitre, nous faisons une analyse de ces outils de programmation pour le processeur Cell. L'étude comporte des outils industriels tels que \emph{\textbf{RapidMind}} et\emph{\textbf{OpenMP}} ainsi que des outils développés par des laboratoires de recherche académiques : \emph{\textbf{Sequoia}} et \emph{\textbf{CellSS}}. Les approches citées dans ce qui suit sont celles qui nous ont paru pertinentes et assez mures pour pouvoir être utilisées dans notre domaine d'application. Certains outils reprennent d'autres outils existants pour les architectures parallèles à mémoire partagée ou distribuée qui ont été adaptés pour l'architecture et la hiérarchie mémoire du Cell.
%%====================================================== THREADS POSIX ======================================================================================================================================
%\section{Les Threads POSIX}
%Les \emph{threads} POSIX\footnote{Portable Operating System Interface for Unix} ou \emph {Pthreads} sont une standardisation\cite{pthreads_std} du modèle de programmation par \emph{threads} pour les systèmes UNIX. Ce modèle est basé sur une API de programmation parallèle qui permet la gestion des \emph{threads} ainsi que la synchronisation par \emph{mutex} ou variables conditionnelles. Historiquement, les concepteur de \emph{hardware} ont développé leurs implémentations propriétaires des \emph{threads}, ceci a rendu la portabilité du code des programmeurs quasi impossible. La nécessité d'une API standard est donc devenue vitale, c'est pour cette raison que la majorité des vendeurs de \emph{hardware} possèdent actuellement leur implémentation standard des \emph{threads} POSIX. Les \emph{Pthreads} sont définis autour d'un ensemble de procédures et de types en langage C contenus dans le fichier d'entête \texttt{"pthread.h"}.\\
%D'une manière générale un \emph{thread} est un flux d'instructions pouvant s'exécuter de manière indépendante sur un OS donné. Du point de vue du programmeur ceci s'apparente à une procédure qui peut s'exécuter indépendamment du programme principal, un programme contenant des procédures de ce type est dit \emph{multi-threaded}. Afin de détailler le principe de fonctionnement des \emph{threads} il est nécessaire de faire un rappel sur les \emph{process} UNIX. Un \emph{process} est créé par l'OS est contient un certain \emph{overhead} qui consiste en certaines ressources nécessaires à son exécution. Les \emph{threads} résident à l'intérieur de ces ressources et sont capables d'être ordonnancés et exécutés en tant qu'entités indépendantes car ils ne dupliquent qu'une partie des ressources qui leurs permettent d'être des morceaux de code exécutables. Le flot de contrôle est rendu indépendant car le \emph{thread} possède ses propres : pointeur de pile, registres, propriétés d'ordonnancement (priorité et politique), ensemble de signaux et données spécifiques. En somme, un \emph{thread} existe dans un \emph{process} dont il utilise les ressources. Il possède son propre flot de contrôle et ne duplique que les ressources nécessaires à son exécution indépendante. Il peut partager les ressources du \emph{process} avec d'autres \emph{threads} et s'exécuter en coordination avec ces derniers. La complexité due à sa création et à sa gestion est légère comparativement à celle du \emph{process} et sa durée de vie est celle de son \emph{process} parent.
%\subsection{l'API Pthread}
%L'API des \emph{threads} POSIX peut être décomposée en trois types de routines:
%\begin{itemize}
%\item \textbf{Les routines de gestion des \emph{threads}} : comprends les tâches de création, propriétés d'exécution et terminaison des \emph{threads}.
%\item \textbf{Les \emph{mutex}} (abréviation de \emph{mutual exclusion}): ils permettent de synchroniser les \emph{threads}, les routines gèrent la création, destruction, réservation et libération des \emph{mutex}.
%\item \textbf{Les variables conditionnelles} : ces dernières gèrent la communication entre des \emph{threads} qui partagent les \emph{mutex}. Elles sont basées sur des conditions fixées par le programmeur, elles incluent des fonctions de création, destruction, attente et signalisation basées sur certaines valeurs de ces variables. 
%\end{itemize}
%\rule{\textwidth}{0.2mm}\\
%\subsubsection{Gestion des Threads}
%\begin{itemize}
%\item \textbf{Création et Terminaison des \emph{threads}}: Initialement le programme contient un seul \emph{thread} qui est le \texttt{main()}. Les autres \emph{threads} doivent être créés explicitement par le programmeur. \texttt{pthread\_create} créé un nouveau \emph{thread} et le rend exécutable, un exemple de code à base de \emph{Pthreads} est donné dans le listing \ref{pthreadcode}. Cette routine peut être appelée autant de fois que l'on veut et à n'importe quel endroit dans le code. Le nombre de \emph{threads} maximal créé par un \emph{process} dépend de l'implémentation. Une fois créés les \emph{threads} peuvent créer à leur tour d'autres \emph{threads} et il n'existe aucune dépendance ni hiérarchie entre les \emph{threads}. Le \emph{thread} est crée avec certains attributs par défaut, ceux-ci pouvant être changés ultérieurement. Il existe plusieurs manières de terminer un \emph{thread} : soit par le \emph{thread} lui même qui le fait par un \texttt{return} de sa routine principale ou par la fonction \texttt{pthread\_exit()}, ou alors par un autre \emph{thread} en utilisant \texttt{pthread\_cancel()} et enfin en cas de terminaison du \emph{process} parent.
%\item \textbf{Passage d'Arguments au \emph{threads}} : On peut passer un argument au \emph{thread} via la routine \texttt{pthread\_create()}. On peut également passer plusieurs arguments en les rassemblant dans une structure et en passant l'adresse de celle-ci.
%\item \textbf{Jonction et Détachement des \emph{threads}} : La jonction est une manière de faire une synchronisation entre les \emph{threads}, la fonction \texttt{pthread\_join()} bloque le \emph{thread} appelant jusqu'a ce que le \emph{thread} appelé termine son exécution. Le caractère joignable ou pas d'un \emph{thread} est spécifié à sa création : s'il est créé en tant que \emph{thread} détaché il ne pourra pas être joignable. La routine \texttt{pthread\_detach()} sert à détacher un \emph{thread} qui était joignable à sa création.
%\item \textbf{Gestion de la Pile} : Le standard ne définit pas la taille par défaut de la pile du \emph{thread}, celle-ci dépend de l'implémentation. Toutefois, le programmeur peut en spécifier la taille ainsi que l'emplacement de la mémoire dans laquelle elle doit être stockée.
%\end{itemize}
%
%\subsubsection{Les Variables \emph{mutex}}
%Les \emph{mutex} sont un des principaux mécanismes de synchronisation de \emph{threads}. Ils permettent par exemple de synchroniser des \emph{threads} ou alors de protéger des données partagées en cas d'écriture simultanée. Un \emph{mutex} peut être réservé (\emph{lock}) par un seul \emph{thread} à un moment donné, le propriétaire du \emph{mutex} est le seul à le posséder : tout autre \emph{thread} qui essaye de réserver ce même \emph{mutex} échoue jusqu'à ce que le propriétaire le libère (\emph{unlock}). Il existe des routines de création et de destruction des \emph{mutex}, la réservation des \emph{mutex} se fait soit par appel à la routine \texttt{pthread\_\emph{mutex}\_lock()} (bloquant), \texttt{pthread\_\emph{mutex}\_trylock()} (non bloquant) et se libère par \texttt{pthread\_\emph{mutex}\_unlock()}. Parmi les exemples d'utilisation des \emph{mutex} on peut citer les cas de \emph{race condition} où plusieurs \emph{threads} essayent de mettre à jour une variable globale, il est nécessaire dans ce genre de situation de protéger cette variable par un \emph{mutex} afin que celle-ci ait la même valeur du point de vue de tous les \emph{threads}. On dit alors que l'on crée une \emph{section critique}.
%%===============================Listing Pthreads =======================================
%\lstset{ %
%language=C,                % choose the language of the code
%basicstyle=\footnotesize,       % the size of the fonts that are used for the code
%backgroundcolor=\color{light-gray},  % choose the background color. You must add \usepackage{color}
%showspaces=false,               % show spaces adding particular underscores
%showstringspaces=false,         % underline spaces within strings
%showtabs=false,                 % show tabs within strings adding particular underscores
%frame=single,			% adds a frame around the code
%tabsize=2,			% sets default tabsize to 2 spaces
%captionpos=b,			% sets the caption-position to bottom
%breaklines=true,		% sets automatic line breaking
%breakatwhitespace=false,	% sets if automatic breaks should only happen at whitespace
%escapeinside={\%*}{*)}  ,        % if you want to add a comment within your code
%caption = Exemple de code \emph{Pthread} basique montrant les routines de création de \emph{threads},
%label = pthreadcode
%}
%\lstinputlisting{Chapter2/Code/pthreadexample.c}
%%===================================================================================
%\subsubsection{Les Variables de Condition}
%Les variables de condition fournissent aux \emph{threads} une autre manière de se synchroniser. Contrairement aux \emph{mutex} qui sont basés sur le contrôle de l'accès à une variable, la synchronisation par variable de condition se fait selon une valeur spécifique. Les variables de condition sont utilisées en conjonction avec les \emph{mutex}. L'appel à la fonction \texttt{pthread\_cond\_wait()} bloque le \emph{thread} appelant jusqu'à ce que la condition spécifiée est signalée. Cette routine doit être appelée tant que le \emph{mutex} est réservé et libère automatiquement le \emph{mutex} quand elle est en attente. Une fois que le signal est reçu, le \emph{thread} est réveillé et le \emph{mutex} est réservé automatiquement pour être utilisé par le \emph{thread}. La responsabilité de libérer le \emph{mutex} est à la charge du programmeur qui le fait une fois que son utilisation n'est plus nécessaire. La fonction \texttt{pthread\_cond\_signal()} est utilisée pour signaler (ou réveiller) un autre \emph{thread} qui est en attente de la variable de condition. Elle doit être appelée après que le \emph{mutex} est réservé et doit libérer le \emph{mutex} dans l'ordre pour permettre à \texttt{pthread\_cond\_wait()} de s'achever. Il existe une routine nommée \texttt{pthread\_cond\_broadcast()} qui met en attente plusieurs \emph{threads} en même temps. 
%
%
%\subsection{Les Threads POSIX sur le Cell}
%Sur un système Linux pour le Cell, le \emph{thread} principal s'exécute sur le PPE, celui-ci pouvant produire un ou plusieurs tâches sur le processeur. Une tâche peut contenir un ou plusieurs \emph{threads} Linux qui peuvent s'exécuter soit sur le PPE soit sur le SPE. Un \emph{thread} qui s'exécute sur le SPE possède son propre contexte incluant un banc de registre de 128 x 128-bit, un compteur de programme et une file d'attente de commandes MFC, et il peut communiquer avec d'autres unités d'exécution au travers de l'interface des canaux MFC. Un \emph{thread} PPE peut interagir directement avec un \emph{thread} SPE via sa mémoire locale ou son espace de \emph{problem state} ou indirectement via la mémoire centrale ou les routines la \emph{SPE support d'exécution Management Library}. L'OS définit le mécanisme et la politique d'ordonnancement pour les SPE disponibles, il est également responsable de la gestion des priorités entre les tâches, du chargement du programme de la notification des évenemments au SPEs ainsi que du support du \emph{debugger}.
%Une API de gestion des \emph{threads} SPE similaire à la bibliothèque POSIX a été conçue, dans le but de fournir à la fois un environnement de programmation familier et une flexibilité dans la gestion des SPEs. Cette API supporte à la fois la création et la terminaison des tâches SPE ainsi que l'exclusion mutuelle par des primitives de mise à jour atomiques. L'API peut accéder au SPE en utilisant un modèle virtuel dans lequel l'OS affecte dynamiquement les \emph{threads} aux SPEs dans l'ordre de leur disponibilité. Les applications, peuvent spécifier de manière optionnelle un masque d'affinités pour affecter les \emph{threads} a un SPE spécifique. Les dispositifs architecturaux de communication entre les \emph{threads} et de synchronisation (\emph{mailbox}, signaux, etc...) peuvent être accédés via un ensemble d'appels système ou alors via l'application qui mappe un bloc de contrôle du SPE dans l'espace mémoire de l'application. Sur le Cell il existe trois blocs de contrôle du SPE, un accédé par l'application, un autre par l'OS et un troisième par un superviseur. Une interface accessible à l'utilisateur permet  la communication directe entre les processeurs SPEs ou PPE, ceci permet d'éviter des appels système couteux.\\
%Lorsque l'application fait une requête de création de \emph{threads}, la bibliothèque de \emph{threads} SPE envoie la requête à l'OS pour allouer un SPE et créer un \emph{thread} SPE à partir d'un fichier objet de format ELF (Executable and Linkable Format) intégrée dans un exécutable Cell. Le \emph{miniloader} un programme SPE de 256-bit, télécharge la segment de code à exécuter sur le SPE, l'avantage de cette approche et d'une part d'éviter au PPE d'effectuer cette tâche et d'autre part de profiter du fait que les les transferts PPE-SPE quand il se font du côté SPE, sont nettement plus efficace grâce à une interface qui contient plus de canaux de communications.
%\begin{figure}[!htbf]
%	\centering
%	\includegraphics[scale =0.6]{Chapter2/figures/cell_compilation_process}
%	\caption{Processus \emph{dual source} de génération de code exécutable pour le Cell}
%  \label{fig_compprocess}
%\end{figure}
%\subsection{Processus de Génération de Code}
%Dans le modèle de programmation décrit ci-dessus le processus de génération de code binaire exécutable sur le Cell est dit \emph{dual-source}. En effet, il existe deux code sources distincts, un code pour le SPE (spe.c sur la figure \ref{fig_compprocess})) qui contient le code exécuté sur le SPE. Un deuxième code source qui est celui s'exécutant sur le PPE contient le \emph{\emph{thread}} maitre qui gère les \emph{\emph{threads}} SPE. Le processus de génération de code exécutable est décrit dans la figure \ref{fig_compprocess}. Dans la première étape le code SPE est compilé ce qui donne un binaire exécutable SPE. Celui-ci est par la suite traité par un outils spécifique \emph{spu-embedd} qui permet de transformer ce binaire en bout de code qui peut être enfouis dans l'exécutable du PPE. Cette procédure se fait par l'outil d'édition de lien qui considère alors le code SPE comme une bibliothèque dont le code objet doit être intégré dans l'exécutable final.
%\subsection{conclusion}
%La programmation par \emph{threads} sur le Cell est le modèle de base pour la mise en ouvre de code parallèle sur cette architecture. Il est caractérisé par une API très bas niveau qui permet en même temps de garder un contrôle précis sur le déroulement de son application et d'avoir une grande flexibilité en terme de choix de déploiement d'un algorithme donné. Grâce au dispositifs architecturaux de signalisation et de synchronisation, l'interface est rendue très efficace en terme de performance sur le Cell. Toutefois, du point de vue du programmeur, la mise en oeuvre du code est surement plus laborieuse que pour d'autres modèles de programmation, mais celle-ci peut être justifiée dans le cadre de fortes contraintes sur les temps d'exécution ou dans le cas ou le modèle de calcul SPMD n'est pas adapté à l'application déployée. 

%====================================================== RAPIDMIND ======================================================================================================================================

\section{\emph{\textbf{RapidMind}}}
\emph{\textbf{RapidMind}}\cite{rapidmind} est un modèle de programmation parallèle multi-plateformes, GPU, multi-coeur symétrique et pour le processeur Cell. Il relève du modèle de programmation \emph{stream processing}\cite{Kapasi_2003} et s'apparente à un langage de programmation enfoui dans \emph{C++}. Il est basé sur la bibliothèque template \emph{C++} et une bibliothèque de support d'exécution qui effectue la génération dynamique de code. La bibliothèque template permet l'invocation de code SPE à l'intérieur du code PPE, avec l'ensemble du code SPE écrit en template.\\
La bibliothèque template de \emph{\textbf{RapidMind}} fournit un ensemble de types de données, des macros de contrôle, des opérations de réduction et des  fonctions communes qui permettent à la bibliothèque de support d'exécution de capturer une représentation du code SPE. Les types de données ont été spécialement conçus pour exprimer de manière simple les opérations SIMD et les exposer facilement à la bibliothèque du support d'exécution. Le support d'exécution à son tour, extrait le parallélisme à partir de ces opérations en vectorisant le code et en divisant les calculs sur les tableaux et les vecteurs sur les différents SPEs. Il peut également effectuer des optimisations de boucle comme la détection des invariants de boucle. le support d'exécution \emph{\textbf{RapidMind}} assigne des tâches aux SPEs de manière dynamique et peut effectuer des optimisations à plus haut niveau comme la superposition des calculs et des transferts qui permet de masquer la latence de ces derniers. Enfin, le modèle de calcul est un modèle SPMD. Il diffère du modèle SIMD du fait que les programmes peuvent contenir du flot de contrôle et par le fait que celui-ci puisse gérer une certaine forme de parallélisme de tâches bien que étant initialement un modèle \emph{data-parallel}. Un exemple de code \emph{\textbf{RapidMind}} est donné dans le listing \ref{rapidmindcode}.\\
\subsection{Modèle de programmation et interface}
L'interface est basée sur trois types \emph{C++} principaux: \textbf{\texttt{Value<N,T>}}, \textbf{\texttt{Array<D,T>}} et \textbf{\texttt{Program}}, tous sont des conteneurs, les deux premiers pour les données et le dernier pour les opérations. Le calcul parallèle est effectué soit en appliquant des \textbf{\texttt{Program}} sur des \textbf{\texttt{Array}} pour créer de nouveaux \textbf{\texttt{Array}}, ou en appliquant une opération collective parallèle qui peut être paramétrée par un objet \textbf{\texttt{Program}} comme la réduction par exemple.\\
A première vue, les types \textbf{\texttt{Value}} et \textbf{\texttt{Array}} ne sont pas une grande nouveauté. En effet, tout développeur \emph{C++} a pour habitude d'utiliser les types N-tuples pour exprimer le calcul numérique sur des vecteurs, et le type \textbf{\texttt{Array}} est une manière usuelle d'encapsuler la vérification des valeurs limites (\emph{boundary checking}). Toutefois ces types constituent une interface pour une machine parallèle puissante basée sur la génération dynamique de code. Ceci est rendu possible grâce au type \textbf{\texttt{Program}} qui est la principale innovation du modèle de programmation \emph{\textbf{RapidMind}}. Un mode d'exécution symbolique est utilisé pour collecter dynamiquement des opérations arbitraires sur les \textbf{\texttt{Value}} et les \textbf{\texttt{Array}} dans les objets \textbf{\texttt{Program}}.
\subsubsection{Le type \textbf{\texttt{Value}}}
Le type \textbf{\texttt{Value<N,T>}} est un N-tuple. Les instances de ce type contiennent N valeurs de type T, ou T peut être un type numérique de base (un flottant simple ou double précision ou tout autre type entier), les flottants 16-bits sont également supportés. Des notations courtes existent pour certaines tailles usuelle comme le \textbf{\texttt{Value4f}} pour un quartet de flottants simple précision ou \textbf{\texttt{Value3ub}} pour un triplet d'entiers 8-bits non signés.\\
Les opérations arithmétiques standard et les opérations logiques sont surchargées pour les types tuples et opèrent composante par composante. Les fonctions de la bibliothèque standard  sont également supportées, comme les fonctions trigonométriques et logarithmiques. En plus des opérations arithmétiques, des opérations de réorganisation des données on été ajoutées au type  \textbf{\texttt{Value}} : ces opérations permettent la duplication d'une composante ou la permutation des composantes. Les calculs sont exprimés en utilisant les tuples de \textbf{\texttt{Value}} et les opérateurs sur ces types peuvent être utilisés directement pour exprimer du parallélisme SWAR (SIMD Within A Register).

 \subsubsection{Le type \textbf{\texttt{Array}}}
Le type \textbf{\texttt{Array<D,T>}} est également un conteneur de données. Ce qui le distingue du type \textbf{\texttt{Value}} est le fait qu'il peut avoir plusieurs dimensions et que sa taille est variable. L'entier D représente la dimensionnalité (1,2 ou 3), le type T est le type des éléments du conteneur. Le type des éléments et pour le moment restreint aux instances du type \textbf{\texttt{Value<N,T>}}.\\
Les instances du type \textbf{\texttt{Array}} supportent les opérateurs "[]" et "()" pour l'accès aléatoire aux données. L'opérateur "[]" utilise des entiers en arguments tandis que l'opérateur "()" utilise des coordonnées réelles comprises dans [0, 1] dans chaque dimension, cette particularité est utile par exemple pour les modes d'interpolation des images.\\
Les sous-tableaux peuvent être accèdés en utilisant les fonctions \textbf{slice}, \textbf{offset} et \textbf{stride}. Les effets de bords sont gérés en utilisant la fonction membre \textbf{\texttt{boundary}}, qui inclut différents modes de traitement pour les bords. Les types \textbf{\texttt{Value}} et \textbf{\texttt{Array}} suivent une sémantique par valeur qui permet d'éviter l'aliasing de pointeurs et simplifie la programmation et l'optimisation. Il existe également d'autres types de sous-tableaux, les références sur tableaux et les accesseurs.
\subsubsection{Le type \textbf{\texttt{Program}}}
Un objet \textbf{\texttt{Program}} contient une séquence d'opérations, ces opérations sont spécifiées par le passage en mode \emph{retained} qui est indiqué par la macro mot-clé \textbf{\texttt{BEGIN}}. Normalement, le système fonctionne en mode \emph{immediate}. Dans ce mode les opérations sur un tuple de valeurs s'exécutent à la spécification comme pour une bibliothèque matrice-vecteur classique:  les calculs sont effectués sur la même machine que le programme hôte et le résultat est sauvegardé dans le tuple \textbf{\texttt{Value}} de sortie. En mode \emph{retained} un nouvel objet \textbf{\texttt{Program}} qui est retourné par la macro \textbf{\texttt{BEGIN}} est créé. Les opérations dans ce mode ne sont pas exécutées; elles sont symboliquement évaluées et sauvegardées dans l'objet \textbf{\texttt{Program}}. La sortie du mode \emph{retained} est marquée par la macro \textbf{\texttt{END}}, qui ferme l'objet \textbf{\texttt{Program}} et le marque comme étant prêt à être compilé, étape à la suite de laquelle l'objet \textbf{\texttt{Program}} est utilisé pour le calcul. Les objets \textbf{\texttt{Program}} sont compilés de manière dynamique ce qui permet d'exploiter les caractéristiques bas-niveau de la machine cible.\\
Il est à noter que même si les types \emph{\textbf{RapidMind}} sont des classes \emph{C++}, le compilateur est plutôt assimilable à un compilateur FORTRAN et peut ainsi effectuer le même type d'optimisations sur les calculs vectoriels. Les fonctionnalités du langage \emph{C++} sont utilisées pour structurer les calculs et générer le code mais pas lors de l'exécution.
\subsection{Evaluation partielle et algèbre du programme}
Les objets \textbf{\texttt{Program}} sont des conteneurs d'opérations, et ces opérations peuvent être manipulées par le système de manière explicite. Cela permet l'implémentation de plusieurs dispositifs avancés de programmation.\\\\
\newpage
%===============================Listing Rapidmind =======================================
\lstset{ %
language=C,                % choose the language of the code
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
backgroundcolor=\color{light-gray},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=single,			% adds a frame around the code
tabsize=2,			% sets default tabsize to 2 spaces
captionpos=b,			% sets the caption-position to bottom
breaklines=true,		% sets automatic line breaking
breakatwhitespace=false,	% sets if automatic breaks should only happen at whitespace
escapeinside={\%*}{*)}  ,        % if you want to add a comment within your code
caption = Exemple de parallélisation de code avec \emph{\textbf{RapidMind}},
label = rapidmindcode
}
\lstinputlisting{Chapter2/Code/rapidmindexample.c}
En premier lieu, les \textbf{\texttt{Program}} peuvent être évalués partiellement. Si un objet \textbf{\texttt{Program}} \textbf{p} possède \textbf{n} entrées, l'expression \textbf{p(A)} retourne un objet \textbf{\texttt{Program}} avec \textbf{(n-1)} entrées. En d'autres termes les entrées de l'objet \textbf{\texttt{Program}} ne sont pas obligatoirement fournies en une fois. Il est possible de lier toutes les entrées d'un objet \textbf{\texttt{Program}} mais de différer son exécution effective. L'exécution d'un objet \textbf{\texttt{Program}} n'est déclenchée que quand il est affecté à un \emph{bundle}, \textbf{\texttt{Array}} ou \textbf{\texttt{Value}}. L'opérateur \textbf{"()"} est utilisé pour lier les entrées de l'objet \textbf{\texttt{Program}}. Ceci est appelé le \emph{tight binding}. Un changement de l'entrée après un \emph{tight binding}, n'affecte pas les entrées d'un \textbf{\texttt{Program}}, même si son exécution est différée. Dans l'exemple précédent, on crée \textbf{"p(A)"} et on l'affecte à un objet \textbf{\texttt{Program}} \textbf{"q"}, puis on modifie ensuite l'entrée \textbf{"A"}. Lors de l'exécution de \textbf{"q"}, celui-ci utilisera la valeur de \textbf{"A"} au moment du binding dans \textbf{"p"}, pas la valeur modifiée. Le \emph{tight binding} permet l'optimisation de l'objet \textbf{\texttt{Program}} basée sur les valeurs effectives dans l'entrée liée.\\
Toutefois, le système supporte également le \emph{loose binding}, spécifié par l'opérateur \textbf{"<<"}. L'expression \textbf{"p<<A"} est similaire à \textbf{"p(A)"} sauf que les changements sur \textbf{"A"} sont visibles à l'exécution différée de \textbf{"p<<A"}.\\
%===================================================================================
Une entrée d'un \textbf{\texttt{Program}} peut être liée à un \textbf{\texttt{Array}} ou un tuple de \textbf{\texttt{Value}}. Si des tableaux de tailles différentes sont liés à un \textbf{\texttt{Program}} la plus petite entrée est répliquée suivant les conditions aux bords pour avoir la taille de l'entrée de l'entrée la plus grande.\\
Les \textbf{\texttt{Program}} peuvent être combinés pour créer de nouveaux \textbf{\texttt{Program}} en utilisant deux opérations: la composition fonctionnelle et le \emph{bundling}. Ces opérations forment une algèbre fermée dans l'ensemble des objets \textbf{\texttt{Program}}. L'opérateur de composition fonctionnelle \textbf("<<") quand il est appliqué à deux objets \textbf{\texttt{Program}} \textbf{"p"} et \textbf{"q"} \textbf{"p << q"} transmet toutes les entrées du \textbf{\texttt{Program}} à droite de l'opérateur à l'entrée de celui de gauche, il crée un nouvel objet \textbf{\texttt{Program}} ayant les entrées de \textbf{"q"} et les sorties de \textbf{"p"}. L'opérateur \emph{bundle} quand à lui utilise la fonction \textbf{"bundle"}. Cette fonction concatène toutes les entrées/sorties de ses arguments dans l'ordre et crée un nouvel objet \textbf{\texttt{Program}} équivalent à la concaténation des sources de ces \textbf{\texttt{Program}} d'entrée en séquence.\\
Ces opérations combinées avec la compilation dynamique permettent une amélioration considérable des performances surtout quand le programme est dominé par des instructions d'accès mémoire.

\subsection{Les opérations collectives}
L'opération de base supportée est l'application parallèle d'un programme sur un tableau de données. Toutefois, d'autres schémas de communication et de calcul sont supportés sous la forme d'opérations collectives. Les patrons de communication irréguliers sont fournis par les opérations de \emph{scatter} et \emph{gather},et l'opération de réduction fournit un patron de calcul hiérarchique.\\
L'opération \emph{gather} permet de récupérer des données résidant dans des emplacements non-contigus de la mémoire et l'opération \emph{scatter} l'écriture dans des zones de même nature. L'opération de réduction quant à elle est programmable : elle prend deux entrées et fournit une sortie. Elle permet par exemple de sommer les éléments d'un vecteur d'une manière hiérarchique (Fig. \ref{reduction}).\\

\begin{figure}[!htbf]
	\centering
	\includegraphics[width=0.8\columnwidth]{Chapter2/figures/reduction}
	\caption{Illustration d'une opération collective de réduction, ici une opération de sommation est effectuée, le résultat final est l'accumulation des éléments du tableau}
  \label{reduction}
\end{figure}

On pourra noter que l'opérateur impliqué dans la réduction doit être associatif. Parmi les opérateurs qui ont été implémentés on peut citer \textbf{sum}, \textbf{product}, \textbf{min} et \textbf{max}.

\subsection{Spécificité du backend pour le Cell de \emph{\textbf{RapidMind}}}
L'implémentation de \emph{\textbf{RapidMind}} pour le Cell possède certaines particularités qui tiennent compte de l'architecture particulière de ce processeur. En effet, les unités de calcul des SPEs étant purement vectorielles, la génération de code est rendue difficile à cause notamment des instructions de permutation additionnelles nécessaires à l'accomplissement du calcul.
%Le parallélisme SWAR peut être mappé directement sur les registres SIMD du SPE mais les opérations de permutation de données ne sont pas implémentées de manière aussi efficace les unes que les autres.
De plus la parallélisation qui consiste à appliquer un \textbf{\texttt{Program}} à un tableau permet en théorie de faire des millions de calculs en parallèle. Mais le Cell ne possède qu'un nombre limité d'unités de traitement. C'est pour cela que les données sont subdivisée en plusieurs paquets et transférées dans les mémoires locales des SPEs avant d'être traitées. Le triple \emph{buffering} est utilisé pour cacher la latence des transferts DMA. Pour les accès mémoire non réguliers un cache logiciel est utilisé. Si les programmes incluent un flux de contrôle, des tâches différentes peuvent prendre des temps d'exécution différents et un système de \emph{load balancing} (équilibrage de charge) est mis en place. 

\subsection{Conclusion sur \textbf{\emph{\textbf{RapidMind}}}}
La plate-forme de développement \textbf{\emph{\textbf{RapidMind}}} combine une interface basée sur la compilation dynamique et un modèle de calcul \emph{data-parallel}. Elle peut être considérée soit comme une API de calcul parallèle ou un langage de programmation parallèle enfoui dans \emph{C++}. Elle supporte plusieurs niveaux de parallélisme notamment le parallélisme SWAR et le parallélisme SPMD. Le modèle de programmation est commun à plusieurs plate-formes GPU, multi-coeur et Cell. C'est un modèle de programmation assez simple à utiliser et qui repose en grande partie sur un compilateur C++ ce qui lui confère une grande popularité auprès des utilisateurs. Au niveau des performances on peut relever de bons résultats dans \cite{rapidmind}.\\
La société \emph{\textbf{RapidMind}} a été rachetée par Intel en 2009 et l'outil de parallélisation se nomme désormais \emph{Array Building Blocks}\cite{ARBB_Newburn_2011} qui fait partie de la suite Intel Parallel Studio.

%====================================================== OPENMP ======================================================================================================================================
\section{\emph{\textbf{OpenMP}} pour le Cell}
\emph{\textbf{OpenMP}} pour le Cell\cite{cell_omp} intégré dans le compilateur XL d'IBM\cite{Eichenberger_Pact_2005} est basé sur les transformations du compilateur et une bibliothèque de support d'exécution. Le compilateur transforme des \texttt{pragmas} \emph{\textbf{OpenMP}} en code source intermédiaire qui implémente les constructions \emph{\textbf{OpenMP}} correspondantes. Ce code inclut des appels aux fonctions de la bibliothèque de support d'exécution du Cell. Cette dernière fournit des fonctionnalités basiques à \emph{\textbf{OpenMP}} :  la gestion des \emph{threads}, la répartition de la charge de travail ainsi que la synchronisation. Un exemple de parallélisation d'une boucle for est donné dans le listing \ref{ompexample}, page \pageref{ompexample}.\\
Chaque segment de code compris dans une construction parallèle est listé par le compilateur dans une fonction séparée. Le compilateur insère les appels à la bibliothèque de support d'exécution \emph{\textbf{OpenMP}} dans la fonction parente de la fonction listée. Ces appels aux fonctions de la bibliothèque de support d'exécution vont ainsi invoquer les fonctions listées et gérer leur exécution.\\
Le \emph{framework} est basé sur le compilateur IBM XL. Ce dernier possède des \emph{front-end} pour \emph{C/C++} et \emph{FORTRAN}, et contient la même infrastructure d'optimisation pour ces langages. Le \emph{framework} d'optimisation se divise en deux composants TPO et TOBEY. TPO est chargé des optimisations haut niveau indépendantes de la machine cible tandis que TOBEY effectue les optimisations bas-niveau spécifiques à l'architecture.\\
Le compilateur résulte d'une adaptation de versions existantes du compilateur XL supportant \emph{\textbf{OpenMP}}, mais la spécificité de l'architecture du Cell a posé quelques problèmes qui sont les suivants:
\begin{itemize}
\item \textbf{\emph{threads} et synchronisation}: les \emph{threads} s'exécutant sur le PPE diffèrent de ceux du SPE en termes de capacité de traitement. Le système a été conçu pour prendre en compte la différence entre les deux architectures.
\item \textbf{Génération de code}: Le jeu d'instruction du PPE diffère de celui du SPE. Il en résulte que l'optimisation du code PPE est faite séparément de celle du SPE. L'espace de stockage sur le SPE étant limité, le code SPE, s'il excède cette capacité, peut être partitionné en sections binaires (\emph{overlays}) au lieu d'une section monolithique. De plus, les données partagées dans le code SPE nécessitent un transfert DMA de la mémoire centrale vers la mémoire locale. Ceci est fait soit par le compilateur qui insère explicitement des commandes DMA dans le code, soit par un mécanisme de cache logiciel qui fait partie de la bibliothèque de support d'exécution du SPE.\\
\item \textbf{Modèle mémoire}: le hardware du Cell assure que les transactions DMA sont cohérentes vis à vis du cache L2 du PPE, mais ne fournit pas de mécanisme de cohérence pour les données résidant dans la mémoire locale, le modèle mémoire implémenté assure la cohérence des données qui est requise par les spécifications.
\end{itemize}
%\newpage
%===============================Listing OMP =======================================
\lstset{ %
language=C,                % choose the language of the code
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
backgroundcolor=\color{light-gray},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=single,			% adds a frame around the code
tabsize=2,			% sets default tabsize to 2 spaces
captionpos=b,			% sets the caption-position to bottom
breaklines=true,		% sets automatic line breaking
breakatwhitespace=false,	% sets if automatic breaks should only happen at whitespace
escapeinside={\%*}{*)}  ,        % if you want to add a comment within your code
caption = Exemple de code \emph{\emph{\textbf{OpenMP}}} où une  boucle for est parallélisée,
label = ompexample
}
\lstinputlisting{Chapter2/Code/ompexample.c}
%===================================================================================
Les sections qui suivent décrivent la manière dont ces problèmes ont été traités.
\subsection{\emph{threads} et synchronisation}
Les \emph{threads} peuvent s'exécuter sur le PPE ou les SPEs. Le \emph{thread} maitre est toujours exécuté sur le PPE. Celui-ci est responsable de la création des autres \emph{threads}, de la répartition et de l'ordonnancement des tâches, et des opérations de synchronisation. L'absence d'OS sur le SPE explique le fait que le PPE gère toutes les requêtes OS. Cette répartition permet au SPE de se consacrer uniquement aux tâches de calcul.\\
Actuellement, un seul \emph{thread} est sensé s'exécuter sur le PPE, et le nombre de \emph{threads} parallèles exécutés sur les SPEs se déclare par la variable d'environnement \texttt{OMP\_NUM\_THREADS}. La création et synchronisation des \emph{threads} est implémentée à l'aide des bibliothèques du SDK (Software Development Kit). Le \emph{thread} sur le PPE crée des \emph{threads} SPE à l'exécution seulement, quand les structures parallèles sont rencontrées pour la première fois.\\
Pour les niveaux de parallélisme imbriqué (boucles imbriquées), chaque \emph{thread} dans la région parallèle la plus externe exécute séquentiellement la région parallèle interne. les itérations de boucles sont divisées en autant de morceaux qu'il y a de \emph{threads}, avec un mécanisme d'ordonnancement et de synchronisation simplifié. Lorsque le \emph{thread} SPE est créé, il effectue des initialisations et entre dans une phase d'attente d'affectation de tâches de la part du PPE, exécute ces tâches et se met en attente d'autres tâches, jusqu'à ce qu'il reçoive un signal de fin de tâche. Une tâche SPE peut être l'exécution d'une région parallèle (boucle ou section), ou alors l'exécution d'un flush de cache ou encore la participation à une opération de synchronisation par barrière.\\
Il existe une file d'attente dans la mémoire système correspondant à chaque \emph{thread}. Quand le \emph{thread} maitre assigne une tâche à un \emph{thread} SPE, il écrit les informations sur cette tâche sur la file d'attente qui lui est consacrée, incluant le type de tâche, les bornes supérieure et inférieure de la boucle parallèle, ainsi que le pointeur de fonction pour la région de code listée qui doit être exécutée. Une fois que le \emph{thread} SPE prend une tâche de la file d'attente, il signale au \emph{thread} maitre que l'espace dans la file d'attente est à nouveau libre. Les mécanismes de synchronisation sont assurés au travers de \emph{mailbox} qui permettent l'échange de messages bloquants ou non-bloquants entre le \emph{thread} maitre et les \emph{threads} de calcul. Les \emph{locks} \emph{\textbf{OpenMP}} sont implémentés grâce aux commandes DMA atomiques.

\subsection{Génération de code}
En premier lieu, le compilateur sépare chaque région dans le code source qui correspond à une construction \emph{\textbf{OpenMP}} parallèle, et l'isole dans une fonction séparée. La fonction peut prendre des paramètres supplémentaires comme les bornes supérieure et inférieure de la boucle. Le compilateur insère un appel à la bibliothèque de support d'exécution \emph{\textbf{OpenMP}} au niveau de la fonction parente de la fonction listée, et insère un pointeur dans cette fonction de la bibliothèque de support d'exécution. Le compilateur insère également des instructions de synchronisation lorsque celle-ci est nécessaire.\\
Le fait que l'architecture du Cell soit hétérogène impose que les fonctions isolées contenant des tâches parallèles soit clonées afin d'être exécutables aussi bien par le SPE que le PPE. Le clonage est effectué quand le graphe d'appel global est disponible de telle sorte que le sous-graphe d'un appel à une fonction isolée puisse être  entièrement cloné. Le clonage permet aussi lors des étapes ultérieures d'effectuer des optimisations qui dépendent de l'architecture comme la vectorisation de code qui ne peut pas se faire dans une étape commune à cause des différences entre les jeux d'instructions SPU et VMX. Une table de mise en correspondance entre les versions PPE et SPE contient les pointeurs des fonctions isolées de telle sorte à ce qu'il n'y ait pas de confusion lors de l'exécution.\\
A la fin de l'étape d'optimisation haut-niveau (TPO), les procédures sur les différentes architectures sont séparées en deux unités de compilation différentes et celles-ci sont traitées une par une, par le \emph{back-end} TOBEY\cite{Blainey_TOBEY_1994}.\\
L'unité PPE ne requière pas de traitement particulier. Par contre l'unité compilée SPE peut produire un binaire d'une taille importante et qui ne tient pas dans la mémoire locale. Il existe deux approches pour remédier à ce problème. La première consiste au partitionnement de la section parallèle dans un programme en plusieurs sections de taille moindre et la génération d'un binaire distinct pour chaque sous-section. Cette approche est limitée, d'une part par ce qu'une sous-section peut ne pas avoir une taille assez petite pour tenir dans la mémoire locale et d'autre part la complexité générée par la création et la synchronisation de plusieurs \emph{threads} affecte considérablement les performances.\\
La deuxième approche qui est celle utilisée dans le compilateur IBM XL, est le partitionnement du graphe d'appel et les \emph{overlays} de code. Le code SPE est ainsi partitionné et un code \emph{overlays} est crée pour chaque partition. Ces \emph{overlays} partagent l'espace d'adresses mais n'occupent pas la mémoire locale en même temps. Un poids est affecté à chacun des arcs du graphe représentant la fréquence d'appels de la fonction. Le graphe d'appel est partitionné afin de maximiser cette fréquence d'appel dans une partition en utilisant l'algorithme de l'arbre couvrant maximum \cite{Pemmaraju_2003} (\emph{maximum spanning tree}). Le code SPE ainsi  généré est intégré dans le code PPE avant d'être exécuté.\\

\subsection{Modèle mémoire}
\emph{\textbf{OpenMP}} spécifie un modèle à mémoire partagée à cohérence faible (\emph{relaxed-consistency} \emph{shared memory}). Ce modèle permet à chaque \emph{thread} d'avoir sa propre vue temporaire de la mémoire. Une valeur écrite dans une variable, ou une valeur lue à partir d'une mémoire peut rester dans la vue temporaire du \emph{thread} jusqu'à ce qu'elle soit obligée de partager la mémoire par une opération de flush \emph{\textbf{OpenMP}}.\\
Ce modèle est adapté au Cell car il prend en compte la mémoire limitée des SPEs. Les données privées accédées dans le code SPE sont allouées en mémoire privée. Les variables partagées, sont elles allouées en mémoire centrale et peuvent être accédées via DMA par les SPEs. Deux mécanismes distincts sont utilisés pour les transferts DMA: la bufferisation statique et le cache logiciel contrôlé par le compilateur. Dans les deux cas, les données globales peuvent avoir une copie dans la mémoire locale SPE.\\
Certaines références sont considérées comme étant régulières du point de vue du compilateur. Ces références interviennent dans les boucles, les adresses mémoires vers lesquelles elle pointent peuvent être exprimées en utilisant des expressions affines de variables d'induction de la boucle, et la boucle qui les contient ne possède aucune dépendance induite par la boucle (vraie, de sortie ou anti-dépendance) impliquant ces références. Pour ces références régulières aux données partagées, un buffer temporaire est utilisé dans le SPE. Des opération DMA \emph{get} et \emph{put} sont utilisées respectivement pour lire et écrire de et vers ce buffer à partir de la mémoire centrale.  Plusieurs buffers peuvent être utilisés afin de recouvrir les calculs par des transferts mémoire.\\
Pour les références irrégulières à la mémoire le cache logiciel est utilisé. Le compilateur remplace les \textbf{\texttt{load}} et \textbf{\texttt{store}} à partir de et vers ces zones mémoire par des instructions qui vont chercher les adresses effectives, dans le répertoire du cache. Si une ligne de cache pour l'adresse effective est trouvée (\emph{cache hit}) la valeur dans le cache est utilisée. Dans le cas contraire (\emph{cache miss}) la donnée est récupérée en mémoire via un DMA \emph{get} dans le cas d'une lecture.\\
La taille de la ligne de cache (128 octets) et son associativité (4) sont choisies respectivement pour optimiser les transferts DMA et exploiter le jeu d'instructions SIMD pour le calcul des adresses (4x 32-bits). Le système assure également au SPE l'accès à des données qui seraient dans la pile d'une fonction PPE qui appelle une fonction SPE.
\subsection{Conclusion sur \emph{\textbf{OpenMP}} pour le Cell}
Le modèle de programmation \emph{\textbf{OpenMP}} intégré dans le compilateur IBM XL pour le processeur Cell est une approche qui a le mérite de permettre à l'utilisateur de réutiliser son code \emph{\textbf{OpenMP}} existant, sans se soucier des détails de l'architecture du Cell. Le support d'\emph{\textbf{OpenMP}} est assuré par des transformations du compilateur couplées à une bibliothèque de support d'exécution. Les problématiques qui sont posées pour le portage d'\emph{\textbf{OpenMP}} sur le Cell sont notamment celles de la synchronisation des \emph{threads}, de la génération de code et du modèle mémoire. La solution proposée est innovante car elle propose un compilateur qui permet de générer un seul binaire exécutable destiné à des jeux d'instructions différents et sur un espace mémoire distribué. Les performances sur des benchmarks simples ainsi que sur des codes plus complexes donnés dans \cite{cell_omp} démontrent l'efficacité de l'outil en comparaison avec un code optimisé à la main. Pour ce qui est du domaine d'application que nous étudions, à savoir le traitement d'images, \emph{\textbf{OpenMP}} peut être une solution adaptée pour des calculs simples du type point à point où les corps de boucles sont réguliers et où la vectorisation automatique est triviale. Par contre, lorsqu'il s'agit de calculs du type convolution où il existe des accès non réguliers aux données et des dépendances entre les pas de boucle, les tâches de génération et d'optimisation du code deviennent complexes pour un compilateur. De plus, les optimisations de plus haut niveau telles que celles qui concernent les transferts de données et les optimisations au niveau algorithmique ne sont pas prises en charge par l'implémentation d'\emph{\textbf{OpenMP}} pour le Cell. C'est pour ces raisons là que cet outil reste efficace dans des cas de parallélisation de boucles simples et intenses en calcul mais la variété des algorithmes et des calculs en traitement d'images nous oblige à nous orienter vers un modèle moins automatique et plus orienté par le programmeur.
 
%====================================================== CELLSS =============================================================================================================

\section{ Le langage de programmation \emph{\textbf{CellSS}}}
\begin{figure}[htb]
	\centering
	\includegraphics[width=\columnwidth]{Chapter2/figures/cellss}
	\caption{Procédure de génération de code de \emph{\textbf{CellSS}}}
  \label{cellss_chain}
\end{figure}
\emph{\textbf{CellSS}} (\emph{Cell SuperScalar})\cite{cellss_sc06} est un environnement qui a pour objectif de fournir à l'utilisateur un outil de programmation simple mais qui donne des exécutables qui exploitent efficacement l'architecture du processeur Cell. Il découle d'un modèle de programmation nommé GRID\cite{bsc_grid} qui assimile un processeur super-scalaire à une grille de calcul: les unités fonctionnelles du processeur sont les ressources de la grille, les données contenues dans les registres correspondent aux fichiers dans la grille et les instructions assembleur sont assimilées aux tâches de calcul.\\
Cell SuperScalar est constitué de deux composants clés : un compilateur source vers source et une bibliothèque de support d'exécution. Le processus de génération de code est illustré dans la figure \ref{cellss_chain}. Partant d'un code source séquentiel écrit en langage C, des annotations en \emph{\textbf{CellSS}} sont insérées dans le code. Le compilateur \textit{source-to-source} est utilisé pour générer deux fichiers C distincts. Le premier correspond au programme principal de l'application. Il est compilé par un compilateur PPE qui crée un objet pour ce même processeur. Le deuxième code source correspond à celui exécuté par le SPE sous contrôle du PPE. Cet exécutable est enfoui dans le binaire du PPE pour pouvoir être exécuté. Cette procédure est la même que celle utilisée par le SDK d'IBM qui est basé sur deux compilateurs distincts et une phase d'intégration du code SPE dans celui du PPE.\\
Une section parallèles est annotée par des clauses \emph{\textbf{CellSS}}, ce qui crée des tâches concurrentes (voir listing \ref{cellsscode01}). L'exécution du programme est assurée par le PPE qui assigne les tâches aux SPEs au travers de la bibliothèque de support d'exécution. Le support d'exécution se charge de créer un noeud qui correspond à une tâche dans le graphe, et vérifie la dépendance avec une autre tâche lancée auparavant et ajoute un arc entre les deux. Si la tâche courante est prête à être exécutée le support d'exécution envoie une requête au SPE pour qu'il se charge de l'exécution. Les transferts DMA sont gérés par le support d'exécution de manière transparente. Les appels au support d'exécution ne sont pas bloquants et de ce fait, si une tâche n'est pas prête ou tous les SPEs sont occupés, le programme principal continue son exécution.\\
On pourra noter que tout le processus (assignations de tâches, analyses des dépendances, transferts de données) sont transparents du point de vue de l'utilisateur, qui écrit un code séquentiel dans lequel il annote la partie à exécuter par les SPEs. Le système peut changer dynamiquement le nombre des SPEs utilisés en prenant en compte le maximum de concurrence contenu dans l'application à chaque phase.
\newpage
%===============================Listing \emph{\textbf{CellSS}} =======================================
\lstset{ %
language=C,                % choose the language of the code
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
backgroundcolor=\color{light-gray},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=single,			% adds a frame around the code
tabsize=2,			% sets default tabsize to 2 spaces
captionpos=b,			% sets the caption-position to bottom
breaklines=true,		% sets automatic line breaking
breakatwhitespace=false,	% sets if automatic breaks should only happen at whitespace
escapeinside={\%*}{*)}  ,        % if you want to add a comment within your code
caption = Exemple sparse LU avec \emph{\textbf{CellSS}} : définition des tâches,
label = cellsscode01
}
\lstinputlisting{Chapter2/Code/cellssexample01.c}



\newpage
%===============================Listing \emph{\textbf{CellSS}} =======================================
\lstset{ %
language=C,                % choose the language of the code
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
backgroundcolor=\color{light-gray},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=single,			% adds a frame around the code
tabsize=2,			% sets default tabsize to 2 spaces
captionpos=b,			% sets the caption-position to bottom
breaklines=true,		% sets automatic line breaking
breakatwhitespace=false,	% sets if automatic breaks should only happen at whitespace
escapeinside={\%*}{*)}  ,        % if you want to add a comment within your code
caption = Exemple sparse LU avec \emph{\textbf{CellSS}} : programme principal,
label = cellsscode02
}
\lstinputlisting{Chapter2/Code/cellssexample02.c}
\subsection{\emph{Runtime}}
A l'exécution, les appels à une fonction \texttt{\textbf{Execute}} seront responsables du comportement de l'application sur le processeur Cell. Pour chaque appel à la fonction \emph{Execute} le support d'exécution effectue les actions suivantes:
\begin{itemize}
\item L'addition d'un noeud dans un graphe des tâches qui représente la tâche appelée.
\item L'analyse des dépendances de données de la nouvelle tâche avec les tâches appelées précédemment. Cette analyse prend comme hypothèse que deux paramètres sont les mêmes s'ils ont la même adresse. Le système cherche les types de dépendances de données \emph{RaW}, \emph{WaR} et \emph{WaW} \footnote{Read after Write, Write after Read et Write after Write}.
\item Le renommage de paramètres similaire au renommage de registres, une technique issue des processeurs superscalaires. Le renommage se fait sur les paramètres \emph{output} et \emph{input/output} pour chaque appel de fonction qui possède un paramètre qui va être écrit, au lieu d'écrire dans l'adresse originale de celui-ci, un emplacement mémoire nouveau sera utilisé, celui-ci sera un renommage de l'emplacement du paramètre original. Ceci permet l'exécution de la fonction indépendamment d'un appel précédent à une fonction qui écrit ou lit ce paramètre. Cette technique permet de ce fait de supprimer efficacement toutes les dépendances \emph{WaR} et \emph{WaW} en utilisant de l'espace mémoire supplémentaire et simplifie ainsi le graphe des dépendances et augmente les chances d'extraire du parallélisme.
\item Enfin, la tâche peut être exécutée.
\end{itemize}

\subsubsection{Ordonnancement dynamique}
Durant l'exécution de l'application, le support d'exécution maintient une liste des tâches prêtes. Une tâche est étiquetée comme étant prête, à partir du moment où il n'existe aucune dépendance entre cette tâche et d'autres tâches ou alors que ces dépendances ont été résolues (les tâches précédentes dans le graphe ont fini leur exécution). Le graphe de dépendances de tâches ainsi que la liste des tâches prêtes sont mis-à-jour à chaque fois qu'une tâche finit son exécution. Lorsqu'une tâche est terminée le support d'exécution reçoit une notification et le graphe de tâches est vérifié pour établir les dépendances qui ont été satisfaites et les tâches dont toutes les dépendances ont été résolues et qui sont ajoutées dans la liste des tâches prêtes.\\
\'Etant donné une liste de tâches prêtes et une liste de ressources disponibles, le support d'exécution choisit la meilleure correspondance entre les tâches et les ressources et soumet les tâches pour l'exécution. La soumission de la tâche comprend toutes les actions nécessaires pour pouvoir exécuter la tâche: le transfert des paramètres et la requête d'exécution de la tâche.
\subsubsection{Intergiciel pour le Cell}
Une application \emph{\textbf{CellSS}} est composée de deux types de binaires exécutables : le programme principal, qui s'exécute sur le PPE et le programme tâche qui lui s'exécute sur le SPE. Ces binaires sont obtenus par compilation de deux sources générés par le compilateur \emph{\textbf{CellSS}} et les bibliothèques de support d'exécution. Lors du démarrage du programme sur le PPE le programme de type \emph{task} est lancé sur tous les SPEs durant l'exécution, celui-ci se met en attente de requêtes de la part du programme principal. Lorsque la politique d'ordonnancement choisit une \emph{task} de la liste des tâches prêtes à être lancées et un SPE sur lequel elle va être exécutée. Une structure de données nommée \emph{task control buffer} est construite. Celle-ci contient des informations telles que l'identifiant de la tâche, l'adresse de chacun des paramètres ainsi que des informations de contrôle. L'identifiant sert à distinguer les tâches déjà présentes dans la mémoire des SPEs de celles qui ne le sont pas et qui doivent être chargées avant exécution. Les requêtes émanant du programme principal pour exécuter une tâche dans les SPEs se font via \emph{mailbox}, celle-ci contient l'adresse et la taille du \emph{task control buffer} correspondant à la tâche. L'exécution de la tâche se fait de la manière suivante: le SPE se met en attente d'une requête sur la \emph{mailbox}, une fois la requête reçue il rapatrie les données et éventuellement le code de la tâche une fois la tâche finie, selon le contenu du \emph{task control buffer} il garde les données dans sa mémoire ou les transfert en mémoire centrale. La synchronisation se fait à la fin de l'exécution et lorsque toutes les données résultantes sont transférées vers la mémoire centrale.

\subsubsection{Exploitation de la localité}
Lorsque le graphe de dépendance de tâches construit par \emph{\textbf{CellSS}} contient un arc allant d'un noeud vers un autre, il existe une dépendance de données entre les tâches qui impose un transfert de données, le but étant de minimiser la quantité de données transférées entre le PPE et les SPEs et entre SPEs. La politique de placement est faite de sorte à exploiter la localité et donc à regrouper quand c'est possible les tâche interdépendantes dans le même SPE.
\subsection{Conclusion sur \emph{\textbf{CellSS}}}
\emph{\textbf{CellSS}} est un modèle de programmation basé sur un compilateur et un support d'exécution. Il permet l'exécution d'un code source séquentiel sur une architecture parallèle grâce à l'annotation de ce code par des directives de placement sur les SPEs. Le support d'exécution construit un graphe de dépendances des fonctions appelées et ordonnances ces fonctions sur le SPE en gérant les transferts mémoire de manière transparente. L'algorithme d'ordonnancement exploite la localité afin de minimiser les transferts mémoire.\\
Le modèle de programmation \emph{\textbf{CellSS}} parait plus adapté qu'\emph{\textbf{OpenMP}} pour notre domaine d'application. D'une part, parce qu'il est basé sur une notion de graphe de tâches pouvant être placées suivant un schéma choisi par le programmeur et d'autre part, les tâches peuvent contenir du code vectoriel optimisé ce qui n'est pas le cas pour les sections \emph{\textbf{OpenMP}} par exemple. Il est donc clair, que ce modèle est plus adapté pour notre domaine d'application. Toutefois, les essais que nous avons mené avec l'outil et qui ont donnée lieu à plusieurs échanges avec les développeurs du BSC (Barcelona Supercomputing Center), ont montré que l'outils était encore dans un état de maturité insuffisant car il ne prenait pas en charge toutes les fonctionnalités énumérées dans \cite{cellss_sc06} et qu'il ne pouvait donc pas être utilisé en production.

%====================================================== SEQUOIA ===========================================================================================================

\section{Le langage de programmation \emph{\textbf{Sequoia}}}
\emph{\textbf{Sequoia}}\cite{sequoia_sc06} est un langage de programmation bas-niveau dédié aux machines modernes, qu'elles soient des processeurs parallèles ou alors superscalaires, et dans lesquels l'allocation de la mémoire et le transfert des données au travers de la hiérarchie mémoire est primordial pour la performance. \emph{\textbf{Sequoia}} est une extension au langage C, même si les constructions qu'il permet de faire sont très différentes du modèle de programmation du C. Il est basé sur un modèle de programmation qui assiste l'utilisateur dans la structuration des programmes parallèles, pour qu'ils soient efficaces au niveau de la bande passante et qu'ils restent portables sur de nouvelles machines. Le modèle de programmation repose sur les principes suivants:
\begin{itemize}
\item La notion de mémoire hiérarchique est directement introduite dans le modèle de programmation ce qui permet un gain de portabilité et de performance. \emph{\textbf{Sequoia}} s'exécute sur des machines qui sont représentées sous forme d'un modèle abstrait en arbre de modules mémoire distincts qui décrit comment les données sont transférées et où elles résident dans la hiérarchie mémoire.
\item Les \emph{task} sont utilisées comme une abstraction des unités de calcul auto-suffisantes qui incluent la description des communications et de la charge de travail. La \emph{task} isole chaque calcul dans son propre espace mémoire local et contient le parallélisme.
\item Afin de garantir la portabilité, une stricte séparation est maintenue entre l'expression générique de l'algorithme et les optimisations spécifiques à une machine donnée. Pour minimiser l'impact de cette séparation sur la performance, les détails du déploiement sur une machine spécifique sont sous le contrôle de l'utilisateur.
\end{itemize}
Ainsi, \emph{\textbf{Sequoia}} adopte une approche pragmatique pour fournir un outil de programmation parallèle portable en fournissant un ensemble limité d'abstractions qui peut être implémenté de manière efficace et sous contrôle de l'utilisateur.
\subsection{Mémoire hiérarchique}
\begin{figure}[!htbf]
	\centering
	\includegraphics[scale =0.6]{Chapter2/figures/sequoia_fig1}
	\caption{Multiplication de matrices de tailles 1024x1024 structurée en hiérarchie de tâches indépendantes effectuant des multiplications sur des blocs de données plus petits}
  \label{seq_fig1}
\end{figure}
Le principe de mémoire hiérarchique est au coeur de l'outil \emph{\textbf{Sequoia}}. Dans les systèmes modernes contenant plusieurs unités de traitement avec une hiérarchie mémoire à plusieurs niveaux, il est primordial de diviser un calcul de taille importante en des opérations plus petites pour atteindre des bonnes performances. Cela permet d'exposer le parallélisme et d'atténuer l'effet de la latence d'accès à la mémoire car les données sont physiquement proches des unités de traitement. Un exemple de découpage pour l'application produit de matrices est donné dans la figure \ref{seq_fig1}. Cet exemple contient du parallélisme imbriqué et la localité des données y est primordiale. \emph{\textbf{Sequoia}} requiert une telle réorganisation hiérarchique dans les programmes, qui a été inspirée de l'idée des \emph{space-limited procedures} qui prône les stratégies \emph{divide-and-conquer} tenant compte de la hiérarchie mémoire. Les \emph{space-limited procedures} requièrent à chaque fonction dans une chaine d'appels d'accepter des arguments occupant beaucoup moins d'espace mémoire que les fonctions appelantes. Un système complet a été implémenté autour de cette abstraction incluant un compilateur et un support d'exécution pour le processeur Cell.\\
L'écriture d'un programme \emph{\textbf{Sequoia}} implique la description d'une hiérarchie de tâches et le placement de ces tâches sur la hiérarchie mémoire de la machine cible. Cela impose à l'utilisateur de considérer une machine parallèle comme un arbre de modules mémoire distincts. Les transferts de données entre les niveaux de la hiérarchie se font par blocs éventuellement asynchrones. La logique du programme décrit le transfert des données à tous les niveaux, mais les noyaux de calcul sont contraints de travailler uniquement sur les données qui sont sur les noeuds feuilles (de niveau 0) de l'arbre représentant la machine. La représentation abstraite du processeur Cell (Fig.\ref{seq_fig2}) contient des noeuds correspondants à la mémoire principale ainsi qu'à chaque mémoire locale du SPE.
\begin{figure}[!htbf]
	\centering
	\includegraphics[scale =0.6]{Chapter2/figures/sequoia_fig2}
	\caption{Modèle abstrait \emph{\textbf{Sequoia}} du processeur Cell}
  \label{seq_fig2}
\end{figure}
Un code \emph{\textbf{Sequoia}} ne fait pas de référence explicite à un certain niveau de la hiérarchie et les transferts de données entre les modules mémoire se font de manière implicite. Ainsi, les communications décrites dans \emph{\textbf{Sequoia}} peuvent se faire au travers d'une instruction de prefetch, un transfert DMA ou un message MPI selon les spécificité de l'architecture cible. Ceci garantit la portabilité de l'application tout en bénéficiant des performances des communications explicites. Il y a certaines machines qui possèdent une topologie qui n'est pas facilement représentable sous forme d'arbre. C'est pour cela que la notion de \emph{virtual level} (niveau virtuel) à été introduite dans \emph{\textbf{Sequoia}}, ce niveau ne correspond à aucune mémoire physique. Ce niveau permet par exemple de représenter l'aggrégation des mémoires locales des SPEs sur le processeur Cell. Cela permet notamment d'encapsuler les communications horizontales inter-noeud tout en gardant le modèle d'abstraction en arbre qui lui, ne permet que des communications verticales.
\subsection{Modèle de programmation : les tâches}
La notion de \emph{task} est au coeur du modèle de programmation de \emph{\textbf{Sequoia}}: c'est une fonction pure de tout effet de bord avec une sémantique de passage de paramètre par valeur. Les propriétés qui seront énoncées dans la suite garantissent la portabilité du modèle sans sacrifier les performances. Un exemple de code de multiplication de matrices par blocs est donné dans le listing \ref{sequoiacode} page \pageref{sequoiacode}.

\subsubsection{Communication explicite et localité}
La définition d'une tâche exprime à la fois la localité et la communication dans un programme. Lorsqu'une tâche s'exécute, l'ensemble de toutes les données référencées doivent rester dans un seul noeud de l'arbre abstrait de la machine. Ainsi, une tâche doit s'exécuter dans un endroit précis de la machine. Les pointeurs et les références ne sont pas permis à l'intérieur d'une tâche ce qui permet de dire que l'ensemble des données traitées par la tâche est contenu dans sa définition.\\
L'implémentation contient un appel récursif dans lequel un sous-ensemble des données est passé en paramètre. Les communications sont encapsulées par les tâches en utilisant une sémantique de passage de paramètre dit \emph{call-by-value-result} qui est un passage de paramètres par valeur dans lequel les copies locales des données sont réécrites dans l'espace global à la fin de l'appel de la fonction. Chaque tâche s'exécute dans son espace d'adresses local, toutes les données d'entrée des tâches appelantes sont copiées dans l'espace mémoire de la fonction appelée et les résultats sont recopiées vers l'espace mémoire de la fonction appelante après le retour de la fonction appelée.\\
Le déploiement d'un programme \emph{\textbf{Sequoia}} dicte quand une tâche appelée doit être exécutée dans le même module mémoire que la tâche appelante ou alors assignée à une mémoire fille.

\subsubsection{Isolation et parallélisme}
La granularité du parallélisme dans \emph{\textbf{Sequoia}} est la \emph{tâche} et l'exécution parallèle résulte de l'appel de \emph{tâches} concurrentes. Une tâche s'exécute généralement sur une partie de la boucle externe sous forme de plusieurs \emph{sous-tâches} parallèles, chaque \emph{sous-tâche} s'exécutant en isolation, une propriété qui garantit la portabilité et la performance. Une des contraintes imposées au modèles et que les tâches s'exécutant en parallèle ne peuvent pas coopérer entre elles car elles n'ont aucun moyen de communiquer. Ceci limite le modèle de programmation au modèle SPMD mais évite le recours aux mécanismes de synchronisation couteux.
\subsubsection{Décomposition de tâche}
\emph{\textbf{Sequoia}} introduit des primitives de décomposition de tableaux et de placement de tâches, elles sont décrites ci-dessous:\\

\noindent \rule{\textwidth}{0.2mm}\\
\textbf{\emph{\textbf{Sequoia}} blocking primitives}\\
\begin{itemize}
\item \texttt{\textbf{blkset}}\\
Un objet \emph{\textbf{Sequoia}} opaque représentant une collection de blocs de tableaux.\\
\item \texttt{\textbf{rchop(A, len0, len1, ...)}}\\
Génere un \texttt{\textbf{blkset}} qui contient des blocks qui ne se recouvrent pas et qui tuilent le tableau multidimensionnel A. Chaque bloc est multidimensionnel de taille \texttt{len0 $\times$ xlen1$\times$ ...}.
\item \texttt{\textbf{rchop(A, rchop\_t(offset0, len0, stride0), ...)}}\\
Généralisation de \texttt{\textbf{rchop}} qui génère des ensembles de blocs qui contiennent potentiellement des blocs qui se recouvrent. L'offset du tableau de départ, la taille du bloc, et le saut entre les blocs est spécifié pour toutes les dimensions du tableau source.
\item \texttt{\textbf{ichop(A, Starts, Ends, N)}}\\
Génère un ensemble de blocs du tableau A de tailles non régulières. Les indices de départ et de fin du bloc sont donnés par les éléments dans le tableau de longueur N \texttt{Starts} et \texttt{Ends}. 
\item \texttt{\textbf{gather(A, IdxBlkset)}}\\
Génère un ensemble de blocs en rassemblant les éléments d'un tableau source A en utilisant des indices fournis dans les blocs de \texttt{IdxBlkset}. Le \texttt{blkset } résultant possède les mêmes nombre et taille que les blocs de \texttt{IdxBlkset}.\\
\end{itemize}
\textbf{\emph{\textbf{Sequoia}} mapping primitives}\\
\begin{itemize}
\item \texttt{\textbf{mappar(i=i0 to iM, j=j0 to jN ...)   {...}}}\\
Une boule \texttt{\textbf{for}} multi-dimensionnelle contenant uniquement un appel à une \emph{sous-tâche} dans le corps de boucle. La tâche est mappée en parallèle en une collection de blocs.
\item \texttt{\textbf{mapseq(i=i0 to iM, j=j0 to jN ...)   {...}}}\\
Une boule multi-dimensionnelle contenant uniquement un appel à une \emph{sous-tâche} dans le corps de boucle. La tâche est mappée séquentiellement en une collection de blocs.
\item \texttt{\textbf{mapreduce(i=i0 to iM, j=j0 to jN ...)   {...}}}\\
Permet de faire le mapping en une collection de blocs, qui effectue une réduction sur au moins un argument de la tâche. Pour le support des réductions d'arbres parallèles, une tâche supplémentaires de
 recombinaison est requise.\\
\end{itemize}
\rule{\textwidth}{0.2mm}\\
\subsubsection{Variantes de Tâches}
\emph{\textbf{Sequoia}} inclut deux types de tâches qui servent essentiellement à distinguer le code de mapping du code de calcul, elles sont décrites ci-dessous:
\begin{itemize}
\item \emph{Inner Tasks}: ce sont les tâches qui appellent des sous-tâches. Elles n'ont pas d'accès direct à leurs arguments de type tableau mais elles passent aux sous-tâches sous forme de blocs. Les \emph{Inner Tasks} utilisent les primitives de \emph{mapping} et de \emph{blocking} pour structurer les calculs sous forme de sous-tâches. La définition d'une \emph{Inner Task} n'est associée à aucun module mémoire particulier de la machine, elle peu s'exécuter dans n'importe quel niveau de la hiérarchie mémoire dans lequel les données traitées tiennent.
\item \emph{Leaf Tasks}: ce sont des tâches qui ne font pas appel à des sous-tâches et qui opèrent directement sur des données résidant dans les niveaux feuilles de la hiérarchie mémoire. 
\end{itemize}

\subsubsection{Paramètrisation de tâches}
Les tâches sont écrites de manière à ce qu'elles soient paramétrables pour la spécialisation à de multiples machines cibles. La spécialisation est le processus de création d'instances d'une tâche qui est personnalisée pour s'exécuter sur un certain niveau de la hiérarchie mémoire de la machine. La paramétrisation des tâches permet à une stratégie de décomposition décrite par une variante de tâche, d'être appliquée dans différents contextes, rendant la tâche portable sur différentes machines et sur différents niveaux de la hiérarchie mémoire d'une cible donnée. L'utilisation de paramètres comme la taille des tableaux ainsi que les paramètres ajustable, découple l'expression d'un algorithme de son implémentation sur une machine donnée.
\subsubsection{Spécialisation de tâches et tunning}
Dans \emph{\textbf{Sequoia}} on donne au programmeur le contrôle complet sur les phases de spécialisation et de tunning du code, au travers d'une phase dite de \emph{task mapping and specification} qui est créée par l'utilisateur pour une machine donnée est maintenue indépendamment du code source. En plus, cette phase permet au programmeur de fournir des directives d'optimisation qui sont propres à une cible donnée. 
Les spécification de mapping ont pour but de donner à l'utilisateur un contrôle précis sur le mapping d'une hiérarchie de  tâches sur une machine en isolant les optimisations spécifiques à une cible donnée dans un autre endroit. Au lieu de confier le travail à un compilateur, \emph{\textbf{Sequoia}} permet au programmeur d'optimiser son code lui même afin d'obtenir les meilleurs performances possibles.
\newpage
%===============================Listing \emph{\emph{\textbf{Sequoia}}}=======================================
\lstset{ %
language=C,                % choose the language of the code
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
backgroundcolor=\color{light-gray},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=single,			% adds a frame around the code
tabsize=2,			% sets default tabsize to 2 spaces
captionpos=b,			% sets the caption-position to bottom
breaklines=true,		% sets automatic line breaking
breakatwhitespace=false,	% sets if automatic breaks should only happen at whitespace
escapeinside={\%*}{*)}  ,        % if you want to add a comment within your code
caption = Exemple de multiplication matricielle par blocs \emph{\textbf{Sequoia}},
label = sequoiacode
}
\lstinputlisting{Chapter2/Code/sequoia.c}
%===================================================================================
\subsection{Implémentation du compilateur \emph{\textbf{Sequoia}}}
Dans l'implémentation de \emph{\textbf{Sequoia}}, un compilateur source vers source génère du code C qui s'interface avec un support d'exécution spécifique à la plate-forme. Les paramètres d'entrée du compilateur sont un programme \emph{\textbf{Sequoia}} ainsi que des spécifications de mapping sur la machine cible.
\subsubsection{Compilateur Cell et support d'exécution}
Les instances de tâches \emph{Inner} correspondant à la mémoire principale sont exécutées par le PPE alors que les instances correspondant au niveau mémoire des \emph{local store} sont exécutées par les SPE. Les codes sources PPE et SPE sont compilés séparément, un code binaire est ainsi combiné pour l'exécution. Si toutefois le code SPE dépasse la capacité du local store il est découpé sous forme d'overlays. Le support d'exécution est piloté par les évènements : un système de notification via \emph{mailbox} est mis en place entre le PPE est les SPEs, les tâches sont assignées par le PPE au SPEs. Une fois que la notification est reçue, un mécanisme du support d'exécution charge le morceau de code à exécuter dans les SPEs et initie les transferts de données via DMA. Le système permet la superposition de transferts et de calculs afin d'améliorer les performances. Les mécanismes de synchronisation ne sont pas constamment utilisés entre les tâches, un seul point de synchronisation est requis lors de la fin des sections parallèles, ce qui minimise le surcoût.

\subsubsection{Optimisations}
En plus de permettre au programmeur d'optimiser son implémentation des tâches dans \emph{\textbf{Sequoia}}, certaines optimisations visant à utiliser efficacement la mémoire sont effectuées, notamment l'optimisation des transferts au niveau d'un même niveau de la hiérarchie mémoire, où les copies inutiles sont détectées et supprimées. D'autres optimisations dans le \emph{software-pipelining} et le déplacement des invariants de boucle, sont effectuées de manière statique à la compilation.

\subsection{Conclusion sur \emph{\textbf{Sequoia}}}
\emph{\textbf{Sequoia}} est un langage de programmation \emph{data parallel} qui tente d'allier la portabilité avec la performance pour le portage d'algorithmes sur des architectures parallèles. La performance est assurée par l'octroi à l'utilisateur d'une grande liberté dans l'optimisation du code de calcul qui s'exécute sur les noeuds au plus bas niveau de la hiérarchie mémoire. La portabilité est garantie par le fait que l'expression de l'algorithme est découplée de l'implémentation. L'expression explicite des communications, des mouvements des données au travers de la hiérarchie mémoire, des calculs parallèles et la définition d'un ensemble de travaux sont effectués grâce à une seule abstraction, la \emph{tâche}. \emph{\textbf{Sequoia}} fournit des primitives de structuration des calculs en tant que hiérarchie de tâches afin d'améliorer la localité et laisse au programmeur le soin d'optimiser la tâche pour une architecture donnée. Cependant, l'outil possède des limitations quand aux schéma de parallélisation possibles car il ne supporte que le parallélisme SPMD. Les schémas que nous avons implémentés lors de notre étude ne sont pas couverts par l'outil. De plus, les optimisations bas-niveau sont à la charge du programmeur. Cela impose d'apprendre un \emph{framework} de programmation supplémentaire avec des limitations imposées par l'outil. Nous n'avons donc pas retenu cette solution pour la mise en oeuvre de nos implémentations.
\newpage
\section{Conclusion}
Dans ce qui précède, nous avons décrit différents outils de programmation pour le processeur Cell. Ce chapitre, qui n'est pas une étude exhaustive, fait état des principaux outils qui ont fait objet de publications et d'évaluations significatives. Les outils diffèrent par le modèle de programmation sur lequel ils se basent. Les plus simples à utiliser, qui sont les approches à base d'annotation de code (\emph{\textbf{OpenMP}}, \emph{\textbf{CellSS}}), laissent le soin au compilateur de faire le travail de parallélisation et d'optimiser le code. D'autre part, \emph{\textbf{RapidMind}} et \emph{\textbf{Sequoia}} se reposent sur un langage spécifique accompagné d'un support d'exécution et d'un compilateur, mais une bonne partie du travail d'optimisation est laissée à la charge du programmeur. D'autres modèles de programmation qui ne sont pas exposés ici, ont fait l'objet d'études sur le processeur Cell, dont le modèle de programmation par passage de message MPI. N'ayant pas pu avoir accès aux implémentations décrites dans  \cite{Ohara_2006_MPI} et \cite{Kumar_2007_MPI}, nous n'avons pas pu en évaluer la facilité de mise en oeuvre et les performances.\\
L'ensemble de ces outils ont vu le jour pour faciliter la programmation sur le Cell, et fournir une alternative à l'utilisation fastidieuse des \emph{pthreads} qui sont un outil de programmation parallèle très bas niveaux qui laisse une grande liberté au programmeur pour ce qui est du déploiement de son code et de son optimisation. Un code à base de \emph{\emph{threads} }  est de ce fait long à mettre en oeuvre est difficile à maintenir, mais il permet d'un autre  côté d'avoir un contrôle total sur son implémentation.
On notera que la mise en oeuvre à nécessité un grand effort de la part des concepteurs pour deux raisons principales: (1) la mémoire distribuée du Cell qui impose la gestion explicite des transferts mémoire à partir de et vers la mémoire centrale (2) Le PPE et les SPEs possèdent des jeux d'instructions différents ce qui rend difficile l'étape de génération de code.\\
L'ensemble des outils étudiés dans ce chapitre adoptent un modèle de programmation du type SPMD, qui ne permet d'exploiter que le parallélisme de données dans les applications. De plus, ces outils se basent sur les compilateurs fournis pour les tâches d'optimisation du code. Les outils présentés sont limités à un seul schéma de parallélisation et ne permettent pas de faire certaines optimisations très profitables pour les applications de traitement d'images telles que les optimisations interprocédurales et la vectorisation de code. Cette analyse a permis de mettre en avant le fait que ces outils ne sont pas adaptées à notre domaine d'application. Dans le chapitre qui suit nous présentons un outil de programmation pour le Cell que nous avons développé et qui propose une approche de programmation différente, plus adaptée au traitement d'images et qui permet d'exploiter d'autres formes de parallélisme.

%On trouve dans la littérature plusieurs jeux de squelettes algorithmiques répondant à divers besoins [45, 22, 5, 88, 119, 54]. Au sein de QUAFF, 
%\section{The Divide \& Conquer Skeleton (Fixed Degree}
%Ce type de squelette provient de la célèbre technique du \emph{divide and conquer}. Cette technique peut s'appliquer lorsque la solution à un problème peut être définie récursivement comme une collections de sous-problèmes qui sont des instances plus petites du problème original. Les algorithmes de ce type offrent un bon potentiel de parallélisation. En effet, si l'on arrive à exprimer un problème sous forme de sous-problèmes définis récursivement  on imagine bien que ces derniers peuvent être exécutées de manière concurrente sur plusieurs processeurs. L'exécution des algorithmes du type \emph{divide and conquer} se résume à l'évaluation d'un arbre de processus évoluant dynamiquement, le processus représentant un sous-problème généré. Le défi étant de s'assurer que les déploiement de cet arbre virtuel se fait de la manière la plus efficace possible sur une vraie machine. 
%\section{The Iterative Combination Skeleton}
%\section{The Cluster Skeleton}
	%\section{The Task Queue Skeleton}>>>>>>> .r54
