%\begin{quote}
%\emph{"I think games are an interesting application area, but quite clearly, Cell is not just for games.  There are many other areas it can be used.  Games are the thing that inspired us to do it.}\\
%Peter Hofstee, chief architect of the Cell processor
%\end{quote}
\indent Le processeur Cell est une architecture unique en son genre car elle renferme une multitude de dispositifs dédiés au calcul haute-performance. Son architecture parallèle à plusieurs niveaux permet aux utilisateurs aguerris d'atteindre des performances jusque là réservées aux seuls clusters de machines et utilisant des paradigmes de haut niveau tels que le \emph{message-passing}. En ce sens l'architecture du Cell, destinée initialement au domaine des jeux vidéos, a trouvé d'autres débouchés notamment dans le calcul scientifique au sens large.\\
\indent Le Cell est composé d'un processeur PowerPC classique nommé PPE (Power Processor Element) et de huit unités de calcul accélératrices appelées SPE (\emph{Synergestic Processor Element}). Ces unités de calcul sont reliées par un bus interne qui permet également l'accès  la mémoire principale (\emph{Main Storage}), ainsi qu'à  d'autres périphériques externes. Le processeur Cell est considéré comme un processeur hétérogène car il comporte deux types d'architectures différentes : celle du PPE qui n'est autre qu'une déclinaison du PowerPC 970 et celle des SPE qui sont des unités SIMD accélératrices spécialisées dans des traitements contenant un flot de données important comme le multimédia par exemple. Les jeux d'instructions vectorielles des SPE est très proche à Altivec, présent sur les architectures de type PowerPC \\
\section{Aperçu de l'architecture}
\begin{figure}[!htbf]
	\centering
	\includegraphics[scale =0.65]{Chapter2/figures/cell_fig01_bw}
	\caption{Vue d'ensemble de l'architecture hétérogène du processeur Cell}
  \label{cell_fig1}
\end{figure}
Le processeur Cell est la première implémentation de l'architecture \emph{Cell Broadband Engine} (CBEA), qui est entièrement compatible avec l'architecture \emph{PowerPC} 64-bit. Ce processeur à été initialement conçu pour la console de jeux \emph{PlayStation 3} mais ses performances hors normes ont très vite fait de lui un bon candidat pour d'autres domaines d'applications qui requièrent une grande puissance de calcul, comme le traitement du signal et des images.\\
Le processeur Cell est une machine multi-coeurs hétérogène, capable d'effectuer une quantité de calcul en virgule flottante considérable, sur des données occupant une large bande-passante. Il est composé d'un processeur 64-bit appelé \emph{Power Processor Element} (PPE), huit co-processeurs spécialisés appelés \emph{Synergistic Processor Element} (SPE), un contrôleur mémoire haute-vitesse et une interface de bus à large bande-passante. Le tout intégré sur une seule et même puce.\\
Le PPE et les SPEs communiquent au travers d'un bus interne très rapide appelé \emph{Element Interconnect Bus} (EIB) (Fig. \ref{cell_fig1}). Si l'on considère une fréquence d'horloge de 3.2 GHz, le processeur Cell peut atteindre théoriquement une performance crête de 204.8 GFlop/s en simple-précision (32-bit) et 14.6 GFlop/s en double-précision (64-bit). Il est important de noter que sur la première génération le débit des instructions arithmétiques en double-précision était d'une instruction tous les 7 cycles ce qui explique les 14.6 GFlop/s. Ce débit à été amélioré pour atteindre 1instruction/cycle sur la dernière génération \emph{PowerXCell 8i}, ce qui donne 102.4 GFlop/s. \\

%Le bus interne supporte une bande passante qui peut aller jusqu'à 204.8 Go/s pour les transferts internes à la puce (impliquant le PPE, les SPEs, la mémoire et les contrôleurs I/O). le contrôleur mémoire: \emph{Memory Interface Controller} (MIC) fournit une bande-passante de 25.6 Gbytes/s vers la mémoire principale. Le contrôleur I/O quand à lui fournit 25 Gbytes/s en entrée et 35 Gbytes/s en sortie.\\
%Le rôle du PPE est celui d'un chef d'orchestre. Il prend en charge l'OS (\emph{Operating System}) et coordonne les SPEs. Au niveau de l'architecture c'est un \emph{PowerPC} 64-bit classique avec une extension SIMD, un cache L1 de 32 Ko (données et instructions) et un cache L2 de 512 KB. C'est un processeur à exécution dans l'ordre (\emph{in-order execution processor}), il supporte le \emph{dual-issue} (parallélisme d'instructions) ainsi que le multi-threading d'ordre 2 (parallélisme de tâches).\\
%Chaque SPE est composé d'une SPU (\emph{Synergistic Processor Unit}) et d'un MFC (\emph{Memory Flow Controller}). Le MFC contient à son tour un contrôleur DMA (\emph{Direct Access Memory}), une unité de gestion de la mémoire (MMU), une unité interface de bus, et une unité atomique pour la synchronisation avec les autres SPEs et le PPE. Le SPU est un processeur de type RISC avec un jeu d'instructions et une micro-architecture conçus pour les applications flot de données haute-performance ou de calcul intensif. Le SPU inclut une mémoire locale de 256 Ko qui contient les données et les instructions. Le SPU ne peut pas accéder directement à la mémoire principale mais par le biais de commandes DMA via le MFC qui permettent de lire et d'écrire dans la mémoire principale. Les deux unités MFC et SPU sont indépendantes ce qui permet l'exécution des tâches de calcul et de transferts en parallèle sur le SPE.\\
I%l n'existe pas de mécanisme hardware tel que la mémoire cache pour la gestion automatique des mémoires locales, et celles-ci doivent être gérées par le software. Le MFC effectue des commandes DMA pour transférer entre la mémoire centrale et les mémoires locales. Les instructions DMA pointent des emplacements de la mémoire centrale en utilisant des adresses virtuelles compatibles \emph{PowerPC}. Les commandes DMA peuvent transférer des données à partir de n'importe quel emplacement lié au bus d'interconnexion (mémoire principale, la mémoire locale d'un autre SPE, ou un périphérique I/O). Des transferts SPE vers SPE en parallèle sont faisables à raison de 16 \emph{bytes} par cycle d'horloge SPE, tandis que la bande-passante de la mémoire centrale est de 25.6 Gbytes/s pour le processeur entier.\\
%Chaque SPU contient 128 registres SIMD de taille 128-bits. Cette quantité importante de registres facilite l'ordonnancement efficace des instructions ainsi que d'autres optimisations comme le déroulage de boucle (loop-unrolling).\\
%Toutes les instructions SIMD sont des instructions que le pipeline peut exécuter à 4 granularités: 16 entiers 8-bit, 8 entiers 16-bit, 4 entiers 32-bits ou flottants simple-précision. Le processeur SPU est un processeur à exécution dans l'ordre (\emph{in-order-execution processor}), il possède deux pipelines d'instructions connus sous les dénominations pair (\emph{even}) et impair (\emph{odd}).\\
%Les instructions flottantes et entières sont dans le pipeline \emph{even} alors que le reste est dans le pipeline \emph{odd}. Chaque SPU peut lancer et compléter jusqu'à deux instructions par cycle, une par pipeline. Toutes les instructions flottantes en simple-précision peuvent être lancées en un cycle d'horloge du processeur. Par contre les instructions flottantes en double-précision ne sont pipelinées que partiellement, il en résulte un débit d'exécution moindre (deux instructions double-précision tous les 7 cycles d'horloge SPU).\\
%Si l'on prend une instruction de multiplication accumulation en flottant simple-précision (qui compte pour deux opérations) les 8 SPEs peuvent exécuter un total de 64 opérations par cycle \cite{kahle_2005}.\\

\subsection{Le PPE:  Power Processor Element}

Le PPE est un processeur 64-bit compatible avec l'architecture Power, optimisée au niveau de l'efficacité énergétique. La profondeur de pipeline du PPE est de 23 étages, chiffre qui peut paraitre faible par rapport au précédentes architectures PowerPC surtout quand on sait que la durée de l'étage est réduite d'un facteur 2. Le PPE est une architecture dual-issue (deux instructions peuvent être lances par cycle) qui ne réordonnance pas dynamiquement les instructions  l'exécution (exécution dans l'ordre). Les instructions arithmétiques simples s'exécutent et fournissent leur résultat en deux cycles. Les instructions de chargements (\texttt{LOAD}) s'exécutent également en deux cycles. Une instruction flottante en double précision s'exécute en dix cycles. Le PPE supporte une hiérarchie conventionnelle de caches avec un cache L1 (de niveau 1) données et instructions de 32 Ko, et un cache L2 de 512 Ko.\\
Le processeur fournit deux \emph{threads} d'exécution simultanés et peut être vu comme un processeur double-coeur avec un flot de donnes partagé, ceci donne l'impression au logiciel d'avoir deux unités de traitement distinctes. Les registres sont dupliqués mais pas les caches qui sont partagés par les deux \emph{threads}. Les instructions provenant de deux \emph{threads} de calcul différents sont entrelacées, afin d'optimiser l'utilisation de la fenêtre d'exécution.\\
Le processeur est composé de trois unités : l'unité d'instructions (UI) responsable du chargement, décodage, branchements, exécution et complétion des instructions. Une unité d'exécution des opérations en arithmétique point-fixe (XU) qui est également responsable des instructions \texttt{LOAD/STORE}. Et enfin l'unité VSU qui exécute les instructions en virgule flottante ainsi que les instructions vectorielles. Les instructions SIMD dans le PPE sont celle des générations précédentes de PowerPC 970 et effectuent des opérations sur des registres 128-bit de données qui donnent un parallélisme de 2, 4, 8 ou 16, selon le type de données considéré.

\subsection{Les SPE (Synergistic Processing Element)}
Le SPE contient un jeu d'instructions nouveau mais qui n'est autre qu'une version réduite du jeu d'instructions SIMD VMX, mais optimisé au niveau de consommation d'énergie et des performances pour les applications de calcul intensif et de multimedia. Le SPE contient une mémoire locale de 256 Ko (\emph{scratchpad}) qui est une mémoire de données et d'instructions. Les données et les instructions sont transférées de la mémoire centrale vers cette mémoire privée au travers de commandes DMA qui sont exécutées par le MFC (Memory Flow Controller) qui est présent dans chaque SPE. Chaque SPE peut supporter jusqu'à16 commandes DMA en suspens. L'unité DMA peut être programmée de trois manières différente: 1) avec des instructions sur le SPE qui insèrent des commandes DMA dans la file d'attente; 2) par la programmation de transferts permettant de faire des accès sur des zones non contiguës de la  mémoire au travers d'une liste de DMA, ce qui permet de définir un ensemble de transferts contigus de tailles différentes; 3) par l'insertion d'une commande DMA dans la file d'attente d'un autre processeur par les commandes de DMA-write.\\
Afin de faciliter la programmation et de permettre des transferts entre SPEs les mémoires locales sont mappées en mémoire centrale. La présence des mémoires locales introduit un autre niveau dans la hiérarchie mémoire au dessus des registres. Les temps d'accès de ces mémoires sont de l'ordre du cycle ce qui en fait de bons candidats pour réduire la latence d'accès  la mémoire centrale qui est de l'ordre du millier de cycles, d'autant plus que le fait que le contrôleur DMA soit indépendant de l'unité donne un niveau de parallélisme supplémentaire. La présence de ces mémoires privées permet à différents modèles de programmation d'être appliqués au processeur Cell.

\subsection{Gestion de la mémoire}
Dans une application pour le processeur Cell, plusieurs SPEs peuvent partager un espace mémoire commun avec les threads PPE. En même temps, d'autres SPEs peuvent référencer des espaces mémoire virtuels associés à des applications qui s'exécutent de manière concurrente sur le système. Le support de cette fonctionnalité est assuré par l'unité de gestion mémoire (\emph{Memory Management Unit}) qui permet de traduire les adresses système lors de la requête. Le contrôleur participe aux protocoles de cohérence de la mémoire afin d'assurer la cohérence des tables de pages.\\
Chaque contrôleur peut être programmé pour effectuer des transferts mémoire soit à partir du SPE en insérant une commande dans la file d'attente locale soit à partir d'un noeud distant. Le contrôleur mémoire peut également participer à des opérations de synchronisation de la mémoire et des threads. Un mécanisme de liste de transferts est également supporté par le contrôleur qui permet d'englober une séquence de transferts au sein d'une même commande.

\subsection{Contrôleur de flot mémoire (\emph{Memory Flow Controler})}
Afin d'accéder aux données globales partagées par les threads s'exécutant sur le PPE et ceux exécutés sur le SPE, chaque SPE contient un contrôleur de flot mémoire, qui effectue des transferts entre la mémoire système et les mémoire privées des SPEs. Le contrôleur mémoire fournit au SPEs l'accès à la mémoire système par le biais des transferts DMA entre celle-ci et les mémoire locales des SPE. Les tailles des blocs de transfert varient entre un octet et 16 Ko. Une requête de transfert spécifie l'adresse locale du SPE à partir de l'adresse physique dans le SPE. L'adresse mémoire système est elle spécifiée par une adresse virtuelle qui est traduite en adresse physique par le contrôleur mémoire en se basant sur les tables de pages.    


\subsection{Le bus interne (Element Interconnect Bus)}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= \columnwidth]{Chapter2/figures/cellnoc}
  \caption{Réseau d'interconnexion du Cell d'après \cite{cellnoc}}
  \label{fignoc}
\end{figure}
Le bus interne du processeur permet de relier les unités de traitement PPE, SPE  la fois entre elles,  la mémoire centrale ainsi qu'aux sorties externes. Le bus contient des chemins de données différents de ceux des requêtes. Les éléments autour du bus sont connectés par des liaisons point-à-point et un arbitre de bus est responsable de la réception des commandes et de leur diffusion vers les unités. Le bus est constitué de quatre anneaux d'une largeur de 16-octets, deux fonctionnent dans le sens d'une aiguille d'une montre et les deux autres dans le sens inverse. Chaque anneau peux potentiellement gérer 3 transferts en parallèle si toutefois leurs chemins ne se croisent pas. Le EIB opère à une fréquence qui est la moitié de celle du processeur, chaque unité du bus peut simultanément envoyer et recevoir 16 octets par cycle d'horloge du bus.

%====================================================== THREADS POSIX ======================================================================================================================================
%\section{Les threads POSIX}
%Les \emph{threads} POSIX\footnote{Portable Operating System Interface for Unix} ou \emph {Pthreads} sont une standardisation\cite{pthreads_std} du modèle de programmation par \emph{threads} pour les systèmes UNIX. Ce modèle est basé sur une API de programmation parallèle qui permet la gestion des \emph{threads} ainsi que la synchronisation par \emph{mutex} ou variables conditionnelles. Historiquement, les concepteur de \emph{hardware} ont développé leurs implémentations propriétaires des \emph{threads}, ceci a rendu la portabilité du code des programmeurs quasi impossible. La nécessité d'une API standard est donc devenue vitale, c'est pour cette raison que la majorité des vendeurs de \emph{hardware} possèdent actuellement leur implémentation standard des \emph{threads} POSIX. Les \emph{Pthreads} sont définis autour d'un ensemble de procédures et de types en langage C contenus dans le fichier d'entête \texttt{"pthread.h"}.\\
%D'une manière générale un \emph{thread} est un flux d'instructions pouvant s'exécuter de manière indépendante sur un OS donné. Du point de vue du programmeur ceci s'apparente à une procédure qui peut s'exécuter indépendamment du programme principal, un programme contenant des procédures de ce type est dit \emph{multi-threaded}. Afin de détailler le principe de fonctionnement des \emph{threads} il est nécessaire de faire un rappel sur les \emph{process} UNIX. Un \emph{process} est créé par l'OS est contient un certain \emph{overhead} qui consiste en certaines ressources nécessaires à son exécution. Les \emph{threads} résident à l'intérieur de ces ressources et sont capables d'être ordonnancés et exécutés en tant qu'entités indépendantes car ils ne dupliquent qu'une partie des ressources qui leurs permettent d'être des morceaux de code exécutables. Le flot de contrôle est rendu indépendant car le \emph{thread} possède ses propres : pointeur de pile, registres, propriétés d'ordonnancement (priorité et politique), ensemble de signaux et données spécifiques. En somme, un \emph{thread} existe dans un \emph{process} dont il utilise les ressources. Il possède son propre flot de contrôle et ne duplique que les ressources nécessaires à son exécution indépendante. Il peut partager les ressources du \emph{process} avec d'autres \emph{threads} et s'exécuter en coordination avec ces derniers. La complexité due à sa création et à sa gestion est légère comparativement à celle du \emph{process} et sa durée de vie est celle de son \emph{process} parent.
%\subsection{l'API pthread}
%L'API des \emph{threads} POSIX peut être décomposée en trois types de routines:
%\begin{itemize}
%\item \textbf{Les routines de gestion des \emph{threads}} : comprends les tâches de création, propriétés d'exécution et terminaison des \emph{threads}.
%\item \textbf{Les \emph{mutex}} (abréviation de \emph{mutual exclusion}): ils permettent de synchroniser les \emph{threads}, les routines gèrent la création, destruction, réservation et libération des \emph{mutex}.
%\item \textbf{Les variables conditionnelles} : ces dernières gèrent la communication entre des \emph{threads} qui partagent les \emph{mutex}. Elles sont basées sur des conditions fixées par le programmeur, elles incluent des fonctions de création, destruction, attente et signalisation basées sur certaines valeurs de ces variables. 
%\end{itemize}
%\rule{\textwidth}{0.2mm}\\
%\subsubsection{Gestion des threads}
%\begin{itemize}
%\item \textbf{Création et Terminaison des \emph{threads}}: Initialement le programme contient un seul \emph{thread} qui est le \texttt{main()}. Les autres \emph{threads} doivent être créés explicitement par le programmeur. \texttt{pthread\_create} créé un nouveau \emph{thread} et le rend exécutable, un exemple de code à base de \emph{Pthreads} est donné dans le listing \ref{pthreadcode}. Cette routine peut être appelée autant de fois que l'on veut et à n'importe quel endroit dans le code. Le nombre de \emph{threads} maximal créé par un \emph{process} dépend de l'implémentation. Une fois créés les \emph{threads} peuvent créer à leur tour d'autres \emph{threads} et il n'existe aucune dépendance ni hiérarchie entre les \emph{threads}. Le \emph{thread} est crée avec certains attributs par défaut, ceux-ci pouvant être changés ultérieurement. Il existe plusieurs manières de terminer un \emph{thread} : soit par le \emph{thread} lui même qui le fait par un \texttt{return} de sa routine principale ou par la fonction \texttt{pthread\_exit()}, ou alors par un autre \emph{thread} en utilisant \texttt{pthread\_cancel()} et enfin en cas de terminaison du \emph{process} parent.
%\item \textbf{Passage d'Arguments au \emph{threads}} : On peut passer un argument au \emph{thread} via la routine \texttt{pthread\_create()}. On peut également passer plusieurs arguments en les rassemblant dans une structure et en passant l'adresse de celle-ci.
%\item \textbf{Jonction et Détachement des \emph{threads}} : La jonction est une manière de faire une synchronisation entre les \emph{threads}, la fonction \texttt{pthread\_join()} bloque le \emph{thread} appelant jusqu'a ce que le \emph{thread} appelé termine son exécution. Le caractère joignable ou pas d'un \emph{thread} est spécifié à sa création : s'il est créé en tant que \emph{thread} détaché il ne pourra pas être joignable. La routine \texttt{pthread\_detach()} sert à détacher un \emph{thread} qui était joignable à sa création.
%\item \textbf{Gestion de la Pile} : Le standard ne définit pas la taille par défaut de la pile du \emph{thread}, celle-ci dépend de l'implémentation. Toutefois, le programmeur peut en spécifier la taille ainsi que l'emplacement de la mémoire dans laquelle elle doit être stockée.
%\end{itemize}

%\subsubsection{Les variables \emph{mutex}}
%Les \emph{mutex} sont un des principaux mécanismes de synchronisation de \emph{threads}. Ils permettent par exemple de synchroniser des \emph{threads} ou alors de protéger des données partagées en cas d'écriture simultanée. Un \emph{mutex} peut être réservé (\emph{lock}) par un seul \emph{thread} à un moment donné, le propriétaire du \emph{mutex} est le seul à le posséder : tout autre \emph{thread} qui essaye de réserver ce même \emph{mutex} échoue jusqu'à ce que le propriétaire le libère (\emph{unlock}). Il existe des routines de création et de destruction des \emph{mutex}, la réservation des \emph{mutex} se fait soit par appel à la routine \texttt{pthread\_\emph{mutex}\_lock()} (bloquant), \texttt{pthread\_\emph{mutex}\_trylock()} (non bloquant) et se libère par \texttt{pthread\_\emph{mutex}\_unlock()}. Parmi les exemples d'utilisation des \emph{mutex} on peut citer les cas de \emph{race condition} où plusieurs \emph{threads} essayent de mettre à jour une variable globale, il est nécessaire dans ce genre de situation de protéger cette variable par un \emph{mutex} afin que celle-ci ait la même valeur du point de vue de tous les \emph{threads}. On dit alors que l'on crée une \emph{section critique}.
%===============================Listing Pthreads =======================================
%\lstset{ %
%language=C,                % choose the language of the code
%basicstyle=\footnotesize,       % the size of the fonts that are used for the code
%backgroundcolor=\color{light-gray},  % choose the background color. You must add \usepackage{color}
%showspaces=false,               % show spaces adding particular underscores
%showstringspaces=false,         % underline spaces within strings
%showtabs=false,                 % show tabs within strings adding particular underscores
%frame=single,			% adds a frame around the code
%tabsize=2,			% sets default tabsize to 2 spaces
%captionpos=b,			% sets the caption-position to bottom
%breaklines=true,		% sets automatic line breaking
%breakatwhitespace=false,	% sets if automatic breaks should only happen at whitespace
%escapeinside={\%*}{*)}  ,        % if you want to add a comment within your code
%caption = Exemple de code \emph{Pthread} basique montrant les routines de création de \emph{threads},
%label = pthreadcode
%}
% \lstinputlisting{Chapter2/Code/pthreadexample.c}
%===================================================================================
%\subsubsection{Les variables de condition}
%Les variables de condition fournissent aux \emph{threads} une autre manière de se synchroniser. Contrairement aux \emph{mutex} qui sont basés sur le contrôle de l'accès à une variable, la synchronisation par variable de condition se fait selon une valeur spécifique. Les variables de condition sont utilisées en conjonction avec les \emph{mutex}. L'appel à la fonction \texttt{pthread\_cond\_wait()} bloque le \emph{thread} appelant jusqu'à ce que la condition spécifiée est signalée. Cette routine doit être appelée tant que le \emph{mutex} est réservé et libère automatiquement le \emph{mutex} quand elle est en attente. Une fois que le signal est reçu, le \emph{thread} est réveillé et le \emph{mutex} est réservé automatiquement pour être utilisé par le \emph{thread}. La responsabilité de libérer le \emph{mutex} est à la charge du programmeur qui le fait une fois que son utilisation n'est plus nécessaire. La fonction \texttt{pthread\_cond\_signal()} est utilisée pour signaler (ou réveiller) un autre \emph{thread} qui est en attente de la variable de condition. Elle doit être appelée après que le \emph{mutex} est réservé et doit libérer le \emph{mutex} dans l'ordre pour permettre à \texttt{pthread\_cond\_wait()} de s'achever. Il existe une routine nommée \texttt{pthread\_cond\_broadcast()} qui met en attente plusieurs \emph{threads} en même temps. 

\section{Environnement de développement de base}
L'environnement de développement fourni par IBM est le \emph{Cell Software Development Kit (Cell SDK)}. Plusieurs versions ont vu le jour, la première était la 1.0 qui a précédé la livraison des premières puces Cell, l'exécution du code se faisait alors sur un simulateur du processeur. La dernière version du SDK connue à ce jour est la 3.0. La description qui suit est basée sur la version antérieure 2.1 du SDK. L'environnement de développement contient les composants suivants : 
\begin{itemize}
\item \textbf{La chaîne d'outils GNU : } Cette chaîne contient le compilateur \emph{gcc} (\emph{GNU C-language Compiler}) pour le PPE et le SPE. Les deux compilateurs peuvent effectuer de la \emph{cross} compilation sur des plateformes x86. 
\item \textbf{Le compilateur IBM XL C/C++ : } C'est le compilateur conçu par IBM pour le processeur Cell. Il contient également deux compilateurs spécifiques, un pour le PPE; l'autre pour le SPE. La \emph{cross} compilation est également possible avec les compilateurs \emph{XLC} . La présence de deux chaînes de compilateurs distinctes s'explique par le fait que \emph{gcc} est destiné à la communauté \emph{Open Source} et dépend de sa contribution, alors que le compilateur \emph{XLC} est développé et commercialisé par IBM. Dans nos travaux nous avons pu utiliser les deux compilateurs. \emph{XLC} se distingue de \emph{gcc} par la gestion d'OpenMP et un code généré plus efficace sur le PPE et le SPE.
\item \textbf{IBM full-system simulator : } Le simulateur du Cell est une application logicielle qui émule le comportement d'un système complet contenant un processeur Cell. Un système d'exploitation linux est géré par le simulateur. On peut ainsi, exécuter des application pré-compilées sur le simulateur. Il existe plusieurs modes de simulation possibles, du mode purement fonctionnel, au mode précis au cycle près (\emph{cycle accurate}).
\item \textbf{Noyau Linux : } C'est le noyau Linux pour le Cell qui supporte notamment l'exécution parallèle sur les SPEs. Il est développé et maintenu par le \emph{Barcelona Supercomputer Center}. Celui-ci s'exécute sur le PPE qui peut gérer un système d'exploitation alors que les SPEs sont des coprocesseurs dédiés au calcul intensif.
\item \textbf{La bibliothèque de gestion du support d'exécution SPE : } Cette bibliothèque constitue l'API bas-niveau standard pour la programmation d'applications pour le Cell, en particulier pour l'accès au SPEs. La bibliothèque fournit une API neutre vis à vis des systèmes d'exploitation et la manière dont ils gèrent les SPEs, à travers une interface standard très proche de POSIX.
\end{itemize}
Nous avons cité ci-dessus les principaux composants du SDK que nous avons utilisé lors du développement des applications sur le processeur Cell. D'autres composants sont fournis avec le SDK : des bibliothèques de calcul mathématique et numérique optimisées pour le Cell, de utilitaires de mesure de performance ainsi qu'un \emph{plugin} pour l'environnement de développement Eclipse spécifique au développement sur le processeur Cell.

\subsection{Les threads POSIX sur le Cell}
Sur un système Linux pour le Cell, le \emph{thread} principal s'exécute sur le PPE, celui-ci pouvant produire un ou plusieurs \emph{threads} sur le processeur. Une tâche peut contenir un ou plusieurs \emph{threads} Linux qui peuvent s'exécuter soit sur le PPE soit sur les SPEs. Un \emph{thread} qui s'exécute sur le SPE possède son propre contexte incluant un banc de registre de 128 x 128-bit, un compteur de programme et une file d'attente de commandes MFC, et il peut communiquer avec d'autres unités d'exécution au travers de l'interface des canaux MFC. Un \emph{thread} PPE peut interagir directement avec un \emph{thread} SPE via sa mémoire locale ou son espace de \emph{problem state} ou indirectement via la mémoire centrale ou les routines la \emph{SPE Runtime Management Library}. L'OS définit le mécanisme et la politique d'ordonnancement pour les SPE disponibles, il est également responsable de la gestion des priorités entre les tâches, du chargement du programme de la notification des évenemments au SPEs ainsi que du support du \emph{debugger}.
Une API de gestion des \emph{threads} SPE similaire à la librairie POSIX a été conçue, dans le but de fournir à la fois un environnement de programmation familier et une flexibilité dans la gestion des SPEs. Cette API supporte à la fois la création et la terminaison des tâches SPE ainsi que l'exclusion mutuelle par des primitives de mise à jour atomiques. L'API peut accéder au SPE en utilisant un modèle virtuel dans lequel l'OS affecte dynamiquement les \emph{threads} aux SPEs dans l'ordre de leur disponibilité. Les applications, peuvent spécifier de manière optionnelle un masque d'affinités pour affecter les \emph{threads} a un SPE spécifique. Les dispositifs architecturaux de communication entre les \emph{threads} et de synchronisation (mailbox, signaux, etc...) peuvent être accédés via un ensemble d'appels système ou alors via l'application qui mappe un bloc de contrôle du SPE dans l'espace mémoire de l'application. Sur le Cell il existe trois blocs de contrôle du SPE, un accédé par l'application, un autre par l'OS et un troisième par un superviseur. Une interface accessible à l'utilisateur permet  la communication directe entre les processeurs SPEs ou PPE, ceci permet d'éviter des appels système couteux.\\
Lorsque l'application fait une requête de création de \emph{threads}, la librairie de \emph{threads} SPE envoie la requête à l'OS pour allouer un SPE et créer un \emph{thread} SPE à partir d'un fichier objet de format ELF (Executable and Linkable Format) intégré dans un exécutable Cell. Le \emph{miniloader} un programme SPE de 256-bit, charge la segment de code à exécuter sur le SPE, l'avantage de cette approche et d'une part d'éviter au PPE d'effectuer cette tâche et d'autre part de profiter du fait que les les transferts PPE-SPE quand il se font du côté SPE, sont nettement plus efficace grâce à une interface qui contient plus de canaux de communications. Le code à exécuter réside alors dans la mémoire locale des SPEs.
\begin{figure}[!htbf]
	\centering
	\includegraphics[scale =0.6]{Chapter2/figures/cell_compilation_process}
	\caption{Processus \emph{dual source} de génération de code exécutable pour le Cell}
  \label{fig_compprocess}
\end{figure}
\subsection{Processus de génération de code}
Dans le modèle de programmation décrit ci-dessus le processus de génération de code binaire exécutable sur le Cell est dit \emph{dual-source}. En effet, il existe deux code sources distincts, un code pour le SPE (spe.c sur la figure \ref{fig_compprocess})) qui contient le code exécuté sur le SPE. Un deuxième code source qui est celui s'exécutant sur le PPE contient le \emph{\emph{thread}} maitre qui gère les \emph{\emph{threads}} SPE. Le processus de génération de code exécutable est décrit dans la figure \ref{fig_compprocess}. Dans la première étape le code SPE est compilé ce qui donne un binaire exécutable SPE. Celui-ci est par la suite traité par un outils spécifique \emph{spu-embedd} qui permet de transformer ce binaire en bout de code qui peut être enfouis dans l'exécutable du PPE. Cette procédure se fait par l'outil d'édition de lien qui considère alors le code SPE comme une librairie dont le code objet doit être intégré dans l'exécutable final.
\section{Conclusion}
Le processeur Cell possède une architecture parallèle hétérogène complexe. Il renferme plusieurs dispositifs qui font de son architecture un concentré de technologies parallèles. Plusieurs formes de parallélisme y sont présentes et à plusieurs niveaux. L'architecture mémoire quand à elle, est similaire à celle d'un DSP embarqué. Cette hiérarchie mémoire distribuée nécessite une gestion explicite pour son exploitation efficace.
La programmation par \emph{threads} sur le Cell est le modèle de base pour la mise en ouvre de code parallèle sur cette architecture. Il est caractérisé par une API très bas niveau qui permet en même temps de garder un contrôle précis sur le déroulement de son application et d'avoir une grande flexibilité en terme de choix de déploiement d'un algorithme donné. Grâce au dispositifs architecturaux de signalisation et de synchronisation, l'interface est rendue très efficace en terme de performance sur le Cell. Toutefois, du point de vue du programmeur, la mise en oeuvre du code est surement plus laborieuse que pour d'autres modèles de programmation, mais celle-ci peut être justifiée dans le cadre de fortes contraintes sur les temps d'exécution ou dans le cas ou le modèle de calcul SPMD n'est pas adapté à l'application déployée.\\
Au vu des contraintes de programmation énoncées ci-dessus, d'autres outils de programmation pour le Cell ont été développés. Ils se basent sur l'API de base et fournissent des outils de plus haut-niveau plus faciles à prendre en main par le développeur. La question qui se pose alors est celle de la garantie de la performance et de la flexibilité d'utilisation de ces outils par rapport à l'API de base.