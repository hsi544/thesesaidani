%\begin{quote}
%\emph{"I think games are an interesting application area, but quite clearly, Cell is not just for games.  There are many other areas it can be used.  Games are the thing that inspired us to do it.}\\
%Peter Hofstee, chief architect of the Cell processor
%\end{quote}
\indent Le processeur Cell est une architecture unique en son genre car elle renferme une multitude de dispositifs dédiés au calcul haute-performance. Son architecture parallèle à plusieurs niveaux permet aux utilisateurs aguerris d'atteindre des performances jusque là réservées aux seuls clusters de machines et utilisant des paradigmes de haut niveau tels que le \emph{message-passing}. En ce sens l'architecture du Cell, destinée initialement au domaine des jeux vidéos, a trouvé d'autres débouchés notamment dans le calcul scientifique au sens large.\\
\indent Le Cell est composé d'un processeur PowerPC classique nommé PPE (Power Processor Element) et de huit unités de calcul accélératrices appelées SPE (\emph{Synergestic Processor Element}). Ces unités de calcul sont reliées par un bus interne qui permet également l'accès  la mémoire principale (\emph{Main Storage}), ainsi qu'à  d'autres périphériques externes. Le processeur Cell est considéré comme un processeur hétérogène car il comporte deux types d'architectures différentes : celle du PPE qui n'est autre qu'une déclinaison du PowerPC 970 et celle des SPE qui sont des unités SIMD accélératrices spécialisées dans des traitements contenant un flot de données important comme le multimédia par exemple. Les jeux d'instructions vectorielles des SPE est très proche d'Altivec, présent sur les architectures de type PowerPC \\
\section*{Aperçu de l'architecture}
\begin{figure}[!htbf]
	\centering
	\includegraphics[scale =0.65]{Chapter2/figures/cell_fig01_bw}
	\caption{Vue d'ensemble de l'architecture hétérogène du processeur Cell}
  \label{cell_fig1}
\end{figure}
Le processeur Cell est la première implémentation de l'architecture \emph{Cell Broadband Engine} (CBEA), qui est entièrement compatible avec l'architecture \emph{PowerPC} 64-bit. Ce processeur à été initialement conçu pour la console de jeux \emph{PlayStation 3} mais ses performances hors normes ont très vite fait de lui un bon candidat pour d'autres domaines d'applications qui requièrent une grande puissance de calcul, comme le traitement du signal et des images.\\
Le processeur Cell est une machine multi-coeurs hétérogène, capable d'effectuer une quantité de calcul en virgule flottante considérable, sur des données occupant une large bande-passante. Il est composé d'un processeur 64-bit appelé \emph{Power Processor Element} (PPE), huit co-processeurs spécialisés appelés \emph{Synergistic Processor Element} (SPE), un contrôleur mémoire haute-vitesse et une interface de bus à large bande-passante. Le tout intégré sur une seule et même puce.\\
Le PPE et les SPEs communiquent au travers d'un bus interne très rapide appelé \emph{Element Interconnect Bus} (EIB) (Fig. \ref{cell_fig1}). Si l'on considère une fréquence d'horloge de 3.2 GHz, le processeur Cell peut atteindre théoriquement une performance crête de 204.8 GFlop/s en simple-précision (32-bit) et 14.6 GFlop/s en double-précision (64-bit). Il est important de noter que sur la première génération le débit des instructions arithmétiques en double-précision était d'une instruction tous les 7 cycles ce qui explique les 14.6 GFlop/s. Ce débit à été amélioré pour atteindre 1instruction/cycle sur la dernière génération \emph{PowerXCell 8i}, ce qui donne 102.4 GFlop/s. \\
%Le bus interne supporte une bande passante qui peut aller jusqu'à 204.8 Go/s pour les transferts internes à la puce (impliquant le PPE, les SPEs, la mémoire et les contrôleurs I/O). le contrôleur mémoire: \emph{Memory Interface Controller} (MIC) fournit une bande-passante de 25.6 Gbytes/s vers la mémoire principale. Le contrôleur I/O quand à lui fournit 25 Gbytes/s en entrée et 35 Gbytes/s en sortie.\\
%Le rôle du PPE est celui d'un chef d'orchestre. Il prend en charge l'OS (\emph{Operating System}) et coordonne les SPEs. Au niveau de l'architecture c'est un \emph{PowerPC} 64-bit classique avec une extension SIMD, un cache L1 de 32 Ko (données et instructions) et un cache L2 de 512 KB. C'est un processeur à exécution dans l'ordre (\emph{in-order execution processor}), il supporte le \emph{dual-issue} (parallélisme d'instructions) ainsi que le multi-threading d'ordre 2 (parallélisme de tâches).\\
%Chaque SPE est composé d'une SPU (\emph{Synergistic Processor Unit}) et d'un MFC (\emph{Memory Flow Controller}). Le MFC contient à son tour un contrôleur DMA (\emph{Direct Access Memory}), une unité de gestion de la mémoire (MMU), une unité interface de bus, et une unité atomique pour la synchronisation avec les autres SPEs et le PPE. Le SPU est un processeur de type RISC avec un jeu d'instructions et une micro-architecture conçus pour les applications flot de données haute-performance ou de calcul intensif. Le SPU inclut une mémoire locale de 256 Ko qui contient les données et les instructions. Le SPU ne peut pas accéder directement à la mémoire principale mais par le biais de commandes DMA via le MFC qui permettent de lire et d'écrire dans la mémoire principale. Les deux unités MFC et SPU sont indépendantes ce qui permet l'exécution des tâches de calcul et de transferts en parallèle sur le SPE.\\
%l n'existe pas de mécanisme hardware tel que la mémoire cache pour la gestion automatique des mémoires locales, et celles-ci doivent être gérées par le software. Le MFC effectue des commandes DMA pour transférer entre la mémoire centrale et les mémoires locales. Les instructions DMA pointent des emplacements de la mémoire centrale en utilisant des adresses virtuelles compatibles \emph{PowerPC}. Les commandes DMA peuvent transférer des données à partir de n'importe quel emplacement lié au bus d'interconnexion (mémoire principale, la mémoire locale d'un autre SPE, ou un périphérique I/O). Des transferts SPE vers SPE en parallèle sont faisables à raison de 16 \emph{bytes} par cycle d'horloge SPE, tandis que la bande-passante de la mémoire centrale est de 25.6 Gbytes/s pour le processeur entier.\\
%Chaque SPU contient 128 registres SIMD de taille 128-bits. Cette quantité importante de registres facilite l'ordonnancement efficace des instructions ainsi que d'autres optimisations comme le déroulage de boucle (loop-unrolling).\\
%Toutes les instructions SIMD sont des instructions que le pipeline peut exécuter à 4 granularités: 16 entiers 8-bit, 8 entiers 16-bit, 4 entiers 32-bits ou flottants simple-précision. Le processeur SPU est un processeur à exécution dans l'ordre (\emph{in-order-execution processor}), il possède deux pipelines d'instructions connus sous les dénominations pair (\emph{even}) et impair (\emph{odd}).\\
%Les instructions flottantes et entières sont dans le pipeline \emph{even} alors que le reste est dans le pipeline \emph{odd}. Chaque SPU peut lancer et compléter jusqu'à deux instructions par cycle, une par pipeline. Toutes les instructions flottantes en simple-précision peuvent être lancées en un cycle d'horloge du processeur. Par contre les instructions flottantes en double-précision ne sont pipelinées que partiellement, il en résulte un débit d'exécution moindre (deux instructions double-précision tous les 7 cycles d'horloge SPU).\\
%Si l'on prend une instruction de multiplication accumulation en flottant simple-précision (qui compte pour deux opérations) les 8 SPEs peuvent exécuter un total de 64 opérations par cycle \cite{kahle_2005}.\\
\subsection*{Le PPE:  Power Processor Element}

Le PPE est un processeur 64-bit compatible avec l'architecture Power, optimisée au niveau de l'efficacité énergétique. La profondeur de pipeline du PPE est de 23 étages, chiffre qui peut paraitre faible par rapport au précédentes architectures PowerPC surtout quand on sait que la durée de l'étage est réduite d'un facteur 2. Le PPE est une architecture dual-issue (deux instructions peuvent être lancées par cycle) qui ne réordonnance pas dynamiquement les instructions  (exécution dans l'ordre). Les instructions arithmétiques simples s'exécutent et fournissent leur résultat en deux cycles. Les instructions de chargements (\texttt{LOAD}) s'exécutent également en deux cycles. Une instruction flottante en double précision s'exécute en dix cycles. Le PPE supporte une hiérarchie conventionnelle de caches avec un cache L1 (de niveau 1) données et instructions de 32 Ko, et un cache L2 de 512 Ko.\\
Le processeur lance deux \emph{threads} simultanément et peut être vu comme un processeur double-coeur avec un flot de données partagé, ceci donne l'impression au logiciel d'avoir deux unités de traitement distinctes. Les registres sont dupliqués mais pas les caches qui sont partagés par les deux \emph{threads}. Les instructions provenant de deux \emph{threads} de calcul différents sont entrelacées, afin d'optimiser l'utilisation de la fenêtre d'exécution.\\
Le processeur est composé de trois unités : l'unité d'instructions (UI) responsable du chargement, décodage, branchements, exécution et complétion des instructions. Une unité d'exécution des opérations en arithmétique point-fixe (XU) qui est également responsable des instructions \texttt{LOAD/STORE}. Et enfin l'unité VSU qui exécute les instructions en virgule flottante ainsi que les instructions vectorielles. Les instructions SIMD dans le PPE sont celle des générations précédentes de PowerPC 970 et effectuent des opérations sur des registres 128-bit de données qui donnent un parallélisme de 2, 4, 8 ou 16, selon le type de données considéré.

\subsection*{Les SPE (Synergistic Processing Element)}
Le SPE contient un jeu d'instructions nouveau mais qui n'est autre qu'une version réduite du jeu d'instructions SIMD VMX, mais optimisé au niveau de consommation d'énergie et des performances pour les applications de calcul intensif et de multimedia. Le SPE contient une mémoire locale de 256 Ko (\emph{scratchpad}) qui est une mémoire de données et d'instructions. Les données et les instructions sont transférées de la mémoire centrale vers cette mémoire privée au travers de commandes DMA qui sont exécutées par le MFC (Memory Flow Controller) qui est présent dans chaque SPE. Chaque SPE peut supporter jusqu'à16 commandes DMA en suspens. L'unité DMA peut être programmée de trois manières différente: 1) avec des instructions sur le SPE qui insèrent des commandes DMA dans la file d'attente; 2) par la programmation de transferts permettant de faire des accès sur des zones non contiguës de la  mémoire au travers d'une liste de DMA, ce qui permet de définir un ensemble de transferts contigus de tailles différentes; 3) par l'insertion d'une commande DMA dans la file d'attente d'un autre processeur par les commandes de DMA-write.\\
Afin de faciliter la programmation et de permettre des transferts entre SPEs, les mémoires locales sont dupliquées en mémoire centrale. La présence des mémoires locales introduit un autre niveau dans la hiérarchie mémoire au dessus des registres. Les temps d'accès de ces mémoires sont de l'ordre du cycle ce qui en fait de bons candidats pour réduire la latence d'accès  la mémoire centrale qui est de l'ordre du millier de cycles, d'autant plus que le fait que le contrôleur DMA soit indépendant de l'unité de calcul, donne un niveau de parallélisme supplémentaire. La présence de ces mémoires privées permet à différents modèles de programmation d'être appliqués au processeur Cell.\\
La mémoire locale est le composant le plus important en taille du SPE, et il était important de l'implémenter de manière efficace. Une mémoire SRAM à un seul port est utilisée pour réduire la surface. En dépit du fait que la mémoire locale doit arbitrer entre lectures ou écritures DMA, chargements d'instructions, lecture mémoire et écriture mémoire, celle-ci a été conçue avec de ports de lecture moyens (128-bits) et larges (128 octets) dans le but de toujours fournir la meilleure performance possible. Le port le plus large est utilisé pour les commandes DMA et le chargement d'instructions. Cela est du au fait qu'une commande DMA de 128 octets requiert 16 cycles d'horloge pour placer les données sur le bus cohérent du Cell même lorsque les commandes DMA s'exécutent avec une bande passante maximale. Ainsi, 7 sur 8 cycles d'horloge restent disponibles pour les \emph{loads}, \emph{stores} et les chargements d'instructions. De la même manière, les instructions sont chargées par morceaux de 128 octets et la pression sur la mémoire locale est par conséquent réduite. La plus haute priorité est donnée au commandes DMA, la seconde plus haute priorité aux commandes \emph{load} et \emph{store}, le chargement ou préchargement des instructions n'est fait que lorsqu'il y a des cycles disponibles. Toutefois, une instruction qui force la disponibilité d'une fenêtre d'exécution pour le chargement d'instructions existe.\\
Les unités d'exécution du SPE sont organisées autour un flot de données 128 bits. Un banc de 128 registres fournit assez d'entrées pour permettre à un compilateur de réorganiser des groupes d'instructions afin de masquer la latence d'exécution des instructions. Il n'y a qu'un seul banc de registres et toutes les instructions sont SIMD 128 bits avec une largeur d'élément différente selon le type (2x64 bits, 4x32 bits, 8x16 bits, 16x8 bits et 128x 1 bit). Jusqu'à deux instructions sont lancées par cycle :  une fenêtre d'exécution supporte les instructions en virgule fixe et flottante et l'autre exécute les instructions \emph{load} et \emph{store} les permutations ainsi que les instructions de branchement. Les opérations entières simples prennent deux cycles, les opérations sur des flottants simple-précision et les instructions \emph{load} prennent 6 cycles. Les instructions vectorielles en flottants double-précision sont également supportées et leur débit maximal est d'une instruction tous les 7 cycles pour la première génération du Cell, et 1 cycle pour la dernière génération. Toutes les autres instructions sont entièrement pipelinées quelque soit la génération du processeur.\\
Afin de limiter la complexité du matériel dédié à la prédiction de branchement, le programmeur ou le compilateur peuvent par eux même fournir une prédiction de branchement. L'instruction de prédiction de branchement informe le matériel de l'adresse cible de branchement à venir, et le matériel répond en préchargeant au moins 17 instructions à partir de l'adresse cible de branchement. Une instruction de masque de sélection par bits peut également être utilisée afin d'éviter les branchements conditionnels dans le code. La surface dédiée aux unités de contrôle ne représente alors que 10 à 15 \% de la surface totale de 10 $mm^{2}$ du SPE. Le SPE ne dissipe que très peu de watts tout en opérant à une fréquence de 3.2 GHz.
%L'ensemble des spécificités des SPEs citées auparavant rendent la programmation de ces derniers fastidieuse. Les instructions arithmétiques des SPEs sont exclusivement vectorielles :  le calcul se fait forcément sur des registres de 128 bits et l'accès à la mémoire doit se faire avec un alignement multiple de 16 octets. Le jeu d'instructions est assez restreint comparé à ses prédécesseurs. En effet le calcul flottant est privilégié au détriment des instructions en nombres entiers souvent suffisantes pour notre domaine d'application. Cela réduit considérablement le degré de parallélisme et  par conséquent le potentiel d'accélération sur ces processeurs.
%La nature distribuée des mémoires locales des SPEs est aussi une particularité dont on à l'habitude sur les systèmes embarqués. En effet, l'espace mémoire sur le Cell n'est pas partagé entre les processeurs mais distribué sur les SPEs qui contiennent chacun une mémoire privée dont l'espace d'adressage est séparé de celui du PPE qui adresse la mémoire externe. La gestion de cet espace mémoire limité est faite de manière explicite par le programmeur sans qu'il ne soit assisté par un cache matériel comme c'est le cas sur les architectures \emph{SMP} à mémoire partagée. Ce dernier aspect, qui complique le travail du programmeur sur le Cell est d'autant plus crucial pour le traitement d'images car le flux de données y est souvent très important et la gestion de la mémoire est un des facteurs clés pour l'obtention de performances optimales sur ce type d'algorithmes.

\subsection*{Architecture de communication}
Afin de tirer partie de toute la puissance de calcul enfouie dans le Cell, la charge de travail doit être distribuée et coordonnée entre le PPE et les SPEs. Les mécanismes spécifiques de communication du processeur permettent la collection et la distribution des données ainsi que la coordination d'activité concurrentes, de manière efficace entre les unités de calcul. Puisque le SPE ne peut directement agir que sur des données et des instruction présents dans sa mémoire locale, chaque SPE possède un contrôleur DMA qui effectue des transferts à au débit entre la mémoire locale et la mémoire principale du Cell. Ces contrôleurs DMA permettent également des transferts directs entre les mémoire locale de deux SPEs dans le cas d'un schéma de calcul du type pipeline ou producteur consommateur.\\
Par ailleurs, le SPE peut utiliser les signaux out les \emph{mailboxes} pour effectuer des opérations de signalisation avec le PPE ou d'autres SPE. Il existe également d'autre mécanismes de synchronisation disponibles sur le SPE qui opèrent de la même manière que les instructions atomiques des processeurs PowerPC. En réalité les opérations atomiques sur le SPE interagissent avec celle du PPE pour construire des mécanismes de synchronisation telle que les sémaphores entre PPE et SPE. Enfin, le Cell permet d'accéder à toute les ressources du SPE ainsi qu'à l'intégralité de la mémoire locale ce dernier par le biais d'une zone de la mémoire centrale réservée cet effet. Cette variété de mécanismes de communication permet aux programmeurs d'implémenter différents modèles de programmation pour des application parallèles.

\subsection*{Bus d'interconnection d'éléments \emph{EIB}}
La figure \ref{fignoc} illustre le \emph{EIB}, le coeur d'architecture de communication du processeur Cell et qui permet la communication entre le PPE, les SPEs, la mémoire centrale, et les entrées/sorties externes. 
Le \emph{EIB} possède des chemins données séparés pour les commandes (requêtes à partir ou vers un éléments sur le bus) et les données. Chaque élément du bus est connecté avec une liaison point à point au concentrateur d'adresses, qui reçoit et coordonne les commandes des éléments du bus.


\subsection*{Gestion de la mémoire}
Dans une application pour le processeur Cell, plusieurs SPEs peuvent partager un espace mémoire commun avec les threads PPE. En même temps, d'autres SPEs peuvent référencer des espaces mémoire virtuels associés à des applications qui s'exécutent de manière concurrente sur le système. Le support de cette fonctionnalité est assuré par l'unité de gestion mémoire (\emph{Memory Management Unit}) qui permet de traduire les adresses système lors de la requête. Le contrôleur participe aux protocoles de cohérence de la mémoire afin d'assurer la cohérence des tables de pages.\\
Chaque contrôleur peut être programmé pour effectuer des transferts mémoire soit à partir du SPE en insérant une commande dans la file d'attente locale soit à partir d'un noeud distant. Le contrôleur mémoire peut également participer à des opérations de synchronisation de la mémoire et des threads. Un mécanisme de liste de transferts est également supporté par le contrôleur qui permet d'englober une séquence de transferts au sein d'une même commande.

\subsection*{Contrôleur de flot mémoire (\emph{Memory Flow Controler})}
Afin d'accéder aux données globales partagées par les threads s'exécutant sur le PPE et ceux exécutés sur le SPE, chaque SPE contient un contrôleur de flot mémoire, qui effectue des transferts entre la mémoire système et les mémoire privées des SPEs. Le contrôleur mémoire fournit au SPEs l'accès à la mémoire système par le biais des transferts DMA entre celle-ci et les mémoire locales des SPE. Les tailles des blocs de transfert varient entre un octet et 16 Ko. Une requête de transfert spécifie l'adresse locale du SPE à partir de l'adresse physique dans le SPE. L'adresse mémoire système est elle spécifiée par une adresse virtuelle qui est traduite en adresse physique par le contrôleur mémoire en se basant sur les tables de pages.    


\subsection*{Le bus interne (Element Interconnect Bus)}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= \columnwidth]{Chapter2/figures/cellnoc}
  \caption{Réseau d'interconnexion du Cell d'après \cite{cellnoc}}
  \label{fignoc}
\end{figure}
Le bus interne du processeur permet de relier les unités de traitement PPE, SPE  la fois entre elles,  la mémoire centrale ainsi qu'aux sorties externes. Le bus contient des chemins de données différents de ceux des requêtes. Les éléments autour du bus sont connectés par des liaisons point-à-point et un arbitre de bus est responsable de la réception des commandes et de leur diffusion vers les unités. Le bus est constitué de quatre anneaux d'une largeur de 16-octets, deux fonctionnent dans le sens d'une aiguille d'une montre et les deux autres dans le sens inverse. Chaque anneau peux potentiellement gérer 3 transferts en parallèle si toutefois leurs chemins ne se croisent pas. Le EIB opère à une fréquence qui est la moitié de celle du processeur, chaque unité du bus peut simultanément envoyer et recevoir 16 octets par cycle d'horloge du bus.

\subsection*{Programmabilité et modèles de programmation}
\label{prog_models}
Si l'innovation dans l'architecture matérielle peut permettre d'atteindre de nouveaux niveaux de performances et/ou efficacité énergétique, il va de soit que l'effort fournit pour améliorer les performances doit être raisonnable. La programmabilité du Cell à été un souci pour ces concepteurs dès ces débuts, il ont essayé de rendre le système de plus programmable possible et accessible au plus grand nombre. Mais il est clair que le aspects architecturaux qui sont les plus difficile à appréhender par les programmeurs sont ceux qui renferment le grand potentiel d'amélioration des performances. L'existence de la mémoire locale et le fait que celle-ci doit être gérée par le logiciel est un bon exemple de verrou technologique. Cette gestion peut éventuellement être confiée à un compilateur mais la tâche peut être complexe suivant le cas d'utilisation.
Le second aspect de la conception qui affecte la programmabilité est la nature SIMD du flot de données. Le programmeurs peut ignorer cet aspect là de l'architecture, mais en faisant abstraction de celui-ci une grande partie de la performance est laissée de côté. Il faut noter, que comme pour les applications qui s'exécutent sur des processeurs classiques sans utiliser leur unités SIMD, le Cell peut être programmé comme un processeur scalaire. La nature SIMD des SPEs est gérée par les programmeurs et supportée par les compilateurs de la même manière que pour les processeur possédant des unités SIMD.\\
Le SPE diffère des processeurs par plusieurs aspects : la taille du banc de registres (128 entrées), la manière dont les branchement sont gérés et d'autres instructions qui permettent de synchroniser la mémoire locale  avec le lancement des instructions. Ces aspects peuvent être utilisées par un compilateur pour l'optimisation, et le programmeur à intérêt à en avoir connaissance afin de tirer profit aux maximum des dispositifs de l'architecture, mais en tout état de cause il n'est pas nécessaire de programmer les SPEs en assembleur. Une autre différence majeure qui distingue les SPEs des processeurs conventionnels est le fait qu'il ne puissent supporter qu'un seul contexte de programme à la fois. Ce contexte peut être un thread dans une application ou un thread dans un mode privilégié, qui étend le système d'exploitation. Le processeur Cell supporte la virtualisation et permet à plusieurs systèmes d'exploitation de s'exécuter de manière concurrente au dessus d'un logiciel de virtualisation s'exécute en mode hyperviseur.\\
L'intégration d'un processeur de contrôle compatible avec l'architecture PowerPC  permet au Cell d'exécuter les applications Power et PowerPC 32 et 64 bits sans aucune modification. Toutefois, l'utilisation des SPEs est nécessaire pour atteindre les performances et profiter pleinement de l'efficacité énergétique du Cell. L'ensemble des dispositifs de communication et de transfert de données permet d'imaginer plusieurs modèles de programmation possible pour le Cell. Par exemple il est possible d'utiliser le SPE comme coprocesseur sur lequel on décharge une partie du calcul afin de l'accélérer. Plusieurs changement à l'architecture ont été effectuée pour des raisons de programmabilité. Des programmes de test, des bibliothèque de calcul, des extensions de systèmes d'exploitation ont été écrits, analysés vérifiés sur un simulateur fonctionnel avant la finalisation de l'architecture et de l'implémentation du Cell. Certains des modèles de programmation les plus communs sont décrit ci-dessous :
\subsubsection*{Modèle de décharge de fonction}
Ce modèle peut être le plus rapide à mettre en oeuvre tout en bénéficiant du fort potentiel de performances du Cell. Dan ce modèle de programmation, les SPEs sont utilisés comme des accélérateurs de certaines fonctions critiques. L'application principale peut être une application existante ou une nouvelle application qui s'exécute sur le PPE. Dans ce modèle les fonctions critiques invoquées par le programme principal sont remplacées par des fonctions qui s'exécutent sur un ou plusieurs SPEs. La logique du programme principal reste inchangée. La fonction originale est optimisée et recompilée pour le SPE, et l'exécutable SPE généré est intégré au programme PPE dans une section en lecture seule avec la possibilité de l'invoquer à distance. Le programmeur détermine statiquement les portions des codes à exécuter sur le PPE et celles à décharger sur les SPEs. Un compilateur single-source à été conçu par IBM  basé sur des directives de compilation qui permettent de décharger le calcul sur les SPE sur une portion délimitée du code. Une des évolutions les plus significatives que pourrait connaitre les compilateurs étant de pouvoir déterminer automatiquement les portions à déporter sur les SPEs.
\subsubsection*{Modèle d'accélération du calcul}
Ce modèle est centré sur le SPE : il fournit une utilisation plus importante du SPE par l'application que le modèle de décharge de fonction. Le modèle est mis en oeuvre en effectuant les tâches de calcul intensif sur les SPEs. le code source PPE agit essentiellement comme serveur et unité de contrôle pour les SPEs. Les techniques de parallélisation peuvent être utilisées pour répartir le calcul sur les SPEs. La charge de travail peut être partitionnée manuellement par le programmeur ou parallélisée automatiquement par un compilateur. Ce partitionnement doit inclure un ordonnancement efficace des opération DMA pour le mouvement des données et du code entre les SPEs. Ce modèle de programmation peut se base sur une mémoire partagée ou sur un système par passage de message. Dans plusieurs situations, le modèle d'accélération de calcul peut être utilisé pour fournir une accélération pour des fonctions mathématiques de calcul intensif sans que le code ne soit modifié de manière significative.
\subsubsection*{Modèle de calcul par flux}
Comme mentionné auparavant, les SPE peuvent se baser sur un système par passage de message pour faire un calcul en parallèle. Il est donc très simple de mettre en ouvre des pipeline séquentiels ou parallèles, dans lequel chaque SPE effectue un calcul distinct sur les données qui transitent par lui. Le PPE peut alors agir comme contrôleur de flux et les SPE comme des processeur de flux de données. Lorsque les SPE ont une charge de travail équivalent ce modèle peut s'avérer très efficace sur le Cell, à partir du moment où les données résident le plus longtemps possible dans les mémoire internes du SPE. Dans certains cas il peut être plus efficace de faire migrer le code plutôt que les données d'un SPE à un autre au lieu du mouvement de données plus conventionnel
\subsubsection*{Modèle à mémoire partagée}
Le processeur Cell peut être programmé comme un multi-processeur à mémoire partagée ayant des unités avec des jeux d'instructions différents qui permettent de couvrir un spectre de tâches qu'un seul jeu d'instruction ne peut pas couvrir. Le PPE et les SPEs peuvent interagir dans modèle à mémoire partagée complètement cohérent. Les \emph{load} conventionnels en mémoire partagée sont remplacés par une combinaison d'opérations DMA de la mémoire partagée vers la mémoire locale SPE, en utilisant une adresse effective commune au PPE et aux SPEs, et un \emph{load} de la mémoire locale vers le banc de registres. Les opération conventionnelles du type \emph{store} sont remplacées par une combinaison d'un \emph{store} du banc de registres vers la mémoire locale et une opération DMA de la mémoire locale vers la mémoire partagée en utilisant le même mécanisme d'adressage que pour le \emph{load}. On peut alors imaginer un compilateur utilisant les mêmes mécanismes pour utiliser la mémoire locale des SPEs comme un cache de données et d'instructions lues à partir de la mémoire partagée. 

%====================================================== THREADS POSIX ======================================================================================================================================
%\section{Les threads POSIX}
%Les \emph{threads} POSIX\footnote{Portable Operating System Interface for Unix} ou \emph {Pthreads} sont une standardisation\cite{pthreads_std} du modèle de programmation par \emph{threads} pour les systèmes UNIX. Ce modèle est basé sur une API de programmation parallèle qui permet la gestion des \emph{threads} ainsi que la synchronisation par \emph{mutex} ou variables conditionnelles. Historiquement, les concepteur de \emph{hardware} ont développé leurs implémentations propriétaires des \emph{threads}, ceci a rendu la portabilité du code des programmeurs quasi impossible. La nécessité d'une API standard est donc devenue vitale, c'est pour cette raison que la majorité des vendeurs de \emph{hardware} possèdent actuellement leur implémentation standard des \emph{threads} POSIX. Les \emph{Pthreads} sont définis autour d'un ensemble de procédures et de types en langage C contenus dans le fichier d'entête \texttt{"pthread.h"}.\\
%D'une manière générale un \emph{thread} est un flux d'instructions pouvant s'exécuter de manière indépendante sur un OS donné. Du point de vue du programmeur ceci s'apparente à une procédure qui peut s'exécuter indépendamment du programme principal, un programme contenant des procédures de ce type est dit \emph{multi-threaded}. Afin de détailler le principe de fonctionnement des \emph{threads} il est nécessaire de faire un rappel sur les \emph{process} UNIX. Un \emph{process} est créé par l'OS est contient un certain \emph{overhead} qui consiste en certaines ressources nécessaires à son exécution. Les \emph{threads} résident à l'intérieur de ces ressources et sont capables d'être ordonnancés et exécutés en tant qu'entités indépendantes car ils ne dupliquent qu'une partie des ressources qui leurs permettent d'être des morceaux de code exécutables. Le flot de contrôle est rendu indépendant car le \emph{thread} possède ses propres : pointeur de pile, registres, propriétés d'ordonnancement (priorité et politique), ensemble de signaux et données spécifiques. En somme, un \emph{thread} existe dans un \emph{process} dont il utilise les ressources. Il possède son propre flot de contrôle et ne duplique que les ressources nécessaires à son exécution indépendante. Il peut partager les ressources du \emph{process} avec d'autres \emph{threads} et s'exécuter en coordination avec ces derniers. La complexité due à sa création et à sa gestion est légère comparativement à celle du \emph{process} et sa durée de vie est celle de son \emph{process} parent.
%\subsection{l'API pthread}
%L'API des \emph{threads} POSIX peut être décomposée en trois types de routines:
%\begin{itemize}
%\item \textbf{Les routines de gestion des \emph{threads}} : comprends les tâches de création, propriétés d'exécution et terminaison des \emph{threads}.
%\item \textbf{Les \emph{mutex}} (abréviation de \emph{mutual exclusion}): ils permettent de synchroniser les \emph{threads}, les routines gèrent la création, destruction, réservation et libération des \emph{mutex}.
%\item \textbf{Les variables conditionnelles} : ces dernières gèrent la communication entre des \emph{threads} qui partagent les \emph{mutex}. Elles sont basées sur des conditions fixées par le programmeur, elles incluent des fonctions de création, destruction, attente et signalisation basées sur certaines valeurs de ces variables. 
%\end{itemize}
%\rule{\textwidth}{0.2mm}\\
%\subsubsection{Gestion des threads}
%\begin{itemize}
%\item \textbf{Création et Terminaison des \emph{threads}}: Initialement le programme contient un seul \emph{thread} qui est le \texttt{main()}. Les autres \emph{threads} doivent être créés explicitement par le programmeur. \texttt{pthread\_create} créé un nouveau \emph{thread} et le rend exécutable, un exemple de code à base de \emph{Pthreads} est donné dans le listing \ref{pthreadcode}. Cette routine peut être appelée autant de fois que l'on veut et à n'importe quel endroit dans le code. Le nombre de \emph{threads} maximal créé par un \emph{process} dépend de l'implémentation. Une fois créés les \emph{threads} peuvent créer à leur tour d'autres \emph{threads} et il n'existe aucune dépendance ni hiérarchie entre les \emph{threads}. Le \emph{thread} est crée avec certains attributs par défaut, ceux-ci pouvant être changés ultérieurement. Il existe plusieurs manières de terminer un \emph{thread} : soit par le \emph{thread} lui même qui le fait par un \texttt{return} de sa routine principale ou par la fonction \texttt{pthread\_exit()}, ou alors par un autre \emph{thread} en utilisant \texttt{pthread\_cancel()} et enfin en cas de terminaison du \emph{process} parent.
%\item \textbf{Passage d'Arguments au \emph{threads}} : On peut passer un argument au \emph{thread} via la routine \texttt{pthread\_create()}. On peut également passer plusieurs arguments en les rassemblant dans une structure et en passant l'adresse de celle-ci.
%\item \textbf{Jonction et Détachement des \emph{threads}} : La jonction est une manière de faire une synchronisation entre les \emph{threads}, la fonction \texttt{pthread\_join()} bloque le \emph{thread} appelant jusqu'a ce que le \emph{thread} appelé termine son exécution. Le caractère joignable ou pas d'un \emph{thread} est spécifié à sa création : s'il est créé en tant que \emph{thread} détaché il ne pourra pas être joignable. La routine \texttt{pthread\_detach()} sert à détacher un \emph{thread} qui était joignable à sa création.
%\item \textbf{Gestion de la Pile} : Le standard ne définit pas la taille par défaut de la pile du \emph{thread}, celle-ci dépend de l'implémentation. Toutefois, le programmeur peut en spécifier la taille ainsi que l'emplacement de la mémoire dans laquelle elle doit être stockée.
%\end{itemize}

%\subsubsection{Les variables \emph{mutex}}
%Les \emph{mutex} sont un des principaux mécanismes de synchronisation de \emph{threads}. Ils permettent par exemple de synchroniser des \emph{threads} ou alors de protéger des données partagées en cas d'écriture simultanée. Un \emph{mutex} peut être réservé (\emph{lock}) par un seul \emph{thread} à un moment donné, le propriétaire du \emph{mutex} est le seul à le posséder : tout autre \emph{thread} qui essaye de réserver ce même \emph{mutex} échoue jusqu'à ce que le propriétaire le libère (\emph{unlock}). Il existe des routines de création et de destruction des \emph{mutex}, la réservation des \emph{mutex} se fait soit par appel à la routine \texttt{pthread\_\emph{mutex}\_lock()} (bloquant), \texttt{pthread\_\emph{mutex}\_trylock()} (non bloquant) et se libère par \texttt{pthread\_\emph{mutex}\_unlock()}. Parmi les exemples d'utilisation des \emph{mutex} on peut citer les cas de \emph{race condition} où plusieurs \emph{threads} essayent de mettre à jour une variable globale, il est nécessaire dans ce genre de situation de protéger cette variable par un \emph{mutex} afin que celle-ci ait la même valeur du point de vue de tous les \emph{threads}. On dit alors que l'on crée une \emph{section critique}.
%===============================Listing Pthreads =======================================
%\lstset{ %
%language=C,                % choose the language of the code
%basicstyle=\footnotesize,       % the size of the fonts that are used for the code
%backgroundcolor=\color{light-gray},  % choose the background color. You must add \usepackage{color}
%showspaces=false,               % show spaces adding particular underscores
%showstringspaces=false,         % underline spaces within strings
%showtabs=false,                 % show tabs within strings adding particular underscores
%frame=single,			% adds a frame around the code
%tabsize=2,			% sets default tabsize to 2 spaces
%captionpos=b,			% sets the caption-position to bottom
%breaklines=true,		% sets automatic line breaking
%breakatwhitespace=false,	% sets if automatic breaks should only happen at whitespace
%escapeinside={\%*}{*)}  ,        % if you want to add a comment within your code
%caption = Exemple de code \emph{Pthread} basique montrant les routines de création de \emph{threads},
%label = pthreadcode
%}
% \lstinputlisting{Chapter2/Code/pthreadexample.c}
%===================================================================================
%\subsubsection{Les variables de condition}
%Les variables de condition fournissent aux \emph{threads} une autre manière de se synchroniser. Contrairement aux \emph{mutex} qui sont basés sur le contrôle de l'accès à une variable, la synchronisation par variable de condition se fait selon une valeur spécifique. Les variables de condition sont utilisées en conjonction avec les \emph{mutex}. L'appel à la fonction \texttt{pthread\_cond\_wait()} bloque le \emph{thread} appelant jusqu'à ce que la condition spécifiée est signalée. Cette routine doit être appelée tant que le \emph{mutex} est réservé et libère automatiquement le \emph{mutex} quand elle est en attente. Une fois que le signal est reçu, le \emph{thread} est réveillé et le \emph{mutex} est réservé automatiquement pour être utilisé par le \emph{thread}. La responsabilité de libérer le \emph{mutex} est à la charge du programmeur qui le fait une fois que son utilisation n'est plus nécessaire. La fonction \texttt{pthread\_cond\_signal()} est utilisée pour signaler (ou réveiller) un autre \emph{thread} qui est en attente de la variable de condition. Elle doit être appelée après que le \emph{mutex} est réservé et doit libérer le \emph{mutex} dans l'ordre pour permettre à \texttt{pthread\_cond\_wait()} de s'achever. Il existe une routine nommée \texttt{pthread\_cond\_broadcast()} qui met en attente plusieurs \emph{threads} en même temps. 

\section*{Environnement de développement de base}
L'environnement de développement fourni par IBM est le \emph{Cell Software Development Kit (Cell SDK)}. Plusieurs versions ont vu le jour, la première était la 1.0 qui a précédé la livraison des premières puces Cell, l'exécution du code se faisait alors sur un simulateur du processeur. La dernière version du SDK connue à ce jour est la 3.0. La description qui suit est basée sur la version antérieure 2.1 du SDK. L'environnement de développement contient les composants suivants : 
\begin{itemize}
\item \textbf{La chaîne d'outils GNU : } Cette chaîne contient le compilateur \emph{gcc} (\emph{GNU C-language Compiler}) pour le PPE et le SPE. Les deux compilateurs peuvent effectuer de la \emph{cross} compilation sur des plateformes x86. 
\item \textbf{Le compilateur IBM XL C/C++ : } C'est le compilateur conçu par IBM pour le processeur Cell. Il contient également deux compilateurs spécifiques, un pour le PPE; l'autre pour le SPE. La \emph{cross} compilation est également possible avec les compilateurs \emph{XLC} . La présence de deux chaînes de compilateurs distinctes s'explique par le fait que \emph{gcc} est destiné à la communauté \emph{Open Source} et dépend de sa contribution, alors que le compilateur \emph{XLC} est développé et commercialisé par IBM. Dans nos travaux nous avons pu utiliser les deux compilateurs. \emph{XLC} se distingue de \emph{gcc} par la gestion d'OpenMP et un code généré plus efficace sur le PPE et le SPE.
\item \textbf{IBM full-system simulator : } Le simulateur du Cell est une application logicielle qui émule le comportement d'un système complet contenant un processeur Cell. Un système d'exploitation linux est géré par le simulateur. On peut ainsi, exécuter des application pré-compilées sur le simulateur. Il existe plusieurs modes de simulation possibles, du mode purement fonctionnel, au mode précis au cycle près (\emph{cycle accurate}).
\item \textbf{Noyau Linux : } C'est le noyau Linux pour le Cell qui supporte notamment l'exécution parallèle sur les SPEs. Il est développé et maintenu par le \emph{Barcelona Supercomputer Center}. Celui-ci s'exécute sur le PPE qui peut gérer un système d'exploitation alors que les SPEs sont des coprocesseurs dédiés au calcul intensif.
\item \textbf{La bibliothèque de gestion du support d'exécution SPE : } Cette bibliothèque constitue l'API bas-niveau standard pour la programmation d'applications pour le Cell, en particulier pour l'accès au SPEs. La bibliothèque fournit une API neutre vis à vis des systèmes d'exploitation et la manière dont ils gèrent les SPEs, à travers une interface standard très proche de POSIX.
\end{itemize}
Nous avons cité ci-dessus les principaux composants du SDK que nous avons utilisé lors du développement des applications sur le processeur Cell. D'autres composants sont fournis avec le SDK : des bibliothèques de calcul mathématique et numérique optimisées pour le Cell, de utilitaires de mesure de performance ainsi qu'un \emph{plugin} pour l'environnement de développement Eclipse spécifique au développement sur le processeur Cell.

\subsection*{Les threads POSIX sur le Cell}
Sur un système Linux pour le Cell, le \emph{thread} principal s'exécute sur le PPE. Un \emph{thread} PPE peut contenir un ou plusieurs \emph{threads} Linux qui peuvent s'exécuter soit sur le PPE soit sur les SPEs. Un \emph{thread} qui s'exécute sur le SPE possède son propre contexte incluant un banc de registre de 128 x 128-bit, un compteur de programme et une file d'attente de commandes MFC, et il peut communiquer avec d'autres unités d'exécution au travers de l'interface des canaux MFC. Un \emph{thread} PPE peut interagir directement avec un \emph{thread} SPE via sa mémoire locale ou à travers un espace alloué en mémoire principale nommé\emph{problem state space}, ou encore indirectement via la mémoire centrale ou les routines la \emph{SPE Runtime Management Library}. L'OS définit le mécanisme et la politique d'ordonnancement pour les SPE disponibles, il est également responsable de la gestion des priorités entre les tâches, du chargement du programme de la notification des évenemments au SPEs ainsi que du support du \emph{debugger}.
Une API de gestion des \emph{threads} SPE similaire à la librairie POSIX a été conçue, dans le but de fournir à la fois un environnement de programmation familier et une flexibilité dans la gestion des SPEs. Cette API supporte à la fois la création et la terminaison des tâches SPE ainsi que l'exclusion mutuelle par des primitives de mise à jour atomiques. L'API peut accéder aux SPEs en utilisant un modèle virtuel dans lequel l'OS affecte dynamiquement les \emph{threads} aux SPEs dans l'ordre de leur disponibilité. Les applications, peuvent spécifier de manière optionnelle un masque d'affinités pour affecter les \emph{threads} à un SPE spécifique. Les dispositifs architecturaux de communication entre les \emph{threads} et de synchronisation (mailbox, signaux, etc...) peuvent être accèdés via un ensemble d'appels système ou alors via l'application qui mappe un bloc de contrôle du SPE dans l'espace mémoire de l'application. Sur le Cell il existe trois blocs de contrôle du SPE, un accédé par l'application, un autre par l'OS et un troisième par un superviseur. Une interface accessible à l'utilisateur permet  la communication directe entre les processeurs SPEs ou PPE, ceci permet d'éviter des appels système couteux.\\
Lorsque l'application fait une requête de création de \emph{threads}, la librairie de \emph{threads} SPE envoie la requête à l'OS pour allouer un SPE et créer un \emph{thread} SPE à partir d'un fichier objet de format ELF (Executable and Linkable Format) intégré dans un exécutable Cell. Le \emph{miniloader} un programme SPE de 256-bit, charge la segment de code à exécuter sur le SPE, l'avantage de cette approche et d'une part d'éviter au PPE d'effectuer cette tâche et d'autre part de profiter du fait que les les transferts PPE-SPE quand il se font du côté SPE, sont nettement plus efficace grâce à une interface qui contient plus de canaux de communications. Le code à exécuter réside alors dans la mémoire locale des SPEs.
\begin{figure}[!htbf]
	\centering
	\includegraphics[scale =0.6]{Chapter2/figures/cell_compilation_process}
	\caption{Processus \emph{dual source} de génération de code exécutable pour le Cell}
  \label{fig_compprocess}
\end{figure}
\subsection*{Processus de génération de code}
Dans le modèle de programmation décrit ci-dessus le processus de génération de code binaire exécutable sur le Cell est dit \emph{dual-source}. En effet, il existe deux code sources distincts, un code pour le SPE (spe.c sur la figure \ref{fig_compprocess})) qui contient le code exécuté sur le SPE. Un deuxième code source qui est celui s'exécutant sur le PPE contient le \emph{\emph{thread}} maitre qui gère les \emph{\emph{threads}} SPE. Le processus de génération de code exécutable est décrit dans la figure \ref{fig_compprocess}. Dans la première étape le code SPE est compilé ce qui donne un binaire exécutable SPE. Celui-ci est par la suite traité par un outils spécifique \emph{spu-embedd} qui permet de transformer ce binaire en bout de code qui peut être enfouis dans l'exécutable du PPE. Cette procédure se fait par l'outil d'édition de lien qui considère alors le code SPE comme une librairie dont le code objet doit être intégré dans l'exécutable final.
\section*{Conclusion}
Le processeur Cell possède une architecture parallèle hétérogène complexe. Il renferme plusieurs dispositifs qui font de son architecture un concentré de technologies parallèles. Plusieurs formes de parallélisme y sont présentes et à plusieurs niveaux. L'architecture mémoire quand à elle, est similaire à celle d'un DSP embarqué. Cette hiérarchie mémoire distribuée nécessite une gestion explicite pour son exploitation efficace.
La programmation par \emph{threads} sur le Cell est le modèle de base pour la mise en ouvre de code parallèle sur cette architecture. Il est caractérisé par une API très bas niveau qui permet en même temps de garder un contrôle précis sur le déroulement de son application et d'avoir une grande flexibilité en terme de choix de déploiement d'un algorithme donné. Grâce au dispositifs architecturaux de signalisation et de synchronisation, l'interface est rendue très efficace en terme de performance sur le Cell. Toutefois, du point de vue du programmeur, la mise en oeuvre du code est surement plus laborieuse que pour d'autres modèles de programmation, mais celle-ci peut être justifiée dans le cadre de fortes contraintes sur les temps d'exécution ou dans le cas ou le modèle de calcul SPMD n'est pas adapté à l'application déployée.\\
Au vu des contraintes de programmation énoncées ci-dessus, d'autres outils de programmation pour le Cell ont été développés. Ils se basent sur l'API de base et fournissent des outils de plus haut-niveau plus faciles à prendre en main par le développeur. La question qui se pose alors est celle de la garantie de la performance et de la flexibilité d'utilisation de ces outils par rapport à l'API de base.