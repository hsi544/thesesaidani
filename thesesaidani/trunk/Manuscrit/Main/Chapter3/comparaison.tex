Dans cette section, on se propose de comparer l'implementation du même algorithme de détéction de points d'interéts de Harris sur d'autres architectures parallèles émergentes utilisant eventuellement d'autres modèles de programmations que le processeur Cell. Les architectures considérées dans cette étude sont des architectures du type SMP à  mémoire partagée (Intel et PowerPC) ainsi que les cartes graphiques Nvidia et leur langage de programmation CUDA (\emph{Compute Unified Device Architecture}).

\subsection{Les Processeurs Multi-Coeurs}
Ce type de processeurs constitue aujourd'hui le \emph{main stream} en terme de conception d'architectures parallèles et est à  la fois le plus disséminé dans les machines grand public. Le parallélisme y est présent à  plusieurs niveaux, car ces architectures reprennent les concepts des architectures classiques mono-coeurs et dupliquent les coeurs afin d'obtenir un niveau de parallélisme supérieur. La mémoire y est généralement partagée et la hiérarchie mémoire et basée sur plusieurs niveaux de caches communs ou pas. Les modèles et outils de programmations utilisés pour tirer profit du parallélisme de ces architectures sont les librairie de \emph{threads} \emph{Pthread} ainsi que les directives de compilation \emph{OpenMP}. En ce qui concerne les optimisations bas-niveau comme celles au niveau des instructions ou certaines optimisations SIMD, elles sont généralement bien gérés par les compilateurs modernes.

\subsection{Les GPU Nvidia et CUDA}
Les cartes graphiques (\emph{GPU}) on connu ces dernières années un essor particulier, car elles ont subi une véritable révolution dans leur domaine d'utilisation. Les premiers pas du \emph{GPGPU} (\emph{General-Purpose computing on Graphics Processing Units }) ont consisté en l'utilisation de langages de rendu graphique, \emph{Cg} par exemple, pour en faire un usage plus généraliste, à savoir le calcul intensif pour des domaines applications qui relèvent plus du \emph{HPC}.  Cette première évolution à démontré que l'architecture des processeurs graphiques était bien adaptée au calcul intensif, mais le détournement des langages graphiques pour un usage généraliste était trop complexe pour le développeur habitué à programmer en langages C/C++. La définition d'un modèle de programmation approprié est alors devenu une évidence pour les constructeurs de cartes graphiques, mais aussi une grande opportunité pour eux de concurrencer les constructeurs de processeurs généralistes sur leur propre terrain.\\
CUDA (\emph{Compute Unified Device Architecture}) de Nvidia est sans doute la plus importante des initiatives dans ce sens. En effet, CUDA constitue un écosystème complet de programmation parallèle sur les architectures des cartes graphiques. Il définit à la fois une architecture matérielles constituée d'un ensemble de processeurs parallèles organisés en Multi-processeurs SIMD et une hiérarchie mémoire adaptée au problèmes massivement parallèles, similaires aux traitements caractérisant le rendu graphique avancé. Un modèle de programmation propriétaire CUDA, a été développé pour l'exploitation de ce parallélisme. Celui-ci se décline sous forme de plusieurs outils de programmation : 
\begin{itemize}
\item Une extension au langage C définissant de nouveaux types et mots clés propres aux architectures CUDA.
\item Une API Runtime permettant l'exécution d'un modèle haut-niveau de programmation basé sur le parallélisme de donnée.
\item Une API Driver permettant un contrôle plus fin de l'application mais aux prix d'une programmation plus verbeuse que celle de l'API de Runtime.
\end{itemize}

\subsection{Comparaison des Architectures Matérielles}
Au delà des performances intrinsèques sur un algorithme donnée, obtenues sur une architectures données, il nous ai paru important de comparer dans un premier temps les architectures utilisées lors de la comparaison de l'algorithme de Harris sur les différentes plate-formes parallèles émergente. Cette comparaison peut se faite sous différentes critères mais les plus pertinents pour l'exploitation efficace du parallélisme sont les formes de parallélisme et la hiérarchie mémoire. Le tableaux \ref{compare_archi} contient cette comparaison.
Au delà des comparaisons contenu dans le tableau, il est important de noter que les architectures même si elles possèdent plusieurs points communs les architectures diffèrent par leur leur nature. Ainsi, les processeurs multi-core sont des machines complexes, capables de gérer un ou plusieurs systèmes exploitation en plus de tâches purement calculatoires, ceci explique leur architecture complexe qui permet d'avoir une généricité dans les tâches exécutées. Les GPU à l'opposé, ont été conçue initialement pour exécuter des tâches de rendu graphique 3D, leurs architectures sont intimement liées à ce domaine d'application et sont ainsi non adaptés à d'autres types d'applications  que celles massivement parallèle ne contenant pas de flot de contrôle complexe, elle ne peuvent fonctionner qu'avec la présence d'un processeur du type CPU. Le Cell enfin, est une architecture hétérogène qui tient plus des processeurs présents dans l'embarqué que des architectures HPC classiques. En effet, celui-ci a été conçu à l'image d'un DSP capable d'exécuter une quantité de calcul flottants en simple et double précisions tout en ayant l'avantage des systèmes embarqués temps réels au niveau de la garantie d'un temps d'exécution prédictible. Dans le domaine du traitement d'images la majorité des applications sont {Data Parallel} ce qui donne un avantage certains aux architectures GPU en terme d'adéquation avec les algorithmes, par contre certains facteurs comme les fréquences d'horloges ainsi que les contraintes des bus de transferts mémoire qui sont critiques dans notre domaine d'application, rétablissent un équilibre avec les autres types d'architectures.
\begin{table}
\centering
\begin{tabular}{|p{0.25\columnwidth}||p{0.25\columnwidth}|p{0.25\columnwidth}|p{0.25\columnwidth}|}
\hline
   Architetcure & \textbf{Multi-core} & \textbf{Cell BE} & \textbf{Nvidia CUDA} \\
  \hline
   \textbf{Type} & Homogène (SMP à mémoire partagée) & Hétérogène  (à mémoire distribuée) & SIMD (Stream Processors)\\
 \hline
 \textbf{Parallélisme d'Instructions} & oui & oui & non\\
 \hline
 \textbf{Parallélisme de Données} & oui & oui & oui\\
 \hline
 \textbf{Parallélisme de Tâches} &  oui & oui & non\\
 \hline
 \hline
\textbf{Hiérarchie Mémoire} & Partagée (Plusieurs Niveaux de Cache)  & Distribuée (Mémoire Privées dans SPE) & Hybride (Mémoire Partagée, Globale, Texture ... )\\
\hline
\textbf{Optimisation de la Mémoire} & Partagée (Plusieurs Niveaux de Cache)  & Explicite (programmation du DMA) & Explicite (Utilisation des différents niveaux mémoire)\\
\hline
\end{tabular}
\caption{Comparaison des Architectures}
\label{compare_archi}
\end{table}

\subsection{Comparaison des Modèles de Programmation}
Les modèles de programmation représentent l'interface entre le développeur et l'architecture matérielle qui lui permet d'exploiter pleinement les dispositifs de celle-ci. A ce titre, la comparaison de ces modèles de programmation entre les différentes plate-formes parallèles nous ai paru nécessaire. Il est évident que la comparaison ne peut pas permettre de dégager une architecture, ou un modèle de programmation idéaux, mais plutôt une adéquation entre un modèle et une architecture données ou encore une adéquation entre ce couple et un domaine d'application, dans notre cas le traitement d'images.

\begin{table}
\centering
\begin{tabular}{|p{0.33\columnwidth}||p{0.33\columnwidth}|p{0.33\columnwidth}|}
\hline
    \textbf{OpenMP} & \textbf{Multi-core} & \textbf{Cell BE} \\
 \hline
 \hline
 \textbf{Implémentation} & oui & oui \\
 \hline
 \textbf{Adéquation avec l'architecture} & 
                                                                          \begin{itemize} 
                                                                            \item Bonne au niveau mémoire (mémoire partagée)
                                                                            \item Les SMP sont plus faciles à gérer pour OpenMP
                                                                          \end{itemize} & 
                                                                                                                                                                               \begin{itemize}
                                                                                                                                                                                  \item Mauvaise au niveau mémoire (mémoire distribuée)
                                                                                                                                                                                  \item L'architecture hétérogène du Cell complique la répartition de charge
                                                                                                                                                                                \end{itemize} \\
 \hline
 \textbf{Exploitation du Parallélisme} & 
                                                                         \begin{itemize} 
                                                                           \item Parallélisme de Tâches 
                                                                           \item Parallélisme de Données 
                                                                           \item Vectorisation et Parallélisme d'instructions bien gérés par le compilateur
                                                                         \end{itemize}&                       
                                                                                                                                                                                                                          \begin{itemize}
                                                                                                                                                                                                                             \item Parallélisme de Tâches uniquement 
                                                                                                                                                                                                                             \item Vectorisation mal gérée par le compilateur
                                                                                                                                                                                                                          \end{itemize}\\
 \hline
 \hline
\textbf{Gestion de la mémoire} & Implicite (Gérée par le compilateur)  & Explicite (à la main par le programmeur) \\
\hline
\end{tabular}
\caption{OpenMP et les architectures parallèles}
\label{compare_models01}
\end{table}

\begin{table}
\centering
\begin{tabular}{|p{0.33\columnwidth}||p{0.33\columnwidth}|p{0.33\columnwidth}|}
\hline
    \textbf{PThreads} & \textbf{Multi-core} & \textbf{Cell BE} \\
 \hline
 \hline
 \textbf{Implémentation} & oui & oui \\
 \hline
 \textbf{Adéquation avec l'architecture} & 
                                                                          \begin{itemize} 
                                                                            \item Modèle plus flexible 
                                                                            \item Programmation très verbeuse
                                                                           \end{itemize} & 
                                                                                                                                                                               \begin{itemize}
                                                                                                                                                                                  \item A constitué pendant longtemps le seul outil de programmation pour le Cell
                                                                                                                                                                                  \item La flexibilité permet une exploitation plus riche de l'architecture
                                                                                                                                                                                \end{itemize} \\
 \hline
 \textbf{Exploitation du Parallélisme} & 
                                                                         \begin{itemize} 
                                                                           \item Détermination du parallélisme gérée par le programmeur
                                                                           \item Synchronisation gérée par le programmeur
                                                                           \item Vectorisation et optimisation bas-niveau 
                                                                         \end{itemize}&                       
                                                                                                                                                                                                                          \begin{itemize}
                                                                                                                                                                                                                             \item Parallélisme de Tâches uniquement 
                                                                                                                                                                                                                             \item Vectorisation mal gérée par le compilateur
                                                                                                                                                                                                                          \end{itemize}\\
 \hline
 \hline
\textbf{Gestion de la mémoire} & Implicite (Gérée par le compilateur)  & Explicite (à la main par le programmeur) \\
\hline
\end{tabular}
\caption{Pthreads et les architectures parallèles}
\label{compare_models02}
\end{table}

\begin{table}
\centering
\begin{tabular}{|p{0.5\columnwidth}||p{0.5\columnwidth}|}
\hline
    \textbf{CUDA} & \textbf{Architectures Nvidia CUDA} \\
 \hline
 \hline
 \textbf{Adéquation avec l'architecture} & 
                                                                          \begin{itemize} 
                                                                            \item Modèle dédié à l'architecture 
                                                                            \item Programmation de complexité intermédiaire
                                                                           \end{itemize}  \\
 \hline
 \textbf{Exploitation du Parallélisme} & 
                                                                         \begin{itemize} 
                                                                          \item Parallélisme de données uniquement
                                                                           \item Détermination du parallélisme gérée par le programmeur
                                                                           \item Synchronisation gérée par le programmeur
                                                                           \item Optimisations des transferts mémoire et du taux d'occupation des multiprocesseurs 
                                                                         \end{itemize}\\
 \hline
 \hline
 \textbf{Gestion de la mémoire} & Explicite (à la main par le programmeur) \\
\hline
\end{tabular}
\caption{CUDA et les Architectures Nvidia}
\label{compare_models03}
\end{table}

\subsubsection{Mise en oeuvre du code parallèle}
Un des poins critiques pour le passage d'un code d'une version séquentielle vers une version partiellement ou entièrement parallèle est celui du temps de développement nécessaire à cette tâche. Afin de simplifier la comparaison, on se pose dans le cas ou le code possède un fort potentiel de parallélisation et les portions de code exploitables ont été identifiés. L'hypothèse supplémentaires pour avoir une comparaison objective, est la possibilité d'exploiter la forme de parallélisme sur toute les architectures et avec les modèles de programmation associés. Dans notre cas, ceci est effectivement le cas, notre application exploitant essentiellement le parallélisme de données, qui est exploitable sur toutes les architectures et à la fois par OpenMP, Pthreads et CUDA.
\paragraph{Pthreads}
Le modèle de programmation par threads était présent dès les débuts de la programmation parallèle. C'est un modèle complexe de mise-en-ouvre car très proche de l'architecture. Celui-ci était pendant longtemps la seul alternative pour la programmation du processeur Cell, ce qui a rendu sa programmation fastidieuse, en plus des aspects de gestion explicite des transferts mémoire. La mise en oeuvre du code parallèle nécéssite un refonte complète du code et une attention particulière aux détails ce qui rallonge le temps de développement mais aussi de debug et de validation.

\paragraph{OpenMP}
OpenMP est une infrastructure basée sur des directives de compilation et une API de runtime permettant de masquer les aspects les plus désagréables des Ptheads. Celui-ci repose en effet sur les threads, tout en évitant au programmeur tout les aspects bas-niveau de la parallélisation. Il permet des temps de développement assez courts, si le code de base n'est pas très complexe. Il a également l'avantage de permettre de garder le code séquentiel dans sa forme originale.

\paragraph{CUDA}
 La programmation parallèle avec le langage CUDA sur les GPU est globalement accessible aux développeurs C/C++. La mise en oeuvre du code parallèle requière une modification du code original pour coller au modèle de programmation CUDA. Selon le finesse de contrôle souhaitée, la programmation est plus ou moins complexe. L'API de Runtime est plus haute en niveau d'abstraction que l'API Driver. La première est accessible aisément au programmeur et permet une mise ne oeuvre rapide. La seconde API plus bas niveau permet un contrôle plus fin de l'application au prix d'une programmation plus bas niveau et donc plus complexe.
 
\subsection{Architectures Matérielles et Environnement de Développement}
\subsubsection{Processeurs Multi-core}
  \begin{itemize}
    \item Bi-dual coeurs PowerPC G5 à 2.5 GHz (PPC970MP) : Compilateur GCC 4.2, Librairie Pthreads et OpenMP.
    \item Bi-quadri coeurs Intel Penryn à 3.0 GHz (X3370) :  Compilateur ICC 11.0, Librairie Pthreads et OpenMP.
   \end{itemize}

\subsubsection{Processeur Cell BE}
 \begin{itemize}
   \item Cell BE à 3.2 GHz : Compilateur PPU-GCC, SPU-GCC, Cell SDK 3.0Librairie Pthreads et OpenMP cbe-xlc.
  \end{itemize}

\subsubsection{Nvidia CUDA}
 \begin{itemize}
   \item Nvidia GeForce 8800 GTX à 575 MHz (128 stream cores) : Compilateur \textbf{\emph{nvcc}} Langage CUDA.
  \end{itemize}

\subsection{Mesure de Performance}
L'évaluation des performances s'est faite sur les tailles d'images allant de $128\times128$ jusqu'à $2048\times2048$. Les résultats sont donnés en $cpp$ ($cpp=\frac{temps*Frequence}{taille^ {2}}$). Les versions implémentées sont celles présentées auparavant dans la section \ref{parallel_schemes}
 
 \begin{table}
 \begin{tabular}{|p{0.16\columnwidth}||p{0.16\columnwidth}|p{0.16\columnwidth}|p{0.16\columnwidth}|p{0.16\columnwidth}|p{0.16\columnwidth}|}
\hline
\textbf{Architecture} & \textbf{Planar $p=1$} &\textbf{Planar $p=pmax$} & \textbf{Halfpipe $p=1$} & \textbf{Halfpipe $p=pmax$} & \textbf{Gain $p = pmax$}\\
\hline
\rowcolor {medium-gray} PPC970MP ($pmax = 4$)&   43 & 2.9 & Gain & *&* \\
\hline
Intel X3370 ($pmax = 8$)&   Planar & Halfpipe & Gain & *& *\\
\hline
\rowcolor {medium-gray}Cell BE ($pmax = 8$)&   Planar & Halfpipe & Gain &* &*\\
\hline
GeForce 8800 GTX  &   120 & 15 & Gain & *&* \\
\hline
\end{tabular}
 \caption{Comparaison des Implémentations de l'algorithme de Harris sur les Architectures Parallèles}
 \label{compare_perf_arch}
 \end{table}
 
 
 
 