--------------------------

Le processeur Cell possède une architecture parallèle hétérogène complexe. Il renferme plusieurs dispositifs qui font de son architecture un concentré de technologies parallèles. Plusieurs formes de parallélisme y sont présentes et à plusieurs niveaux. L'architecture mémoire quand à elle, est similaire à celle d'un DSP embarqué. Cette hiérarchie mémoire distribuée nécessite une gestion explicite pour son exploitation efficace.
La programmation par \emph{threads} sur le Cell est le modèle de base pour la mise en ouvre de code parallèle sur cette architecture. Il est caractérisé par une API très bas niveau qui permet en même temps de garder un contrôle précis sur le déroulement de son application et d'avoir une grande flexibilité en terme de choix de déploiement d'un algorithme donné. Grâce au dispositifs architecturaux de signalisation et de synchronisation, l'interface est rendue très efficace en terme de performance sur le Cell. Toutefois, du point de vue du programmeur, la mise en oeuvre du code est surement plus laborieuse que pour d'autres modèles de programmation, mais celle-ci peut être justifiée dans le cadre de fortes contraintes sur les temps d'exécution ou dans le cas ou le modèle de calcul SPMD n'est pas adapté à l'application déployée.\\
Au vu des contraintes de programmation énoncées ci-dessus, d'autres outils de programmation pour le Cell ont été développés. Ils se basent sur l'API de base et fournissent des outils de plus haut-niveau plus faciles à prendre en main par le développeur. La question qui se pose alors est celle de la garantie de la performance et de la flexibilité d'utilisation de ces outils par rapport à l'API de base.\\
-------------------------------
Dans ce chapitre nous avons mis en oeuvre la parallélisation de code de traitement d'images sur notre architecture parallèle. L'algorithme qui a été choisi est le détecteur de points d'intérêts de \emph{Harris} qui est à la fois représentatif des traitements bas-niveau, présent dans plusieurs traitements plus complexes et permet plusieurs schémas de parallélisation et d'optimisation. Plusieurs techniques d'optimisation on été présentées : certaines sont spécifiques au traitement du signal et des images et sont applicables à d'autres architectures. D'autres techniques sont plus spécifiques et relèvent de l'adéquation entre l'algorithme et l'architecture spécifique du processeur Cell. L'accent à été mis sur l'optimisation des transferts mémoire à plusieurs niveaux et de plusieurs manières, car elles constituent le principal facteur limitant la performance pour notre domaine d'applications. Plusieurs schémas de parallélisation ont été mis en oeuvre afin d'avoir une idée globale de squelette de parallélisation qui donne les meilleures performances. Les performances ont été mesurées de plusieurs manières et à différents niveau : au niveau des noyaux de calculs une estimation et une mesure des gains apportés par les optimisation bas-niveau ont été effectuées. Au niveau des transferts une mesure de la bande passante fut menée en fonction du schéma de parallélisation, et l'influence de la taille et de la forme de la tuile de calcul ont été étudiées. Enfin, des métriques de passage à l'échelle (\emph{Scalability}) ont été utilisées afin de mesurer l'efficacité de la parallélisation de notre algorithme sur le processeur Cell.
Les performances obtenues lors de cette étude ont été obtenues après un temps de développement important. Elles sont le fruit d'une méthodologie d'optimisation itérative et de l'acquisition d'une expertise sur l'architecture du Cell. Dans le cadre de développement d'applications industrielles, des contraintes de temps de livraisons et de maintenabilité du code se posent. L'outil de base n'est pas adapté pour répondre à de telles contraintes. C'est pour ces raisons là que des outils d'aide au portage de code sur le processeur Cell ont vu le jour.\\
-----------------------------------------
Dans ce qui précède nous avons décrit différents outils de programmation pour le processeur Cell. Ce chapitre, qui n'est pas une étude exhaustive, fait état des principaux outils qui ont fait objet de publications et d'évaluation significatives. Les outils diffèrent par le modèle de programmation sur lequel ils se basent. Les plus simples à utiliser, qui sont les approches à base d'annotation de code (OpenMP, CellSS), laissent le soin au compilateur de faire le travail de parallélisation et d'optimiser le code. De l'autre côté RapidMind et Sequoia adoptent une approche qui définit un langage spécifique accompagné d'un \emph{\emph{runtime}} et d'un compilateur, mais une bonne partie du travail d'optimisation est laissée à la charge du programmeur. Ces outils ont vu le jour pour faciliter la programmation sur le Cell, et fournir une alternative à la l'utilisation fastidieuse des \emph{pthreads} qui sont un outil de programmation parallèle très bas niveaux qui laisse une grande liberté au programmeur pour ce qui est du déploiement de son code et de son optimisation. Un code à base de \emph{\emph{threads} }  est de ce fait long à mettre en oeuvre est difficile à maintenir, mais il permet d'un autre  côté d'avoir un contrôle total sur son implémentation.
On notera que la mise en oeuvre à nécessité un grand effort de la part des concepteurs pour deux raisons principales: (1) la mémoire distribuée du Cell qui impose la gestion explicite des transferts mémoire à partir de et vers la mémoire centrale (2) Le PPE et les SPEs possèdent un jeux d'instructions différents ce qui rend difficile l'étape de génération de code.\\
L'ensemble des outils étudiés dans ce chapitre adoptent un modèle de programmation du type SPMD, qui ne permet d'exploiter que le parallélisme de données dans les applications. De plus, ces outils se basent sur les compilateurs fournis pour les tâches d'optimisation du code. Cette analyse a permis de mettre en avant le fait que ces outils ne soient pas adaptées à notre domaine d'application. Dans le chapitre qui suit nous présentons un outil de programmation pour le Cell que nous avons développé et qui apporte une approche de programmation différente, plus adaptée au traitement d'images et qui permet d'exploiter d'autres formes de parallélisme.\\
------------------------------------------------------
SKELL BE est une solution à base de langage spécifique au domaine enfouis dans C++. Cet outil est basé sur les squelettes algorithmiques, un modèle de programmation parallèle très flexible. Il est très adapté au processeur Cell car le placement du graphe d'application y est primordial pour la performance. Les résultats qui précèdent tendent à prouver que l'on obtient de bonnes performances tant au niveau temporel brut qu'au niveau du passage à l'échelle. Les mesures sur les benchmarks simples ont prouvé que le surcout induit est négligeable comparativement à un code écrit à la main. Le déploiement de l'algorithme de Harris sur le Cell à l'aide de SKELL BE selon plusieurs schémas de parallélisation,  permettent d'apprécier la flexibilité et l'expressivité fournies par l'outil. Les performances obtenues sur l'algorithme prouvent l'efficacité de SKELL BE sur une application de moyenne complexité.\\
Dans les chapitre précédents nous avons étudié le processeur Cell et ses contraintes de programmation. Nous avons également étudié le portage d'une application typique du traitement d'images sur cette architecture massivement parallèle. La question qui reste en suspens est alors celle des architectures parallèle concurrentes. A savoir, la détermination d'un couple outil/architecture qui soit le plus adapté à notre domaine d'application.\\ 
-------------------------------------------
Dans ce qui précède une comparaison sous plusieurs critères à été effectuée sur différentes architectures parallèles. Les différents modèles de programmation on été comparés en terme de rapidité de mise en oeuvre et d'adéquation avec les architectures matérielles. L'algorithme de détection de point d'intérêts de Harris à été utilisé pour comparer les architectures selon deux critères :  la performance temporelle pure ainsi que l'éfficacité énèrgétique.
Nous avons évalué les performances de notre algorithme de référence sur des architectures GPP, GPU et le Cell. A travers les métriques utilisées, il a été mis en évidence l'importance des transformations algorithmiques qui combinées aux instructions SIMD et à la parallélisation multicoeur font que les processeurs généralistes restent compétitifs face aux nouvelles architectures (Cell et GPU) un facteur $\times$90 a été atteint. Grâce à cela, ils dépassent les performances brutes du Cell. De plus, et contrairement au Cell, le nombre de coeurs des machines généralistes a réussi à croître rapidement : Intel et AMD annoncent des processeurs octocoeurs et des machines bi ou quadri-processeurs (soit un maximum de 32 coeurs).\\
Certains processeurs pour serveur sont déclinés en version basse-consommation, ce qui les rend plus compétitifs encore, tout en maintenant un modèle de programmation
simple et des temps de développement rapides.\\