Les travaux exposés dans ce manuscrit traitent de la problématique de parallélisation de code de traitement d'images sur le processeur Cell. Les détails de l'architecture particulière du Cell sont étudiés avec ses contraintes de programmation. Une méthodologie de portage de code aux travers d'un exemple d'implémentation d'un algorithme de traitement d'images bas-niveau. Les outils de programmation haut-niveau de l'architecture sont étudiés et un nouvel outil SKELL BE développé au cours de ces travaux est présenté.
Ce manuscrit contient également une comparaison de performances entre architectures parallèles sur le même algorithme de traitement d'images.

\section{Méthodologie de portage d'application de traitement d'images}
%Dans ce chapitre nous avons mis en oeuvre la parallélisation de code de traitement d'images sur notre architecture parallèle. L'algorithme qui a été choisi est le détecteur de points d'intérêts de \emph{Harris} qui est à la fois représentatif des traitements bas-niveau, présent dans plusieurs traitements plus complexes et permet plusieurs schémas de parallélisation et d'optimisation. Plusieurs techniques d'optimisation on été présentées : certaines sont spécifiques au traitement du signal et des images et sont applicables à d'autres architectures. D'autres techniques sont plus spécifiques et relèvent de l'adéquation entre l'algorithme et l'architecture spécifique du processeur Cell. L'accent à été mis sur l'optimisation des transferts mémoire à plusieurs niveaux et de plusieurs manières, car elles constituent le principal facteur limitant la performance pour notre domaine d'applications. Plusieurs schémas de parallélisation ont été mis en oeuvre afin d'avoir une idée globale de squelette de parallélisation qui donne les meilleures performances. Les performances ont été mesurées de plusieurs manières et à différents niveau : au niveau des noyaux de calculs une estimation et une mesure des gains apportés par les optimisation bas-niveau ont été effectuées. Au niveau des transferts une mesure de la bande passante fut menée en fonction du schéma de parallélisation, et l'influence de la taille et de la forme de la tuile de calcul ont été étudiées. Enfin, des métriques de passage à l'échelle (\emph{Scalability}) ont été utilisées afin de mesurer l'efficacité de la parallélisation de notre algorithme sur le processeur Cell.
%Les performances obtenues lors de cette étude ont été obtenues après un temps de développement important. Elles sont le fruit d'une méthodologie d'optimisation itérative et de l'acquisition d'une expertise sur l'architecture du Cell. Dans le cadre de développement d'applications industrielles, des contraintes de temps de livraisons et de maintenabilité du code se posent. L'outil de base n'est pas adapté pour répondre à de telles contraintes. C'est pour ces raisons là que des outils d'aide au portage de code sur le processeur Cell ont vu le jour.\\
\section{SKELL BE : programmation par squelettes algorithmiques}
%SKELL BE est une solution à base de langage spécifique au domaine enfouis dans C++. Cet outil est basé sur les squelettes algorithmiques, un modèle de programmation parallèle très flexible. Il est très adapté au processeur Cell car le placement du graphe d'application y est primordial pour la performance. Les résultats qui précèdent tendent à prouver que l'on obtient de bonnes performances tant au niveau temporel brut qu'au niveau du passage à l'échelle. Les mesures sur les benchmarks simples ont prouvé que le surcout induit est négligeable comparativement à un code écrit à la main. Le déploiement de l'algorithme de Harris sur le Cell à l'aide de SKELL BE selon plusieurs schémas de parallélisation,  permettent d'apprécier la flexibilité et l'expressivité fournies par l'outil. Les performances obtenues sur l'algorithme prouvent l'efficacité de SKELL BE sur une application de moyenne complexité.\\
%Dans les chapitre précédents nous avons étudié le processeur Cell et ses contraintes de programmation. Nous avons également étudié le portage d'une application typique du traitement d'images sur cette architecture massivement parallèle. La question qui reste en suspens est alors celle des architectures parallèle concurrentes. A savoir, la détermination d'un couple outil/architecture qui soit le plus adapté à notre domaine d'application.\\ 
\section{Comparaison avec d'autres architectures parallèles}
%Dans ce qui précède une comparaison sous plusieurs critères à été effectuée sur différentes architectures parallèles. Les différents modèles de programmation on été comparés en terme de rapidité de mise en oeuvre et d'adéquation avec les architectures matérielles. L'algorithme de détection de point d'intérêts de Harris à été utilisé pour comparer les architectures selon deux critères :  la performance temporelle pure ainsi que l'éfficacité énèrgétique.
%Nous avons évalué les performances de notre algorithme de référence sur des architectures GPP, GPU et le Cell. A travers les métriques utilisées, il a été mis en évidence l'importance des transformations algorithmiques qui combinées aux instructions SIMD et à la parallélisation multicoeur font que les processeurs généralistes restent compétitifs face aux nouvelles architectures (Cell et GPU) un facteur $\times$90 a été atteint. Grâce à cela, ils dépassent les performances brutes du Cell. De plus, et contrairement au Cell, le nombre de coeurs des machines généralistes a réussi à croître rapidement : Intel et AMD annoncent des processeurs octocoeurs et des machines bi ou quadri-processeurs (soit un maximum de 32 coeurs).\\
%Certains processeurs pour serveur sont déclinés en version basse-consommation, ce qui les rend plus compétitifs encore, tout en maintenant un modèle de programmation simple et des temps de développement rapides.\\
\section{Perspectives}
