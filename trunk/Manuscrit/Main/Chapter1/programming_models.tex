\section{RapidMind}
\textbf{RapidMind}[citer paper Rapidmind] est un modèle de programmation parallèle multi-plateformes, GPU, multi-coeur symétrique et pour le processeur Cell, il relève du modèle de programmation \emph{stream programming} et s'apparente à un langage de programmation enfoui dans C++. Il est basé sur la bibliothèque template C++ et une librairie de runtime qui effectué la génération dynamique de code. La librairie template permet l'invocation permet l'invocation de code SPE à l'intérieur du code PPE, avec l'ensemble du code SPE écrit en template.\\
La librairie template de \textbf{RapidMind} fournit un ensemble de types de données, des macros de contrôle, des opérations de réduction et des  fonctions communes qui permettent à la librairie de runtime de capturer une représentation du code SPE (retained code). Les types de données ont été spécialement conçus pour exprimer de manière simple les opérations SIMD et les exposer facilement à la librairie runtime. Le runtime à son tour extraits le parallélisme à partir de ces opérations  en vectorisant le code et en divisant les calculs sur les tableaux et les vecteurs sur les différents SPEs. Il peut également effectuer des optimisations de boucle comme les détection des invariants de boucle. \textbf{RapidMind} assigne des tâches aux SPEs dynamiquement et peut effectuer des optimisations à plus haut niveau comme la superposition des calculs et des transferts qui permet de masquer la latence de ces derniers. Enfin le modèle de calcul est un modèle SPMD, il diffère du modèle SIMD du fait que les programme peuvent contenir du flot de contrôle et que ce modèle puisse gérer une certaine forme de parallélisme de tâches même si étant initialement un modèle data-parallel.\\
\subsection{Modèle de Programmation et Interface}
L'interface est basée sur trois types C++ principaux: \textbf{\texttt{Value<N,T>}}, \textbf{\texttt{Array<D,T>}} et \textbf{\texttt{Program}}, tous sont des conteneurs, les deux premiers pour les données et le dernier pour les opérations. Le calcul parallèle est effectué soit en applicant des \textbf{\texttt{Program}} sur des \textbf{\texttt{Array}} pour créer de nouveaux \textbf{\texttt{Array}}, ou en applicant une opération collective parallèle qui peut être paramêtrée par un objet \textbf{\texttt{Program}} comme la réduction par exemple.\\
A première vue les types \textbf{\texttt{Value}} et \textbf{\texttt{Array}} ne sont pas une grande nouveauté. En effet, tout dévelopeur C++ a pour habitude d'utiliser les types N-tuples pour exprimer le calcul numérique sur des vecteurs, et le type \textbf{\texttt{Array}} est une manière usuelle d'encapsuler la vérification des valeurs limites (boundary checking). Toutefois ces types constituent une interface pour une machine parallèle puissante basée sur la génération dynamique de code. Ceci est rendu possible grâce au type \textbf{\texttt{Program}} qui est la principale innovation du modèle de programmation \textbf{RapidMind}. Un mode d'exécution symbolique \emph{retained} est utiliser pour collecter dynamiquement des opérations arbitraires sur les \textbf{\texttt{Value}} et les \textbf{\texttt{Array}} dans les objets \textbf{\texttt{Program}}.
\subsubsection{le type \textbf{\texttt{Value}}}
le type \textbf{\texttt{Value<N,T>}} est un N-tuple, les instances de ce type contiennent N valeurs de type T, ou T peut être un type numérique de base (un flottant simple ou double précision ou tout autre entier), les flottants 16-bits sont également supportés. Des notations courtes existent pour certaines tailles usuelle comme le \textbf{\texttt{Value4f}} pour un quarter de floats ou \textbf{\texttt{Value3ub}} pour un triplet d'entiers 8-bits non signés.\\
Les opérations arithmétiques standard et les opérations logiques sont surchargés pour les types tuples et opèrent composante par composante. Les fonctions de la bibliothèque standard  sont également supportées, comme les fonctions trigonométriques et logarithmiques. En plus des opérations arithmétiques, des opérations de réorganisation des données on été ajoutées au type value: ces opérations permettent la duplication d'une composante ou ou le réordonnancement des composantes. Par exemple, si \textbf{\texttt{a}} est une valeur de type \textbf{\texttt{Value<4, float>}} qui représente une couleur RGBA, a(2,1,0) est l'inverse représentant le triplet BGR.\\
Les calculs sont exprimés en utilisant les tuples de \textbf{\texttt{Value}} et les opérateurs sur ces types peuvent être utilisés directement pour exprimer du parallélisme SWAR (SIMD Within A Register). Les constructions C++ de modularité tels que namespaces, classes et fonctions.\\
\subsubsection{le type \textbf{\texttt{Array}}}
Le type \textbf{\texttt{Array<D,T>}} est également un conteneur de données. Ce qui le distingue du type \textbf{\texttt{Value}} est le fait qu'il peut être multidimensionnel et de taille variable. L'entier D représente la dimensionnalité (1,2 ou 3), le type T est le type des éléments du conteneur. Le type des éléments et pour le moment restreint aux instances du type \textbf{\texttt{Value<N,T>}}.\\
Les instances du type \textbf{\texttt{Array}} supportent les opérateurs "[]" et "()" pour l'accès aléatoire aux données. L'opérateur "[]" utilisé des entiers en arguments tandis que l'opérateur "()" utilise des coordonnées réelles comprises dans [0, 1] dans chaque dimension, cette particularité est utile par exemple pour les modes d'interpolation des images.\\
Les sous-tableaux peuvent être accèdés en utilisant les fonctions \textbf{slice}, \textbf{offset} et \textbf{stride}. Les effets de bords sont gérés en utilisant la fonction membre \textbf{boundary}, qui inclut différents modes de traitement pour les bords. les types \textbf{\texttt{Value}} et \textbf{\texttt{Array}} suivent une sémantique par valeurs qui permet d'éviter l'aliasing de pointeurs et simplifie la programmation et l'optimisation. Il existe également d'autres types de sous-tableaux, les références sur tableaux et les accèsseurs.
\subsubsection{le type \textbf{\texttt{Program}}}
Un objet \textbf{\texttt{Program}} contient une séquence d'opérations, ces opérations sont spécifiées par le passage en mode \emph{retained} qui est indiqué par la macro mot-clé \textbf{\texttt{BEGIN}}. Normalement, le système fonctionne en mode \emph{immediate}. Dans ce mode les opérations sur un tuple de valeurs s'exécutent à la spécification comme pour une bibliothèque matrice-vecteur classique:  les calculs sont effectués sur la même machine que le programme hôte et le résultat est sauvegardé dans le tuple \textbf{\texttt{Value}} de sortie. En mode \emph{retained} un nouvel objet \textbf{\texttt{Program}} qui est retourné par la macro \textbf{\texttt{BEGIN}} est crée. Les opérations dans ce mode ne sont pas exécutées; elles sont symboliquement évaluées et sauvegardées dans l'objet \textbf{\texttt{Program}}. La sortie du mode \emph{retained} est marquée par la macro \textbf{\texttt{END}}, qui ferme l'objet \textbf{\texttt{Program}} et le marque comme étant prêt à être compilé, étape à la suite de laquelle l'objet \textbf{\texttt{Program}} est utilisé pour le calcul. Les objets \textbf{\texttt{Program}} sont compilés de manière dynamique ce qui permet d'exploiter les caractéristiques bas-niveau de la machine cible.\\
Il est à noter que même si les types \textbf{RapidMind} sont des classes C++, le compilateur est plutôt assimilable à un compilateur FORTRAN et peut ainsi effectuer les mêmes optimisations agressives. Les fonctionnalités du langage C++ sont utilisées pour structurer les calculs et générer le code mais n'est pas utilisé lors de l'exécution.
\subsection{Evaluation Partielle et Algèbre du Programme}
Les objets \textbf{\texttt{Program}} sont des conteneurs d'opérations, et ces opérations peuvent être manipulées par le système de manière explicite. Cela permet l'implémentation de plusieurs dispositifs avancés de programmation.\\
En premier lieu, les \textbf{\texttt{Program}} peuvent être évalués partiellement. Si un objet \textbf{\texttt{Program}} \textbf{p} ayant \textbf{n} entrées, l'expression \textbf{p(A)} retourne un objet \textbf{\texttt{Program}} avec \textbf{(n-1)} entrées. En d'autres termes les entrées de l'objet \textbf{\texttt{Program}} ne sont pas obligatoirement fournies toutes en une fois. Il est possible de binder toutes les entrés d'un objet \textbf{\texttt{Program}} mais de différer son exécution effective. L'exécution d'un objet \textbf{\texttt{Program}} n'est déclenchée que quand il est affecté à un \emph{bundle}, \textbf{\texttt{Array}} ou \textbf{\texttt{Value}}. L'opérateur \textbf{"()"} est utilisé pour binder les entrées de l'objet \textbf{\texttt{Program}}. Ceci est appelé le \emph{tight binding}. Un changement de l'entrée après un \emph{tight binding}, n'affecte pas les entrées d'un \textbf{\texttt{Program}}, même si son exécution est différée. Dans l'exemple précédent, ou l'on crée \textbf{"p(A)"} et qu'on l'affect à un objet \textbf{\texttt{Program}} \textbf{"q"}, et qu'on modifie ensuite l'entrée \textbf{"A"}. Lors de l'exécution de \textbf{"q"}, celui-ci utilisera la valeur de \textbf{"A"} au moment du binding dans \textbf{"p"}, pas la valeur modifiée. Le \emph{tight binding} permet l'optimisation de l'objet \textbf{\texttt{Program}} basée sur les valeurs effectives dans l'entrée bindée.\\
Toutefois, le système supporte également le \emph{loose binding}, spécifié par l'opérateur \textbf{"<<"}. L'expression \textbf{"p<<A"} est similaire à \textbf{"p(A)"} sauf que les changements sur \textbf{"A"} sont visibles à m'exécution différée de \textbf{"p<<A"}.\\
Une entrée à un \textbf{\texttt{Program}} peut être bindée à un \textbf{\texttt{Array}} ou un tuple de \textbf{\texttt{Value}}. Si des arrays de tailles différentes sont bindées à un \textbf{\texttt{Program}} la plus petite entrée est répliquée suivant les conditions aux bords pour avoir la taille de l'entrée de l'entrée la plus grande.\\
Les \textbf{\texttt{Program}} peuvent être combinés pour créer de nouveaux \textbf{\texttt{Program}} en utilisant deux opérations: la composition fonctionnelle est le \emph{bundling}. Ces opérations forment une algèbre fermée dans l'ensemble des objets \textbf{\texttt{Program}}. L'opérateur de composition fonctionnelle \textbf("<<") quand il est appliqué à deux objets \textbf{\texttt{Program}} \textbf{"p"} et \textbf{"q"} \textbf{"p << q"} transmet toutes les entrées du \textbf{\texttt{Program}} à droite de l'opérateur à l'entrée de celui de gauche, il crée un nouvel objet \textbf{\texttt{Program}} ayant les entrées de \textbf{"q"} et les sorties de \textbf{"p"}. L'opérateur \emph{bundle} quand à lui utilise la fonction \textbf{"bundle"}. Cette fonction concatene toutes les entrées/sorties de ses arguments dans l'ordre et crée un nouvel objet \textbf{\texttt{Program}} équivalent à la concaténation des sources de ces \textbf{\texttt{Program}} d'entrée en séquence.\\
Ces opérations combinées avec la compilation dynamique permettent une amélioration considérable des performances surtout quand le programme est dominé par des instructions de mémoire.
\subsection{Les Opérations Collectives}
L'opération de base supportée est l'application parallèle d'un programme sur un tableau de données. Toutefois, d'autres patterns de communication et de calcul sont supportés sous la forme d'opérations collectives. Les patterns de communication irréguliers sont fournis par les opérations de \emph{scatter} et \emph{gather},et l'opération de réduction fournit un pattern de calcul hiérarchique.\\
L'opération\emph{gather} permet de récupérer des données résidant dans des emplacements non-contigus de la mémoire et l'opération \emph{scatter} l'écriture dans des zones de même nature. L'opération de réduction quand à elle est programmable, elle prend deux entrée et fournit une sortie. Elle permet par exemple de sommer les éléments d'un vecteur d'une manière hiérarchique.\\ \textbf{INSERER FIGURE REDUCTION}\\. On pourra noter que l'opérateur impliqué dans la réduction doit être associatif. Parmi les opérateurs qui ont été implémentés on peut citer \textbf{sum}, \textbf{product}, \textbf{min} et \textbf{max}.
\subsection{Spécificité du Backend pour le Cell de RapidMind}
L'implémentation de RapidMind pour le Cell possède certaines particularités qui tiennent compte de l'architecture particulière de ce processeur. Le parallélisme SWAR peut être mappé directement sur les registres SIMD du SPE mais les opérations de permutation de données ne sont pas implémentées de manière aussi efficace les unes que les autres. D'autre part la parallélisation qui consiste à appliquer un program à un tableau permet en théorie de faire des millions de calculs en parallèle, mais le Cell ne possède qu'un nombre d'unités de traitement. C'est pour cela que les données sont divisée en plusieurs paquets et transférées dans les mémoires locales des SPEs avant d'être traitées. Le triple buffering est utilisé pour cacher la latence des transferts DMA. Pour les accès mémoire non réguliers un software-cache est utilisé. Si les programmes incluent un flux de contrôle différents tâches peuvent prendre des temps d'exécution différents un système de \emph{load balancing} (équilibrage de charge). 
\subsection{Conclusion}
La plate-forme de développement RapidMind combine une interface basée sur la compilation dynamique et un modèle de calcul data-parallel. Elle peut être considérée soit comme une API de calcul parallèle ou un langage de programmation parallèle enfoui dans C++. Il supporte plusieurs niveaux de parallélisme notamment le parallélisme SWAR et le parallélisme SPMD. Le modèle de programmation est commun à plusieurs plate-formes GPU, multi-coeur et Cell. C'est un modèle de programmation assez simple à utiliser et qui repose en grande partie sur un compilateur C++ lui confère une grande popularité auprès des utilisateurs. Au niveau des performances on peut relever de bon résultats dans [citer articles] mais pour ce qui est de notre domaine d'applications qui est le traitement d'images, une analyse approfondie sera faite par la suite.
\section{OpenMP Cell pour le Compiltateur XL}
OpenMP pour le Cell intégré dans le compilateur XL d'IBM est basé sur les transformations du compilateur et une librairie de runtime. Le compilateur transforme de pragmas OpenMPen code source intermédiaire qui implémente les constructions OpenMP correspondantes. Ce code inclut des appels aux fonctions de la a la librairie de runtime du Cell. Cette dernière fournit des fonctionnalités basiques à OpenMP incluant la gestion des threads, la répartition de la charge de travail ainsi que la synchronisation.\\
Chaque segment de code compris dans une construction parallèle est listé par le compilateur dans une fonction séparée. Le compilateur insère les appels à la librairie de runtime OpenMP dans la fonction parente de la fonction listée. Ces appels aux fonctions de la librairie de runtime vont ainsi invoquer les fonction listées et gérer leur exécution.\\
Le framework est basé sur le compilateur IBM XL. Ce dernier possède des front-end pour C/C++ et FORTRAN, et contient la même infrastructure d'optimisation pour ces langages. Le framework d'optimisation se divise en deux composants TPO et TOBEY. TPO est chargé des optimisations haut niveau indépendantes de la machine cible tandis que TOBEY effectue les optimisations bas-niveau spécifiques à l'architecture.\\
Le compilateur résulte d'une adaptation de versions existantes du compilateur XL supportant OpenMP, mais la spécificité de l'architecture du Cell à posé quelques problématiques qui sont les suivantes:
\begin{itemize}
\item \textbf{Threads et Synchronisation}: les threads s'exécutant sur le PPE diffèrent de ceux du SPE en termes de capacité de traitement. Le système à été conçu pour prendre en compte la différence entre les deux architectures.
\item \textbf{Génération de Code}: Le jeu d'instruction du PPE diffère de celui du SPE. Il en résulte que l'optimisation du code PPE est faite séparément de celle du SPE. L'espace de stockage sur le SPE étant limité, le code SPE s'il excède cette capacité, peut être partitionné en sections binaires (\emph{overlays}) au lieu d'une section monolithique. De plus, les données partagées dans le code SPE nécessitent un transfert DMA de la mémoire centrale vers la mémoire locale. Ceci est fait soit par le compilateur qui insère explicitement des commandes DMA dans le code, soit par un mécanisme de software cache qui fait partie de la librairie de runtime du SPE.\\
\item \textbf{Modèle Mémoire}: le hardware du Cell assure que les transactions DMA sont cohérents, mais ne fournit pas de mécanisme de cohérence pour les données résidant dans la mémoire locale, le modèle mémoire de OpenMP implémenté assure une cohérence de données qui est requise par les spécifications.
\end{itemize}
Les sections qui suivent décrivent la manière avec laquelle ces problèmes ont été traités.
\subsection{Threads et Synchronisation}
les threads peuvent s'exécuter sur le PPE ou les SPE. Le thread maître est toujours exécuté sur le PPE. Ce thread est responsable de la création des autres threads, de la répartition et de l'ordonnancement des tâches, et des opérations de synchronisation. L'absence d'OS sur le SPE fait que le PPE gère toutes les requêtes OS. Cette répartition permet au SPE de se consacrer uniquement aux tâches de calcul.\\
Actuellement, un seul thread est sensé s'exécuter sur le PPE, est le nombre de threads parallèles exécutés sur les SPEs se déclare par la variable d'environnement OMP\_NUM\_THREADS. La création et synchronisation des threads est implementée les librairies du SDK (Software Development Kit). Le thread sur le PPE crée des threads SPE au runtime seulement quand les structures parallèles sont rencontrées pour la première fois.\\
Pour les niveaux de parallélisme nichés (boucles nichées), chaque thread dans la region parallèle la plus externe exécute séquentiellement la région parallèle interne. les itérations de boucles sont divisées en autant de morceaux qu'il y a de threads, avec un mécanisme d'ordonnancement et de synchronisation simplifié.Lorsque le thread SPE est crée, il effectue des initialisations et entre dans une phase d'attente d'affectation de tâches de la part du PPE, exécute ces tâches et se met en attente d'autres tâches, jusqu'à ce qu'il reçoive un signal de fin de tâches. Une tâche SPE peut être l'exécution d'une region parallèle listée (boucle ou section), ou alors l'exécution d'un flush de cache ou encore la participation à une opération de synchronisation par barrière.\\
Il existe une file d'attente dans la mémoire système correspondant à chaque thread. Quand le thread maître assigne une tâche à un thread, il écrit les informations sur la tâche à la file d'attente de tâche correspondante., incluant le type de tâche, les bornes supérieure et inférieure de la boucle parallèle, ainsi que le pointeur de fonction pour la région de code listée qui doit être exécutée. Une fois que le thread SPE prend une tâche de la file d'attente, il signale au thread maître que l'espace dans la file d'attente et à nouveau libre. Les mécanismes de synchronisation sont assurés au travers de mailbox qui permettent l'échange de messages bloquant ou non-bloquant entre le thread maître et les threads de calcul. Les locks OpenMP sont implémentés grâce au commandes DMA atomiques.
\subsection{Génération de Code}
En premier lieu, le compilateur sépare chaque région dans le code source qui correspond à une construction OpenMP parallèle, et la liste dans une fonction séparée. La fonction peut prendre des paramètres supplémentaires comme les bornes supérieure et inférieure de la boucle. Le compilateur insère un appel à la librairie de runtime OpenMP au niveau de la fonction parente de la fonction listée, et insère un pointeur dans cette fonction de la librairie de runtime. Le compilateur insère également des instructions de synchronisation quand c'est nécessaire.\\
Le fait que l'architecture du Cell soit hétérogène impose que les fonctions listées contenant des tâches parallèles soit clonnées afin d'être executables aussi bien par le SPE que le PPE. Le clonage est effectué quand le graphe d'appel global est disponible de telle sorte que le sou-graphe d'un appel à une fonction listée puisse être clonné entièrement. Le clonage permet aussi lors des étapes d'optimisation ultérieures d'effectuer des optimisations qui dépendent de l'architecture comme la vectorisation de code qui ne peut pas se faire dans une étape commune à cause des différences entre les jeux d'instructions SPU et VMX. Une table de mise en correspondance entre les versions PPE et SPE contient les pointeurs des fonctions listées de telle sorte à ce qu'il n'y ai pas de confusion lors de l'exécution.\\
A la fin de l'étape TPO, les procédures sur les différentes architectures sont séparées en deux unités de compilation différente et celles-ci sont traitées une par une par le back-end TOBEY.\\
L'unité PPE ne requière pas de traitement particulier. Par contre l'unité compilée SPE peut produite un binaire d'une taille importante et qui ne tiens pas dans la mémoire locale. Il existe deux approches pour remédier à ce problème. La première consiste au partitionnement de la section parallèle dans un programme en plusieurs sections de taille moindre et la génération d'un binaire distinct pour chaque sous section. Cette approche est limitée, d'une part par-ce-qu'une sous-section peut avoir une taille pas assez petite pour tenir dans la mémoire locale et d'autre part la complexité générée par la création et la synchronisation de plusieurs threads affecte considérablement les performances. \\
La deuxième approche qui est celle utilisée dans le compilateur IBM XL, est le partitionnement du graphe d'appel et les \emph{overlays} de code. Le code SPE est ainsi partitionné et un code \emph{overlays} est crée pour chaque partition. Ces \emph{overlays} partagent l'espace d'adresses mais n'occupent pas la mémoire locale en même temps. Un poids est affecté à chacun des arcs du graphe représentant la fréquence d'appels de la fonction. Le graphe d'appel est partitionné afin de maximiser cette fréquence d'appel dans une partition en utilisant l'algorithme du \emph{maximum spanning tree}. Le code SPE ainsi  généré est intégré dans le code PPE avant d'être exécuté.\\
\subsection{Modèle Mémoire}
OpenMP spécifie un modèle mémoire \emph{relaxed-consistency}, \emph{shared memory}. Ce modèle permet à chaque thread d'avoir sa propre vue temporaire de la mémoire. Une valeur écrite dans une variable, ou une valeur lue à partir d'une mémoire peut rester dans la vue temporaire du thread jusqu'à ce qu'elle soit obligée de partager la mémoire par une opération de flush OpenMP.\\
Ce modèle est adapté au Cell en tenant compte de la mémoire limitée des SPEs. Les données privées accédées dans le code SPE sont allouées en mémoire privée. Les variables partagées sont elles allouées en mémoire centrale et peuvent être accedées via DMA par les SPEs. Deux mécanismes distincts sont utilisés pour les transferts DMA: le static-buffering et le software-cache contrôlé par le compilateur. Dans les deux cas, les données globales peuvent avoir une copie dans la mémoire locale SPE.\\
Certaines références sont considérées comme étant régulières du point de vue du compilateur. Ces références interviennent dans les boucles, les adresses mémoires vers lesquelles elle pointent peuvent être exprimées en utilisant des expressions affines de variables d'induction de la boucle, et la boucle qui les contient ne possède aucune dépendance induite par la boucle (vraie, de sortie ou anti-dépendance) impliquant ces références. Pour ces références régulières aux données partagées, un buffer temporaire est utilisé dans le SPE. Des opération DMA \emph{get} et \emph{put} sont utilisées respectivement pour lire et écrire de et vers ce buffer à partir de la mémoire centrale.  Plusieurs buffers peuvent être utilisés afin de recouvrir les calculs par des transfers mémoire.\\
Pour les références irrégulières à la mémoire le software-cache est utilisé. Le compilateur remplace les \emph{\texttt{load}} et \emph{\texttt{store}} de et vers ces zones mémoire par des instructions qui vont chercher les adresses effectives, dans le directory du cache. Si une ligne de cache pour l'adresse effective est trouvée (\emph{cache hit}) la valeur dans le cache est utilisée. Dans le cas contraire (\emph{cache miss}) la donnée est récupérée en mémoire via un DMA \emph{get} dans le cas d'une lecture.\\
La taille de la ligne de cache (128 bytes) et son associativité (4) sont choisies respectivement pour optimiser les transfers DMA et exploiter le jeu d'instructions SIMD pour le calcul des adresses (4x 32-bits). Le système assure également au SPE l'accès à des données qui seraient dans la pile d'une fonction PPE qui appelle une fonction SPE.
\subsection{Conclusion}
Le modèle de programmation OpenMP intégré dans le compilateur IBM XL pour le processeur Cell est une approche qui a le mérite de permettre à l'utilisateur de réutiliser son code OpenMP existant, sans se soucier des détails de l'architecture de Cell. Le support d'OpenMP est assuré par des transformations du compilateurs couplés à une librairie de runtime. Les problématiques qui sont posées pour le portage d'OpenMP sur le Cell sont notamment celles de la synchronisation des threads, la génération de code et le modèle mémoire. La solution proposée est inovante car elle propose un compilateur qui permet de générer un seul binaire executable qui s'exécute sur des jeux d'instructions différents et sur un espace mémoire distribué. Les performances sur des benchmarks simples ainsi que sur des codes plus complexes donnés dans \textbf{citer papier OMP\_IWOMP} démontrent l'efficacité de l'outil en comparaison avec un code optimisé à la main.
\section{CellSS (Cell SuperScalar)}
CellSS est un environnement a pour objectif de fournir à l'utilisateur un outil de programmation simple mais qui donne des executables qui exploitent efficacement l'architecture du processeur Cell. Il découle d'un modèle de programmation nommé GRID[citer le papier GRID] qui assimile un processeur superscalaire à une grille de calcul: les unités fonctionnelles du processeur sont les ressources de la grille, les données contenues dans les registres correspondent aux fichiers dans la grille et les instructions assembleur sont assimilées aux tâches de calcul.\\
Cell SuperScalar est constitué de deux composantes clés un compilateur source-to-source et une librairie de runtime. Le processeur de génération de code est illustré dans la figure [Citer Figure]. Partant d'un code source séquentiel écrit en langage C, des annotations en CellSS sont insérées dans le code. Le compilateur source-to-source est utilisé pour générer deux fichiers C distincts. Le premier correspond au programme principal de l'application , il est compilé par un compilateur PPE qui crée un objet pour ce même processeur. Le deuxième code source correspond à celui exécuté par le SPE sous contrôle du PPE. Cet exécutable enfouis dans le binaire du PPE pour pouvoir être exécuté. Cette procédure est la même que celle utilisée par le SDK d'IBM qui est basé sur deux compilateur distincts et une phase d'intégration du code SPE dans celui du PPE.\\
L'exécution du programme est assurée par le PPE qui assigne les \emph{task} aux SPEs au travers de la librairie de runtime. Le runtime se charge de créer un noeud qui correspond à la \emph{task} dans un graphe, et vérifie la dépendance avec une autre \emph{task} lancée auparavant et ajoute un arc entre les deux. Si la \emph{task} courante est prête à être exécutée le runtime envoie une requête au SPE pour qu'il se charge de l'exécution. Les transferts DMA sont gérés par le runtime de manière transparente. Les appels au runtime ne sont pas bloquants et de ce fait si une \emph{task} n'est pas prête ou tous les SPEs sont occupés le programme principal continue sont exécution.\\
On pourra noter que tout le processus (assignation de tâches, analyse des dépendances, transfert de données) sont transparents du point de vue de l'utilisateur, qui écrit un code séquentiel dans lequel il annote la partie à exécuter par les SPEs . Le système peut changer dynamiquement le nombre de SPEs utilisés en prenant en compte le maximum de concurrence contenu dans l'application à chaque phase.
\subsection{Runtime}
Au runtime, des appels à une fonction \emph{Execute} sera responsable du comportement de l'application sur le processeur Cell. Pour chaque appel à la fonction \emph{Execute} le runtime effectue les actions suivantes:
\begin{itemize}
\item L'addition d'un noeud dans un graphe des tâches qui représente la tâche appelée.
\item L'analyse des dépendances de données de la nouvelle tâche avec les tâches appelées précédemment. Cette analyse prend comme hypothèse que deux paramètres sont les mêmes s'ils ont la même adresse. Les système cherche les types de dépendances de données \emph{RaW}, \emph{WaR} et \emph{WaW} \footnote{Read after Write, Write after Read and Write after Write}.
\item Le renommage de paramètres similaire au renommage de registres, une technique issue des processeurs superscalaires, le renommage se fait sur les paramètres \emph{output} et \emph{input/output} pour chaque appel de fonction qui possède un paramètre qui va être écrit, au lieu d'écrire dans l'adresse originale de celui-ci, un emplacement mémoire nouveau sera utilisé, celui-ci sera un renommage de l'emplacement du paramètre original. Ceci permet l'exécution de la fonction indépendamment d'un appel précédent à une fonction qui écrit ou lit ce paramètre. Cette technique permet de ce fait de supprimer efficacement toutes les dépendances \emph{WaR} et \emph{WaW} en utilisant de l'espace mémoire supplémentaire et simplifie ainsi le graphe des dépendances et augmente les chances d'extraire du parallélisme.
\item Enfin, sous certaines conditions, la tâche peut être exécutée.
\end{itemize}
Durant l'exécution de l'application le runtime maintient une liste de tâches prêtes. Une tâche est étiquetée comme étant prête, à partir du moment où il n'existe aucune dépendance entre cette tâche et d'autres tâches ou alors que ces dépendances ont été résolues (les tâches précédentes dans le graphe on finit leur exécution). Le graphe de dépendance de tâches ainsi que la liste des tâches prêtes sont mis-à-jour à chaque fois qu'une tâche finit son exécution. Lorsqu'une tâche est terminée le runtime reçoit une notification et le graphe de tâche est vérifié pour établir les dépendances qui ont été satisfaites et les tâches dont toutes les dépendances ont été résolues et qui sont ajoutées dans la liste des tâches prêtes.\\
Etant donné une liste de tâches prêtes et une liste de ressources disponibles, le runtime choisit la meilleure corréspondance entre les tâches et les ressources et soummet les tâches pour l'exécution. La soumission de la tâche comprend toutes les actions nécéssaires pour pouvoir exécuter la tâche: le transfert des paramètres et la requête d'exécution de la tâche.
\subsubsection{Middleware pour le Cell}