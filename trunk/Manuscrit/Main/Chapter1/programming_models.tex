\section{RapidMind}
\textbf{RapidMind}[citer paper Rapidmind] est un modèle de programmation du processeur Cell, il relève du modèle de programmation \emph{stream programming} et s'apparente à un langage de programmatio enfoui dans C++. Il est basé sur la bibliothèque template C++ et une librarie de runtime qui effectué la génération dynamique de code. La librairie tepmplate permet l'invocation permet l'invocation de code SPE à l'intrieur du code PPE, avec l'ensemble du code SPE écrit en template.\\
La librairie template de \textbf{RapidMind} fournit un ensemble de types de données, des macros de contrôle, des opérations de réduction et des  fonctions communes qui permettent à la librairie de runtime de capturer une représentation du code SPE (retained code). Les types de données ont été spécialement conçus pour exprimer de manière simple les opérations SIMD et les exposer facilement à la librairie runtime. Le runtime à son tour extraits le parallélisme à partir de ces opérations  en vectorisant le code et en divisant les calculs sur les tableaux et les vecteurs sur les différents SPEs. Il peut également effectuer des optimisations de boucle comme les détéction des invariants de boucle. \textbf{RapidMind} assigne des tâches aux SPEs dynamiquementet peut effectuer des optimisations à plus haut niveau comme la superposition des calculs et des transferts qui permet de masquer la latence de ces derniers. Enfin le modèle de calcul est un modèle SPMD, il diffère du modèle SIMD du fait que les programme peuvent contenir du flot de contrôle et que ce modèle puisse gérer une certaine forme de parallélisme de tâches même si étant initialement un modèle data-parallel.\\
\subsection{Modèle de Programmation et Interface}
L'interface est basée sur trois types C++ principaux: \textbf{\texttt{Value<N,T>}}, \textbf{\texttt{Array<D,T>}} et \textbf{\texttt{Program}}, tous sont des conteneurs, les deux premiers pour les données et le dernier pour les opérations. Le calcul parallèle est efféctué soit en applicant des \textbf{\texttt{Program}} sur des \textbf{\texttt{Array}} pour créer de nouveaux \textbf{\texttt{Array}}, ou en applicant une opération collective parallèle qui peut être paramétrée par un objet \textbf{\texttt{Program}} comme la réduction par exemple.\\
A première vue les types \textbf{\texttt{Value}} et \textbf{\texttt{Array}} ne sont pas une grande nouveauté. En effet, tout développeur C++ a pour habitude d'utiliser les types N-tuples pour exprimer le calcul numérique sur des vecteurs, et le type \textbf{\texttt{Array}} est une manière usuelle d'encapsuler la vérification des valeurs limites (boundary checking). Toutefois ces types constituent une interface pour une machine parallèle puissante basée sur la génération dynamique de code. Ceci est rendu possible grâce au type \textbf{\texttt{Program}} qui est la principale innovation du modèle de programmation \textbf{RapidMind}. Un mode d'exécution symbolique \emph{retained} est utiliser pour collecter dynamiquement des opérations arbitraires sur les \textbf{\texttt{Value}} et les \textbf{\texttt{Array}} dans les objets \textbf{\texttt{Program}}.
\subsubsection{le type \textbf{\texttt{Value}}}
le type \textbf{\texttt{Value<N,T>}} est un N-tuple, les instances de ce type contiennent N valeurs de type T, ou T peut être un type numérique de base (un flottant simple ou double précision ou tout autre entier), les flottants 16-bits sont également supportés. Des notations courtes existent pour certaines tailles usuelle comme le \textbf{\texttt{Value4f}} pour un quarter de floats ou \textbf{\texttt{Value3ub}} pour un triplet d'entiers 8-bits non signés.\\
Les opérations arithmétiques standard et les opérations logiques sont surchargés pour les types tuples et opèrent composante par composante. Les fonctions de la bibliothèque standard  sont également supportées, comme les fonctions trigonométriques et logarithmiques. En plus des opérations arithmétiques, des opérations de réorganisation des données on été ajoutées au type value: ces opérations permettent la duplication d'une composante ou ou le réordonnancement des composantes. Par exemple, si \textbf{\texttt{a}} est une valeur de type \textbf{\texttt{Value<4, float>}} qui représente une couleur RGBA, a(2,1,0) est l'inverse représentant le triplet BGR.\\
Les calculs sont exprimés en utilisant les tuples de \textbf{\texttt{Value}} et les opérateurs sur ces types peuvent être utilisés directement pour exprimer du parallélisme SWAR (SIMD Within A Register). Les constructions C++ de modularité tels que namespaces, classes et fonctions.\\
\subsubsection{le type \textbf{\texttt{Array}}}
Le type \textbf{\texttt{Array<D,T>}} est également un conteneur de données. Ce qui le distingue du type \textbf{\texttt{Value}} est le fait qu'il peut être multidimensionnel et de taille variable. L'entier D représente la dimmensionnalité (1,2 ou 3), le type T est le type des éléments du conteneur. Le type des éléments et pour le moment restreint aux instances du type \textbf{\texttt{Value<N,T>}}.\\
Les instances du type \textbf{\texttt{Array}} supportent les opérateurs "[]" et "()" pour l'accès aléatoire aux données. L'opérateur "[]" utilisé des entiers en arguments tandis que l'opérateur "()" utilise des coordonnées réelles comprises dans [0, 1] dans chaque dimension, cette particularité est utile par exemple pour les modes d'interpolation des images.\\
Les sous-tableaux peuvent être accédés en utilisant les fonctions \textbf{slice}, \textbf{offset} et \textbf{stride}. Les effets de bords sont gérés en utilisant la fonction membre \textbf{boundary}, qui inclut différents modes de traitement pour les bords. les types \textbf{\texttt{Value}} et \textbf{\texttt{Array}} suivent une sémantique par valeurs qui permet d'éviter l'aliasing de pointeurs et simplifie la programmation et l'optimisation. Il existe également d'autres types de sous-tableaux, les références sur tableaux et les accesseurs.
\subsubsection{le type \textbf{\texttt{Program}}}
Un objet \textbf{\texttt{Program}} contient une séquence d'opérations, ces opérations sont spécifiées par le passage en mode \emph{retained} qui est indiqué par la macro mot-clé \textbf{\texttt{BEGIN}}. Normalement, le système fonctionne en mode \emph{immediate}. Dans ce mode les opérations sur un tuple de valeurs s'exécutent à la spécification comme pour une bibliothèque matrice-vecteur classique:  les calculs sont effectués sur la même machine que le programme hôte et le résultat est sauvegardé dans le tuple \textbf{\texttt{Value}} de sortie. En mode \emph{retained} un nouvel objet \textbf{\texttt{Program}} qui est retourné par la macro \textbf{\texttt{BEGIN}} est crée. Les opérations dans ce mode ne sont pas exécutées; elles sont symboliquement évaluées et sauvegardées dans l'objet \textbf{\texttt{Program}}. La sortie du mode \emph{retained} est marquée par la macro \textbf{\texttt{END}}, qui ferme l'objet \textbf{\texttt{Program}} et le marque comme étant prêt à être compilé, étape à la suite de laquelle l'objet \textbf{\texttt{Program}} est utilisé pour le calcul. Les objets \textbf{\texttt{Program}} sont compilés de manière dynamique ce qui permet d'exploiter les caractéristiques bas-niveau de la machine cible.\\
Il est à noter que même si les types \textbf{RapidMind} sont des classes C++, le compilateur est plutôt assimilable à un compilateur FORTRAN et peut ainsi effectuer les mêmes optimisations agressives. Les fonctionnalités du langage C++ sont utilisées pour structurer les calculs et générer le code mais n'est pas utilisé lors de l'éxecution.
\section{OpenMP Cell pour le Compiltateur XL}
OpenMP pour le Cell intégré dans le compilateur XL d'IBM est basé sur les transformations du compilateur et une librairie de runtime. Le compilateur transforme de pragmas OpenMPen code source intermédiaire qui implémente les constructions OpenMP correspondantes. Ce code inclut des appels aux fonctions de la a la librairie de runtime du Cell. Cette dernière fournit des fonctionnalités basiques à OpenMP incluant la gestion des threads, la répartition de la charge de travail ainsi que la synchronisation.\\
Chaque segment de code compris dans une construction parallèle est listé par le compilateur dans une fonction séparée. Le compilateur insère les appels à la librairie de runtime OpenMP dans la fonction parente de la fonction listée. Ces appels aux fonctions de la librairie de runtime vont ainsi invoquer les fonction listées et gérer leur exécution.\\
Le framework est basé sur le compilateur IBM XL. Ce dernier possède des front-end pour C/C++ et FORTRAN, et contient la même infrastructure d'optimisation pour ces langages. Le framework d'optimisation se divise en deux composants TPO et TOBEY. TPO est chargé des optimisations haut niveau indépendantes de la machine cible tandis que TOBEY effectue les optimisations bas-niveau spécifiques à l'architecture.\\
Le compilateur résulte d'une adaptation de versions existantes du compilateur XL supportant OpenMP, mais la spécifité de l'architecture du Cell à posé quelques problématiques qui sont les suivantes:
\begin{itemize}
\item \textbf{Threads et Synchronisation}: les threads s'exécutant sur le PPE diffèrent de ceux du SPE en termes de capacité de traitement. Le système à été conçu pour prendre en compte la différence entre les deux architectures.
\item \textbf{Génération de Code}: Le jeu d'instruction du PPE diffère de celui du SPE. Il en résulte que l'optimisation du code PPE est faite séparémment de celle du SPE. L'espace de stockage sur le SPE étant limité, le code SPE s'il excède cette capacité, peut être partitionné en sections binaires (\emph{overlays}) au lieu d'une section monolithique. De plus, les données partagées dans le code SPE nécessitent un transfert DMA de la mémoire centrale vers la mémoire locale. Ceci est fait soit par le compilateur qui insère explicitement des commandes DMA dans le code, soit par un mécanisme de software cache qui fait partie de la librairie de runtime du SPE.\\
\item \textbf{Modèle Mémoire}: le hardware du Cell assure que les transactions DMA sont cohérents, mais ne fournit pas de mécanisme de cohérence pour les données résidant dans la mémoire locale, le modèle mémoire de OpenMP implémenté assure une cohérence de données qui est requise par les spécifications.
\end{itemize}
Les sections qui suivent décrivent la manière avec laquelle ces problèmes ont été traités.
\subsection{Threads et Synchronisation}
les threads peuvent s'exécuter sur le PPE ou les SPE. Le thread maître est toujours exécuté sur le PPE. Ce thread est responsable de la création des autres threads, de la répartition et de l'ordonnancement des tâches, et des opérations de synchronisation. L'absence d'OS sur le SPE fait que le PPE gère toutes les requêtes OS. Cette répartition permet au SPE de se consacrer uniquement aux tâches de calcul.\\
Actuellement, un seul thread est sensé s'exécuter sur le PPE, est le nombre de threads parallèles exécutés sur les SPEs se déclare par la variable d'environnement OMP\_NUM\_THREADS. La création et synchronisation des threads est implementée les librairies du SDK (Software Development Kit). Le thread sur le PPE crée des threads SPE au runtime seulement quand les structures parallèles sont rencontrées pour la première fois.\\
Pour les niveaux de parallélisme nichés (boucles nichées), chaque thread dans la region parallèle la plus externe exécute sequentiellement la région parallèle interne. les itérations de boucles sont divisées en autant de morceaux qu'il y a de threads, avac un mécanisme d'ordonnancement et de synchronisation simplifié.Lorsque le thread SPE est crée, il effectue des initialisations et entre dans une phase d'attente d'affectation de tâches de la part du PPE, exécute ces tâches et se met en attente d'autres tâches, jusqu'à ce qu'il reçoive un signal de fin de tâches. Une tâche SPE peut être l'exécution d'une region parallèle listée (boucle ou section), ou alors l'exécution d'un flush de cache ou encore la participation à une opération de synchronisation par barrière.\\
Il existe une file d'attente dans la mémoire système correspondant à chaque thread. Quand le thread maître assigne une tâche à un thread, il écrit les informations sur la tâche à la file d'attente de tâche correspondante., incluant le type de tâche, les bornes supérieure et inférieure de la boucle parallèle, ainsi que le pointeur de fonction pour la région de code listée qui doit être exécutée. Une fois que le thread SPE prend une tâche de la file d'attente, il signale au thread maître que l'espace dans la file d'attente et à nouveau libre. Les mécanismes de synchronisation sont assurés au travers de mailbox qui permettent l'échange de messages bloquant ou non-bloquant entre le thread maître et les threads de calcul. Les locks OpenMP sont implémentés grâce au commandes DMA atomiques.
\subsection{Génération de Code}
En premier lieu, le compilateur sépare chaque région dans le code source qui correspond à une construction OpenMP parallèle, et la liste dans une fonction séparée. La fonction peut prendre des paramètres supplémentaires comme les bornes supérieure et inférieure de la boucle. Le compilateur insère un appel à la librairie de runtime OpenMP au niveau de la fonction parente de la fonction listée, et insère un pointeur dans cette fonction de la librairie de runtime. Le compilateur insère également des instructions de synchronisation quand c'est nécessaire.\\
Le fait que l'architecture du Cell soit hétérogène impose que les fonctions listées contenant des tâches parallèles soit clonnées afin d'être executables aussi bien par le SPE que le PPE. Le clonage est effectué quand le graphe d'appel dlobal est disponible de telle sorte que le sou-graphe d'un appel à une fonction listée puisse être clonné entièrement. Le clonage permet aussi lors des étapes d'optimisation ultérieures d'effectuer des optimisations qui dépendent de l'architecture comme la vectorisation de code qui ne peut pas se faire dans une étape commune à cause des différences entre les jeux d'instructions SPU et VMX. Une table de mise en correspondance entre les versions PPE et SPE contient les pointeurs des fonctions listées de telle sorte à ce qu'il n'y ai pas de confusion lors de l'exécution.\\
A la fin de l'étape TPO, les procédures sur les différentes architectures sont séparées en deux unités de compilation différente et celles-ci sont traitées une par une par le back-end TOBEY.\\
L'unité PPE ne requière pas de traitement particulier. Par contre l'unité compilée SPE peut produite un binaire d'une taille importante et qui ne tiens pas dans la mémoire locale. Il existe deux approches pour remédier à ce problème. La première consiste au partitionnement de la section parallèle dans un programme en plusieurs sections de taille moindre et la génération d'un binaire distinct pour chaque sous section. Cette approche est limitée, d'une part par-ce-qu'une sous-section peut avoir une taille pas assez petite pour tenir dans la mémoire locale et d'autre part la complexité générée par la création et la synchronisation de plusieurs threads affecte considérablement les performances. \\
La deuxième approche qui est celle utilisée dans le compilateur IBM XL, est le partitionnement du graphe d'appel et les \emph{overlays} de code. Le code SPE est ainsi partitionné et un code \emph{overlays} est crée pour chaque partition. Ces \emph{overlays} partagent l'espace d'adresses mais n'occupent pas la mémoire locale en même temps. Un poids est affecté à chacun des arcs du graphe représentant la fréquence d'appels de la fonction. Le graphe d'appel est partitionné afin de maximiser cette fréquence d'appel dans une partition en utilisant l'algorithme du \emph{maximum spanning tree}. Le code SPE ainsi  généré est intégré dans le code PPE avant d'être exécuté.\\
\subsection{Modèle Mémoire}
OpenMP spécifie un modèle mémoire \emph{relaxed-consistency}, \emph{shared memory}. Ce modèle permet à chaque thread d'avoir sa propre vue temporaire de la mémoire pour rester dans la vue temporaire. Une valeur écrite