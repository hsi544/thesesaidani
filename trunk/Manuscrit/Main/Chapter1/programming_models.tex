Dans ce chapitre on se propose de faire une revue des modèles de programmations pour le processeur Cell. Par modèle de programmation on entend outil de déploiement de code ou de parallélisation de code conçu pour le Cell. Les approches citées dans ce qui suit sont celles qui nous ont paru pertinents et assez mures pour pouvoir être utilisées dans notre domaines d'applications. Il reprennent généralement des outils existants pour les architectures parallèles à mémoire partagée ou distribuée qui ont été adaptés pour l'architecture et la hiérarchie mémoire du Cell.
\section{Les Threads POSIX}
Les threads POSIX\footnote{Portable Operating System Interface for Unix} ou Pthreads sont une standardisation du modèle de programmation par threads pour les système UNIX. Ce modèle est basé sur une API de programmation parallèle qui permet la gestion des threads ainsi que la synchronisation par mutex ou variables conditionnelles.\\
En ce qui concerne le processeur Cell, une API de gestion des threads SPE similaire à la librairie POSIX a été conçue, dans le but de fournir à la fois un environnement de programmation familier et une flexibilité dans la gestion des SPEs. Cette API supporte à la fois la creation et la terminaison des tâches SPE ainsi que l'exclusion mutuelle par des primitives de mise à jour atomiques. L'API peut accéder au SPE en utilisant un modèle virtuel dans lequel l'OS affecte dynamiquement les threads aux SPEs dans l'ordre de leur disponibilité. Les applications, peuvent spécifier de manière optionnelles un mask d'affinités pour affecter les threads a un SPE spécifique. Les dispositifs architecturaux de communication entre les threads et de synchronisation (mailbox, signaux, etc...) peuvent être accedés via un ensemble d'appels système ou alors via l'application qui mappe une block de contrôle du SPE dans l'espace d'application. Sur le Cell il existe trois blocks de contrôle du SPE, un accédé par l'application, un autre par l'OS et un troisième par un superviseur. Une interface accessible à l'utilisateur permet  la communication directe entre les processeur SPEs ou PPE, ceci permet d'éviter des appels système coûteux.\\
Lorsque l'application fait une requête de creation de threads, la librairie de threads SPE envoie la requête à l'OS pour alouer un SPE et créer un thread SPE à partir d'un fichier objet de format ELF (Executable and Linkable Format) intégrée dans un executable Cell. Le \emph{miniloader} un programme SPE de 256-bit, telecharge la segment de code à exécuter sur le SPE, l'avantage de cette approche et d'une part d'éviter au PPE d'effectuer cette tâche et d'autre part de profiter du fait que les les transfers PPE-SPE quand il se font du côté SPE, sont nettement plus efficace grace à une interface qui contient plus de canaux de communications. 
To offload a portion of thread initialization onto the SPE, the PPE can use a “miniloader” executing on the SPE to perform SPE program loading. The miniloader, a 256-bit SPE program, downloads the application ELF segments from the host thread’s effective address space to the SPU local store. Using an SPE-side miniloader is advantageous because it offloads the PPE from having to pace program
loads and it can use the SPE miniloader to preinitialize registers with application/OS parameter values. This is attractive because multiple SPEs can load
threads simultaneously, and SPEs have deeper fetch queues to hold multiple block transfer requests associated with loading a thread. In addition, communication
within a processor element’s scope—that is, between the SPU and its associated MFC—is more efficient than interprocessor element communication between the MFC in an SPE and the PPE using MMIO.

%\subsection{Threads et Tâches}
%Sur un système Linux pour le Cell, the thread principal s'exécute sur le PPE, celui-ci pouvant produire un ou plusieurs tâches sur le processeur. Une tâche peut contenir un ou plusieur threads Linux qui peuvent s'exécuter soit sur le PPE soit sur le SPE. Un thread qui s'exécute sur le SPE possède son propre contexte incluant un banc de registre de 128 x 128-bit  , un compteur de programme et une file d'attente de commandes MFC, et il peut communiquer avec d'autres unités d'exécution au travers de l'interface des canaux MFC. Un thread PPE peut interagir directement avec un thread SPE via sa mémoire locale ou son espace de \emph{problem state} ou indirectement via la mémoire centrale ou les routines la \emph{SPE Runtime Management Library}. L'OS définit le mécanisme et la politique d'ordonnancement pour les SPE disponibles, il est également responsable de la gestion des priorités entre les tâches, du chargement du programme de la notification des évenemments au SPEs ainsi que du support du debugger.
%\subsection{Environnement de Runtime}

\section{RapidMind}
\textbf{RapidMind}\cite{rapidmind} est un modèle de programmation parallèle multi-plateformes, GPU, multi-coeur symétrique et pour le processeur Cell, il relève du modèle de programmation \emph{stream programming} et s'apparente à un langage de programmation enfoui dans C++. Il est basé sur la bibliothèque template C++ et une librairie de runtime qui effectué la génération dynamique de code. La librairie template permet l'invocation permet l'invocation de code SPE à l'intérieur du code PPE, avec l'ensemble du code SPE écrit en template.\\
La librairie template de \textbf{RapidMind} fournit un ensemble de types de données, des macros de contrôle, des opérations de réduction et des  fonctions communes qui permettent à la librairie de runtime de capturer une représentation du code SPE (retained code). Les types de données ont été spécialement conçus pour exprimer de manière simple les opérations SIMD et les exposer facilement à la librairie runtime. Le runtime à son tour extraits le parallélisme à partir de ces opérations  en vectorisant le code et en divisant les calculs sur les tableaux et les vecteurs sur les différents SPEs. Il peut également effectuer des optimisations de boucle comme les détection des invariants de boucle. \textbf{RapidMind} assigne des tâches aux SPEs dynamiquement et peut effectuer des optimisations à plus haut niveau comme la superposition des calculs et des transferts qui permet de masquer la latence de ces derniers. Enfin le modèle de calcul est un modèle SPMD, il diffère du modèle SIMD du fait que les programme peuvent contenir du flot de contrôle et que ce modèle puisse gérer une certaine forme de parallélisme de tâches même si étant initialement un modèle data-parallel.\\
\subsection{Modèle de Programmation et Interface}
L'interface est basée sur trois types C++ principaux: \textbf{\texttt{Value<N,T>}}, \textbf{\texttt{Array<D,T>}} et \textbf{\texttt{Program}}, tous sont des conteneurs, les deux premiers pour les données et le dernier pour les opérations. Le calcul parallèle est effectué soit en applicant des \textbf{\texttt{Program}} sur des \textbf{\texttt{Array}} pour créer de nouveaux \textbf{\texttt{Array}}, ou en applicant une opération collective parallèle qui peut être paramêtrée par un objet \textbf{\texttt{Program}} comme la réduction par exemple.\\
A première vue les types \textbf{\texttt{Value}} et \textbf{\texttt{Array}} ne sont pas une grande nouveauté. En effet, tout dévelopeur C++ a pour habitude d'utiliser les types N-tuples pour exprimer le calcul numérique sur des vecteurs, et le type \textbf{\texttt{Array}} est une manière usuelle d'encapsuler la vérification des valeurs limites (boundary checking). Toutefois ces types constituent une interface pour une machine parallèle puissante basée sur la génération dynamique de code. Ceci est rendu possible grâce au type \textbf{\texttt{Program}} qui est la principale innovation du modèle de programmation \textbf{RapidMind}. Un mode d'exécution symbolique \emph{retained} est utiliser pour collecter dynamiquement des opérations arbitraires sur les \textbf{\texttt{Value}} et les \textbf{\texttt{Array}} dans les objets \textbf{\texttt{Program}}.
\subsubsection{le type \textbf{\texttt{Value}}}
le type \textbf{\texttt{Value<N,T>}} est un N-tuple, les instances de ce type contiennent N valeurs de type T, ou T peut être un type numérique de base (un flottant simple ou double précision ou tout autre entier), les flottants 16-bits sont également supportés. Des notations courtes existent pour certaines tailles usuelle comme le \textbf{\texttt{Value4f}} pour un quarter de floats ou \textbf{\texttt{Value3ub}} pour un triplet d'entiers 8-bits non signés.\\
Les opérations arithmétiques standard et les opérations logiques sont surchargés pour les types tuples et opèrent composante par composante. Les fonctions de la bibliothèque standard  sont également supportées, comme les fonctions trigonométriques et logarithmiques. En plus des opérations arithmétiques, des opérations de réorganisation des données on été ajoutées au type value: ces opérations permettent la duplication d'une composante ou ou le réordonnancement des composantes. Par exemple, si \textbf{\texttt{a}} est une valeur de type \textbf{\texttt{Value<4, float>}} qui représente une couleur RGBA, a(2,1,0) est l'inverse représentant le triplet BGR.\\
Les calculs sont exprimés en utilisant les tuples de \textbf{\texttt{Value}} et les opérateurs sur ces types peuvent être utilisés directement pour exprimer du parallélisme SWAR (SIMD Within A Register). Les constructions C++ de modularité tels que namespaces, classes et fonctions.\\
\subsubsection{le type \textbf{\texttt{Array}}}
Le type \textbf{\texttt{Array<D,T>}} est également un conteneur de données. Ce qui le distingue du type \textbf{\texttt{Value}} est le fait qu'il peut être multidimensionnel et de taille variable. L'entier D représente la dimensionnalité (1,2 ou 3), le type T est le type des éléments du conteneur. Le type des éléments et pour le moment restreint aux instances du type \textbf{\texttt{Value<N,T>}}.\\
Les instances du type \textbf{\texttt{Array}} supportent les opérateurs "[]" et "()" pour l'accès aléatoire aux données. L'opérateur "[]" utilisé des entiers en arguments tandis que l'opérateur "()" utilise des coordonnées réelles comprises dans [0, 1] dans chaque dimension, cette particularité est utile par exemple pour les modes d'interpolation des images.\\
Les sous-tableaux peuvent être accèdés en utilisant les fonctions \textbf{slice}, \textbf{offset} et \textbf{stride}. Les effets de bords sont gérés en utilisant la fonction membre \textbf{boundary}, qui inclut différents modes de traitement pour les bords. les types \textbf{\texttt{Value}} et \textbf{\texttt{Array}} suivent une sémantique par valeurs qui permet d'éviter l'aliasing de pointeurs et simplifie la programmation et l'optimisation. Il existe également d'autres types de sous-tableaux, les références sur tableaux et les accèsseurs.
\subsubsection{le type \textbf{\texttt{Program}}}
Un objet \textbf{\texttt{Program}} contient une séquence d'opérations, ces opérations sont spécifiées par le passage en mode \emph{retained} qui est indiqué par la macro mot-clé \textbf{\texttt{BEGIN}}. Normalement, le système fonctionne en mode \emph{immediate}. Dans ce mode les opérations sur un tuple de valeurs s'exécutent à la spécification comme pour une bibliothèque matrice-vecteur classique:  les calculs sont effectués sur la même machine que le programme hôte et le résultat est sauvegardé dans le tuple \textbf{\texttt{Value}} de sortie. En mode \emph{retained} un nouvel objet \textbf{\texttt{Program}} qui est retourné par la macro \textbf{\texttt{BEGIN}} est crée. Les opérations dans ce mode ne sont pas exécutées; elles sont symboliquement évaluées et sauvegardées dans l'objet \textbf{\texttt{Program}}. La sortie du mode \emph{retained} est marquée par la macro \textbf{\texttt{END}}, qui ferme l'objet \textbf{\texttt{Program}} et le marque comme étant prêt à être compilé, étape à la suite de laquelle l'objet \textbf{\texttt{Program}} est utilisé pour le calcul. Les objets \textbf{\texttt{Program}} sont compilés de manière dynamique ce qui permet d'exploiter les caractéristiques bas-niveau de la machine cible.\\
Il est à noter que même si les types \textbf{RapidMind} sont des classes C++, le compilateur est plutôt assimilable à un compilateur FORTRAN et peut ainsi effectuer les mêmes optimisations agressives. Les fonctionnalités du langage C++ sont utilisées pour structurer les calculs et générer le code mais n'est pas utilisé lors de l'exécution.
\subsection{Evaluation Partielle et Algèbre du Programme}
Les objets \textbf{\texttt{Program}} sont des conteneurs d'opérations, et ces opérations peuvent être manipulées par le système de manière explicite. Cela permet l'implémentation de plusieurs dispositifs avancés de programmation.\\
En premier lieu, les \textbf{\texttt{Program}} peuvent être évalués partiellement. Si un objet \textbf{\texttt{Program}} \textbf{p} ayant \textbf{n} entrées, l'expression \textbf{p(A)} retourne un objet \textbf{\texttt{Program}} avec \textbf{(n-1)} entrées. En d'autres termes les entrées de l'objet \textbf{\texttt{Program}} ne sont pas obligatoirement fournies toutes en une fois. Il est possible de binder toutes les entrés d'un objet \textbf{\texttt{Program}} mais de différer son exécution effective. L'exécution d'un objet \textbf{\texttt{Program}} n'est déclenchée que quand il est affecté à un \emph{bundle}, \textbf{\texttt{Array}} ou \textbf{\texttt{Value}}. L'opérateur \textbf{"()"} est utilisé pour binder les entrées de l'objet \textbf{\texttt{Program}}. Ceci est appelé le \emph{tight binding}. Un changement de l'entrée après un \emph{tight binding}, n'affecte pas les entrées d'un \textbf{\texttt{Program}}, même si son exécution est différée. Dans l'exemple précédent, ou l'on crée \textbf{"p(A)"} et qu'on l'affect à un objet \textbf{\texttt{Program}} \textbf{"q"}, et qu'on modifie ensuite l'entrée \textbf{"A"}. Lors de l'exécution de \textbf{"q"}, celui-ci utilisera la valeur de \textbf{"A"} au moment du binding dans \textbf{"p"}, pas la valeur modifiée. Le \emph{tight binding} permet l'optimisation de l'objet \textbf{\texttt{Program}} basée sur les valeurs effectives dans l'entrée bindée.\\
Toutefois, le système supporte également le \emph{loose binding}, spécifié par l'opérateur \textbf{"<<"}. L'expression \textbf{"p<<A"} est similaire à \textbf{"p(A)"} sauf que les changements sur \textbf{"A"} sont visibles à m'exécution différée de \textbf{"p<<A"}.\\
Une entrée à un \textbf{\texttt{Program}} peut être bindée à un \textbf{\texttt{Array}} ou un tuple de \textbf{\texttt{Value}}. Si des arrays de tailles différentes sont bindées à un \textbf{\texttt{Program}} la plus petite entrée est répliquée suivant les conditions aux bords pour avoir la taille de l'entrée de l'entrée la plus grande.\\
Les \textbf{\texttt{Program}} peuvent être combinés pour créer de nouveaux \textbf{\texttt{Program}} en utilisant deux opérations: la composition fonctionnelle est le \emph{bundling}. Ces opérations forment une algèbre fermée dans l'ensemble des objets \textbf{\texttt{Program}}. L'opérateur de composition fonctionnelle \textbf("<<") quand il est appliqué à deux objets \textbf{\texttt{Program}} \textbf{"p"} et \textbf{"q"} \textbf{"p << q"} transmet toutes les entrées du \textbf{\texttt{Program}} à droite de l'opérateur à l'entrée de celui de gauche, il crée un nouvel objet \textbf{\texttt{Program}} ayant les entrées de \textbf{"q"} et les sorties de \textbf{"p"}. L'opérateur \emph{bundle} quand à lui utilise la fonction \textbf{"bundle"}. Cette fonction concatene toutes les entrées/sorties de ses arguments dans l'ordre et crée un nouvel objet \textbf{\texttt{Program}} équivalent à la concaténation des sources de ces \textbf{\texttt{Program}} d'entrée en séquence.\\
Ces opérations combinées avec la compilation dynamique permettent une amélioration considérable des performances surtout quand le programme est dominé par des instructions de mémoire.
\subsection{Les Opérations Collectives}
L'opération de base supportée est l'application parallèle d'un programme sur un tableau de données. Toutefois, d'autres patterns de communication et de calcul sont supportés sous la forme d'opérations collectives. Les patterns de communication irréguliers sont fournis par les opérations de \emph{scatter} et \emph{gather},et l'opération de réduction fournit un pattern de calcul hiérarchique.\\
L'opération\emph{gather} permet de récupérer des données résidant dans des emplacements non-contigus de la mémoire et l'opération \emph{scatter} l'écriture dans des zones de même nature. L'opération de réduction quand à elle est programmable, elle prend deux entrée et fournit une sortie. Elle permet par exemple de sommer les éléments d'un vecteur d'une manière hiérarchique.\\ \textbf{INSERER FIGURE REDUCTION}\\. On pourra noter que l'opérateur impliqué dans la réduction doit être associatif. Parmi les opérateurs qui ont été implémentés on peut citer \textbf{sum}, \textbf{product}, \textbf{min} et \textbf{max}.
\subsection{Spécificité du Backend pour le Cell de RapidMind}
L'implémentation de RapidMind pour le Cell possède certaines particularités qui tiennent compte de l'architecture particulière de ce processeur. Le parallélisme SWAR peut être mappé directement sur les registres SIMD du SPE mais les opérations de permutation de données ne sont pas implémentées de manière aussi efficace les unes que les autres. D'autre part la parallélisation qui consiste à appliquer un program à un tableau permet en théorie de faire des millions de calculs en parallèle, mais le Cell ne possède qu'un nombre d'unités de traitement. C'est pour cela que les données sont divisée en plusieurs paquets et transférées dans les mémoires locales des SPEs avant d'être traitées. Le triple buffering est utilisé pour cacher la latence des transferts DMA. Pour les accès mémoire non réguliers un software-cache est utilisé. Si les programmes incluent un flux de contrôle différents tâches peuvent prendre des temps d'exécution différents un système de \emph{load balancing} (équilibrage de charge). 
\subsection{Conclusion}
La plate-forme de développement RapidMind combine une interface basée sur la compilation dynamique et un modèle de calcul data-parallel. Elle peut être considérée soit comme une API de calcul parallèle ou un langage de programmation parallèle enfoui dans C++. Il supporte plusieurs niveaux de parallélisme notamment le parallélisme SWAR et le parallélisme SPMD. Le modèle de programmation est commun à plusieurs plate-formes GPU, multi-coeur et Cell. C'est un modèle de programmation assez simple à utiliser et qui repose en grande partie sur un compilateur C++ lui confère une grande popularité auprès des utilisateurs. Au niveau des performances on peut relever de bon résultats dans [citer articles] mais pour ce qui est de notre domaine d'applications qui est le traitement d'images, une analyse approfondie sera faite par la suite.

\section{OpenMP}
OpenMP pour le Cell\cite{cell_omp} intégré dans le compilateur XL d'IBM est basé sur les transformations du compilateur et une librairie de runtime. Le compilateur transforme de pragmas OpenMPen code source intermédiaire qui implémente les constructions OpenMP correspondantes. Ce code inclut des appels aux fonctions de la a la librairie de runtime du Cell. Cette dernière fournit des fonctionnalités basiques à OpenMP incluant la gestion des threads, la répartition de la charge de travail ainsi que la synchronisation.\\
Chaque segment de code compris dans une construction parallèle est listé par le compilateur dans une fonction séparée. Le compilateur insère les appels à la librairie de runtime OpenMP dans la fonction parente de la fonction listée. Ces appels aux fonctions de la librairie de runtime vont ainsi invoquer les fonction listées et gérer leur exécution.\\
Le framework est basé sur le compilateur IBM XL. Ce dernier possède des front-end pour C/C++ et FORTRAN, et contient la même infrastructure d'optimisation pour ces langages. Le framework d'optimisation se divise en deux composants TPO et TOBEY. TPO est chargé des optimisations haut niveau indépendantes de la machine cible tandis que TOBEY effectue les optimisations bas-niveau spécifiques à l'architecture.\\
Le compilateur résulte d'une adaptation de versions existantes du compilateur XL supportant OpenMP, mais la spécificité de l'architecture du Cell à posé quelques problématiques qui sont les suivantes:
\begin{itemize}
\item \textbf{Threads et Synchronisation}: les threads s'exécutant sur le PPE diffèrent de ceux du SPE en termes de capacité de traitement. Le système à été conçu pour prendre en compte la différence entre les deux architectures.
\item \textbf{Génération de Code}: Le jeu d'instruction du PPE diffère de celui du SPE. Il en résulte que l'optimisation du code PPE est faite séparément de celle du SPE. L'espace de stockage sur le SPE étant limité, le code SPE s'il excède cette capacité, peut être partitionné en sections binaires (\emph{overlays}) au lieu d'une section monolithique. De plus, les données partagées dans le code SPE nécessitent un transfert DMA de la mémoire centrale vers la mémoire locale. Ceci est fait soit par le compilateur qui insère explicitement des commandes DMA dans le code, soit par un mécanisme de software cache qui fait partie de la librairie de runtime du SPE.\\
\item \textbf{Modèle Mémoire}: le hardware du Cell assure que les transactions DMA sont cohérents, mais ne fournit pas de mécanisme de cohérence pour les données résidant dans la mémoire locale, le modèle mémoire de OpenMP implémenté assure une cohérence de données qui est requise par les spécifications.
\end{itemize}
Les sections qui suivent décrivent la manière avec laquelle ces problèmes ont été traités.
\subsection{Threads et Synchronisation}
les threads peuvent s'exécuter sur le PPE ou les SPE. Le thread maître est toujours exécuté sur le PPE. Ce thread est responsable de la création des autres threads, de la répartition et de l'ordonnancement des tâches, et des opérations de synchronisation. L'absence d'OS sur le SPE fait que le PPE gère toutes les requêtes OS. Cette répartition permet au SPE de se consacrer uniquement aux tâches de calcul.\\
Actuellement, un seul thread est sensé s'exécuter sur le PPE, est le nombre de threads parallèles exécutés sur les SPEs se déclare par la variable d'environnement OMP\_NUM\_THREADS. La création et synchronisation des threads est implementée les librairies du SDK (Software Development Kit). Le thread sur le PPE crée des threads SPE au runtime seulement quand les structures parallèles sont rencontrées pour la première fois.\\
Pour les niveaux de parallélisme nichés (boucles nichées), chaque thread dans la region parallèle la plus externe exécute séquentiellement la région parallèle interne. les itérations de boucles sont divisées en autant de morceaux qu'il y a de threads, avec un mécanisme d'ordonnancement et de synchronisation simplifié.Lorsque le thread SPE est crée, il effectue des initialisations et entre dans une phase d'attente d'affectation de tâches de la part du PPE, exécute ces tâches et se met en attente d'autres tâches, jusqu'à ce qu'il reçoive un signal de fin de tâches. Une tâche SPE peut être l'exécution d'une region parallèle listée (boucle ou section), ou alors l'exécution d'un flush de cache ou encore la participation à une opération de synchronisation par barrière.\\
Il existe une file d'attente dans la mémoire système correspondant à chaque thread. Quand le thread maître assigne une tâche à un thread, il écrit les informations sur la tâche à la file d'attente de tâche correspondante., incluant le type de tâche, les bornes supérieure et inférieure de la boucle parallèle, ainsi que le pointeur de fonction pour la région de code listée qui doit être exécutée. Une fois que le thread SPE prend une tâche de la file d'attente, il signale au thread maître que l'espace dans la file d'attente et à nouveau libre. Les mécanismes de synchronisation sont assurés au travers de mailbox qui permettent l'échange de messages bloquant ou non-bloquant entre le thread maître et les threads de calcul. Les locks OpenMP sont implémentés grâce au commandes DMA atomiques.
\subsection{Génération de Code}
En premier lieu, le compilateur sépare chaque région dans le code source qui correspond à une construction OpenMP parallèle, et la liste dans une fonction séparée. La fonction peut prendre des paramètres supplémentaires comme les bornes supérieure et inférieure de la boucle. Le compilateur insère un appel à la librairie de runtime OpenMP au niveau de la fonction parente de la fonction listée, et insère un pointeur dans cette fonction de la librairie de runtime. Le compilateur insère également des instructions de synchronisation quand c'est nécessaire.\\
Le fait que l'architecture du Cell soit hétérogène impose que les fonctions listées contenant des tâches parallèles soit clonnées afin d'être executables aussi bien par le SPE que le PPE. Le clonage est effectué quand le graphe d'appel global est disponible de telle sorte que le sou-graphe d'un appel à une fonction listée puisse être clonné entièrement. Le clonage permet aussi lors des étapes d'optimisation ultérieures d'effectuer des optimisations qui dépendent de l'architecture comme la vectorisation de code qui ne peut pas se faire dans une étape commune à cause des différences entre les jeux d'instructions SPU et VMX. Une table de mise en correspondance entre les versions PPE et SPE contient les pointeurs des fonctions listées de telle sorte à ce qu'il n'y ai pas de confusion lors de l'exécution.\\
A la fin de l'étape TPO, les procédures sur les différentes architectures sont séparées en deux unités de compilation différente et celles-ci sont traitées une par une par le back-end TOBEY.\\
L'unité PPE ne requière pas de traitement particulier. Par contre l'unité compilée SPE peut produite un binaire d'une taille importante et qui ne tiens pas dans la mémoire locale. Il existe deux approches pour remédier à ce problème. La première consiste au partitionnement de la section parallèle dans un programme en plusieurs sections de taille moindre et la génération d'un binaire distinct pour chaque sous section. Cette approche est limitée, d'une part par-ce-qu'une sous-section peut avoir une taille pas assez petite pour tenir dans la mémoire locale et d'autre part la complexité générée par la création et la synchronisation de plusieurs threads affecte considérablement les performances. \\
La deuxième approche qui est celle utilisée dans le compilateur IBM XL, est le partitionnement du graphe d'appel et les \emph{overlays} de code. Le code SPE est ainsi partitionné et un code \emph{overlays} est crée pour chaque partition. Ces \emph{overlays} partagent l'espace d'adresses mais n'occupent pas la mémoire locale en même temps. Un poids est affecté à chacun des arcs du graphe représentant la fréquence d'appels de la fonction. Le graphe d'appel est partitionné afin de maximiser cette fréquence d'appel dans une partition en utilisant l'algorithme du \emph{maximum spanning tree}. Le code SPE ainsi  généré est intégré dans le code PPE avant d'être exécuté.\\
\subsection{Modèle Mémoire}
OpenMP spécifie un modèle mémoire \emph{relaxed-consistency}, \emph{shared memory}. Ce modèle permet à chaque thread d'avoir sa propre vue temporaire de la mémoire. Une valeur écrite dans une variable, ou une valeur lue à partir d'une mémoire peut rester dans la vue temporaire du thread jusqu'à ce qu'elle soit obligée de partager la mémoire par une opération de flush OpenMP.\\
Ce modèle est adapté au Cell en tenant compte de la mémoire limitée des SPEs. Les données privées accédées dans le code SPE sont allouées en mémoire privée. Les variables partagées sont elles allouées en mémoire centrale et peuvent être accedées via DMA par les SPEs. Deux mécanismes distincts sont utilisés pour les transferts DMA: le static-buffering et le software-cache contrôlé par le compilateur. Dans les deux cas, les données globales peuvent avoir une copie dans la mémoire locale SPE.\\
Certaines références sont considérées comme étant régulières du point de vue du compilateur. Ces références interviennent dans les boucles, les adresses mémoires vers lesquelles elle pointent peuvent être exprimées en utilisant des expressions affines de variables d'induction de la boucle, et la boucle qui les contient ne possède aucune dépendance induite par la boucle (vraie, de sortie ou anti-dépendance) impliquant ces références. Pour ces références régulières aux données partagées, un buffer temporaire est utilisé dans le SPE. Des opération DMA \emph{get} et \emph{put} sont utilisées respectivement pour lire et écrire de et vers ce buffer à partir de la mémoire centrale.  Plusieurs buffers peuvent être utilisés afin de recouvrir les calculs par des transfers mémoire.\\
Pour les références irrégulières à la mémoire le software-cache est utilisé. Le compilateur remplace les \emph{\texttt{load}} et \emph{\texttt{store}} de et vers ces zones mémoire par des instructions qui vont chercher les adresses effectives, dans le directory du cache. Si une ligne de cache pour l'adresse effective est trouvée (\emph{cache hit}) la valeur dans le cache est utilisée. Dans le cas contraire (\emph{cache miss}) la donnée est récupérée en mémoire via un DMA \emph{get} dans le cas d'une lecture.\\
La taille de la ligne de cache (128 bytes) et son associativité (4) sont choisies respectivement pour optimiser les transfers DMA et exploiter le jeu d'instructions SIMD pour le calcul des adresses (4x 32-bits). Le système assure également au SPE l'accès à des données qui seraient dans la pile d'une fonction PPE qui appelle une fonction SPE.
\subsection{Conclusion}
Le modèle de programmation OpenMP intégré dans le compilateur IBM XL pour le processeur Cell est une approche qui a le mérite de permettre à l'utilisateur de réutiliser son code OpenMP existant, sans se soucier des détails de l'architecture de Cell. Le support d'OpenMP est assuré par des transformations du compilateurs couplés à une librairie de runtime. Les problématiques qui sont posées pour le portage d'OpenMP sur le Cell sont notamment celles de la synchronisation des threads, la génération de code et le modèle mémoire. La solution proposée est inovante car elle propose un compilateur qui permet de générer un seul binaire executable qui s'exécute sur des jeux d'instructions différents et sur un espace mémoire distribué. Les performances sur des benchmarks simples ainsi que sur des codes plus complexes donnés dans \cite{cell_omp} démontrent l'efficacité de l'outil en comparaison avec un code optimisé à la main.
\section{Cell SuperScalar}
CellSS\cite{cellss_sc06} est un environnement a pour objectif de fournir à l'utilisateur un outil de programmation simple mais qui donne des executables qui exploitent efficacement l'architecture du processeur Cell. Il découle d'un modèle de programmation nommé GRID[citer le papier GRID] qui assimile un processeur superscalaire à une grille de calcul: les unités fonctionnelles du processeur sont les ressources de la grille, les données contenues dans les registres correspondent aux fichiers dans la grille et les instructions assembleur sont assimilées aux tâches de calcul.\\
Cell SuperScalar est constitué de deux composantes clés un compilateur source-to-source et une librairie de runtime. Le processeur de génération de code est illustré dans la figure [Citer Figure]. Partant d'un code source séquentiel écrit en langage C, des annotations en CellSS sont insérées dans le code. Le compilateur source-to-source est utilisé pour générer deux fichiers C distincts. Le premier correspond au programme principal de l'application , il est compilé par un compilateur PPE qui crée un objet pour ce même processeur. Le deuxième code source correspond à celui exécuté par le SPE sous contrôle du PPE. Cet exécutable enfouis dans le binaire du PPE pour pouvoir être exécuté. Cette procédure est la même que celle utilisée par le SDK d'IBM qui est basé sur deux compilateur distincts et une phase d'intégration du code SPE dans celui du PPE.\\
L'exécution du programme est assurée par le PPE qui assigne les \emph{task} aux SPEs au travers de la librairie de runtime. Le runtime se charge de créer un noeud qui correspond à la \emph{task} dans un graphe, et vérifie la dépendance avec une autre \emph{task} lancée auparavant et ajoute un arc entre les deux. Si la \emph{task} courante est prête à être exécutée le runtime envoie une requête au SPE pour qu'il se charge de l'exécution. Les transferts DMA sont gérés par le runtime de manière transparente. Les appels au runtime ne sont pas bloquants et de ce fait si une \emph{task} n'est pas prête ou tous les SPEs sont occupés le programme principal continue sont exécution.\\
On pourra noter que tout le processus (assignation de tâches, analyse des dépendances, transfert de données) sont transparents du point de vue de l'utilisateur, qui écrit un code séquentiel dans lequel il annote la partie à exécuter par les SPEs . Le système peut changer dynamiquement le nombre de SPEs utilisés en prenant en compte le maximum de concurrence contenu dans l'application à chaque phase.
\subsection{Runtime}
Au runtime, des appels à une fonction \emph{Execute} sera responsable du comportement de l'application sur le processeur Cell. Pour chaque appel à la fonction \emph{Execute} le runtime effectue les actions suivantes:
\begin{itemize}
\item L'addition d'un noeud dans un graphe des tâches qui représente la tâche appelée.
\item L'analyse des dépendances de données de la nouvelle tâche avec les tâches appelées précédemment. Cette analyse prend comme hypothèse que deux paramètres sont les mêmes s'ils ont la même adresse. Les système cherche les types de dépendances de données \emph{RaW}, \emph{WaR} et \emph{WaW} \footnote{Read after Write, Write after Read and Write after Write}.
\item Le renommage de paramètres similaire au renommage de registres, une technique issue des processeurs superscalaires, le renommage se fait sur les paramètres \emph{output} et \emph{input/output} pour chaque appel de fonction qui possède un paramètre qui va être écrit, au lieu d'écrire dans l'adresse originale de celui-ci, un emplacement mémoire nouveau sera utilisé, celui-ci sera un renommage de l'emplacement du paramètre original. Ceci permet l'exécution de la fonction indépendamment d'un appel précédent à une fonction qui écrit ou lit ce paramètre. Cette technique permet de ce fait de supprimer efficacement toutes les dépendances \emph{WaR} et \emph{WaW} en utilisant de l'espace mémoire supplémentaire et simplifie ainsi le graphe des dépendances et augmente les chances d'extraire du parallélisme.
\item Enfin, sous certaines conditions, la tâche peut être exécutée.
\end{itemize}
Durant l'exécution de l'application le runtime maintient une liste de tâches prêtes. Une tâche est étiquetée comme étant prête, à partir du moment où il n'existe aucune dépendance entre cette tâche et d'autres tâches ou alors que ces dépendances ont été résolues (les tâches précédentes dans le graphe on finit leur exécution). Le graphe de dépendance de tâches ainsi que la liste des tâches prêtes sont mis-à-jour à chaque fois qu'une tâche finit son exécution. Lorsqu'une tâche est terminée le runtime reçoit une notification et le graphe de tâche est vérifié pour établir les dépendances qui ont été satisfaites et les tâches dont toutes les dépendances ont été résolues et qui sont ajoutées dans la liste des tâches prêtes.\\
Etant donné une liste de tâches prêtes et une liste de ressources disponibles, le runtime choisit la meilleure correspondance entre les tâches et les ressources et soumet les tâches pour l'exécution. La soumission de la tâche comprend toutes les actions nécessaires pour pouvoir exécuter la tâche: le transfert des paramètres et la requête d'exécution de la tâche.
\subsubsection{Middleware pour le Cell}
Une application CellSS est composée de deux types de binaires exécutables : le programme principal, qui s'exécute sur le PPE et le programme tâche qui lui s'exécute sur le SPE. Ces binaires sont obtenus par compilation de deux sources générés par le compilateur CellSS et les librairies de runtime. Lors du démarrage du programme sur le PPE le programmes de type \emph{task} est lancé sur tous les SPEs durant l'exécution, celui-ci se met en attente de requêtes de la part du programme principal. Lorsque la politique d'ordonnancement choisit une \emph{task} de la liste des tâches prêtes à être lancées et un SPE sur lequel elle va être exécutée, une structure de donnée nommée \emph{task control buffer} est construite. Celle-ci contient des informations telles que l'identifiant de la tâche, l'adresse de chacun des paramètres ainsi que des informations de contrôle. L'identifiant sert à distinguer des tâches deja présente dans la mémoire des SPEs de celles qui en le sont pas et qui doivent être chargées avant exécution. Les requêtes à émanant du programme principal pour exécuter une tâche dans les SPE se font via mailbox, celle-ci contient l'adresse et la taille du \emph{task control buffer} correspondant à la tâche. L'exécution de la tâche se fait de la manière suivante: le SPE ses met en attente d'une requête sur la mailbox, une fois la requête reçue il rapatrie les données et éventuellement le code de la tâche une fois la tâche finie, selon le contenu du \emph{task control buffer} il garde les données dans sa mémoire ou les transfert en mémoire centrale. La synchronisation se fait à la fin de l'exécution et lorsque toutes les données résultats sont transférées ver la mémoire centrale.
\subsubsection{Exploitation de la Localité}
Lorsque le graphe de dépendance de tâches construit par CellSS contient un arc allant d'un noeud vers un autre, il existe une dépendance de données entre les tâches qui impose un transfers de données, le but étant de minimiser la quantité de données transférées entre le PPE et les SPEs et entre SPEs. La politique d'ordonnancement est faite de telle sorte à exploiter la localité et donc à regrouper quand c'est possible les tâche interdépendantes dans le même SPE.
\subsection{Conclusion}
CellSS est un modèle de programmation basé sur un compilateur et un runtime. Il permet l'exécution d'un code source séquentiel sur une architecture parallèle grâce à l'annotation de ce code par des directives de parallélisation. Le runtime construit un graphe de dépendances des fonctions appelées et ordonnances ses fonctions sur le SPE en gérant les transferts mémoire de manière transparente. L'algorithme d'ordonnancement exploite la localité afin de minimiser les transferts mémoire.
\section{\emph{Sequoia}}
\emph{\textbf{Sequoia}}\cite{sequoia_sc06} est un langage de programmation bas-niveau dédié aux machines modernes, que cela soit des processeurs parallèles ou alors superscalaires, et dans lesquels l'allocation de la mémoire et le transferts des données au travers de la hiérarchie mémoire est primordiale pour la performance.\emph{\textbf{Sequoia}} est une extension au langage C même si les constructions qu'il permet de faire sont très différentes du modèle de programmation du C. Il est basé sur un modèle de programmation qui assiste l'utilisateur dans la structuration des programmes parallèles efficaces au niveau de la bande passante qui restent portables sur de nouvelles machines. Le modèle de programmation repose sur quelques principes qui sont les suivants:
\begin{itemize}
\item La notion de mémoire hiérarchique est directement introduite dans le modèle de programmation ce qui permet un gain de portabilité et de performance. \emph{\textbf{Sequoia}} s'exécute sur des machines qui sont représentées sous forme d'un modèle abstrait en arbre de modules mémoire distincts qui décrit comment les données sont transférées et où elles résident dans la hiérarchie mémoire.
\item Les \emph{task} sont utilisées comme une abstraction des unités de calcul auto-suffisantes qui incluent la description des communications et de la charge de travail. La \emph{task} isole chaque calcul dans son propre espace mémoire local et contient le parallélisme.
\item Afin de garantir la portabilité, une stricte séparation est maintenue entre l'expression générique de l'algorithme et les optimisations spécifiques à une machine donnée. Pour minimiser l'impact de cette séparation sur la performance les détails du déploiement sur une machine spécifique sont sous le contrôle de l'utilisateur.
\end{itemize}
Ainsi, \emph{\textbf{Sequoia}} adopte une approche pragmatique pour fournir un outil de programmation parallèle portable en fournissant un ensemble limité d'abstractions qui peut être implémenté de manière efficace et sous contrôle de l'utilisateur.
\subsection{Mémoire Hiérarchique}
\begin{figure}[!htbf]
	\centering
	\includegraphics[scale =0.6]{Chapter1/Figures/Sequoia_fig1}
	\caption{Multiplication de matrices de tailles 1024x1024 structurée en hiérarchie de tâches indépendantes effectuant des multiplications sur des blocs de données plus petits}
  \label{seq_fig1}
\end{figure}
Le principe de mémoire hiérarchique est au coeur de l'outil \emph{\textbf{Sequoia}}, car dans les systèmes modernes contenant plusieurs unités de traitement avec une hiérarchie mémoire à plusieurs niveaux, il est primordial de diviser un calcul de taille importante en des opérations plus petites pour atteindre des bonnes performances car cela permet d'exposer le parallélisme et d'atténuer l'effet de la latence d'accès à la mémoire car les données sont physiquement proches des unités de traitement. Un exemple de découpage pour l'application produit de matrices est donné dans \ref{seq_fig1}, dans cet exemple qui contient du parallélisme imbriqué et où la localité des données est primordiale. \emph{\textbf{Sequoia}} requiert une telle réorganisation hiérarchique dans les programmes, qui a été inspirée de l'idée des \emph{space-limited procedures} qui prône les strategies \emph{divide-and-conquer} tenant compte de la hiérarchie mémoire. Les \emph{space-limited procedures} requièrent à chaque fonction dans une chaîne d'appels d'accepter des arguments occupant beaucoup moins d'espace mémoire que les fonctions appellantes. Un système complet a été implémenté autour de cette abstraction incluant un compilateur et un runtime pour le processeur Cell.\\
L'écriture d'un programme \emph{\textbf{Sequoia}} implique la description abstraite d'une hiérarchie de tâches et le mapping de ces tâches sur la hiérarchie mémoire de la machine cible. Cela impose à l'utilisateur de considerer une machine parallèle comme un arbre de modules mémoire distincts. Les transferts de données entre les niveaux de la hiérarchie se font par blocks éventuellement asynchrones. La logique du programme décrit le transfert des données à tous les niveaux, mais les noyaux de calcul sont contraints de travailles que sur les données qui sont sur les noeuds feuilles (de niveau 0) de l'arbre représentant la machine. La représentation abstraite du processeur Cell (Fig.\ref{seq_fig2}) contient des noeuds correspondants à la mémoire principale ainsi qu'à chaque mémoire locale du SPE.
\begin{figure}[!htbf]
	\centering
	\includegraphics[scale =0.6]{Chapter1/Figures/Sequoia_fig2}
	\caption{Modèle abstrait Sequoia du processeur Cell}
  \label{seq_fig2}
\end{figure}
Un code \emph{\textbf{Sequoia}} ne fait pas de référence explicite à un certain niveau de la hiérarchie et les transferts de données entre les modules mémoire se font de manière implicite. Ainsi, les communications décrites dans \emph{\textbf{Sequoia}} peut se faire au travers d'une instruction de prefetch, un transfert DMA ou un message MPI selon les spécificité de l'architecture cible. Ceci garantit la portabilité de l'application tout en bénéficiant des performances des communications explicites. Il y a certaines machines possedant une topologie qui n'est pas facilement representable sous forme d'arbre c'est pour cela que la notion de \emph{virtual level} (niveau virtuel) à été introduite dans \emph{\textbf{Sequoia}}, ce niveau ne correspond à aucune mémoire physique. Ce niveau permet par exemple de représenter l'aggregation des mémoires locales des SPEs sur processeur Cell. Cela permet de ce fait d'encapsuler les communications horizontales inter-noeud tout en gardant le modèle d'abstraction en arbre qui lui ne permet que des communications verticales.
\subsection{Modèles de Programmation}
La notion de \emph{task} est au coeur du modèle de programmation de \emph{\textbf{Sequoia}}: c'est une fonction exempt de tout effet de bord avec une sémantique de passage de paramètre par valeur. Les propriétés qui seront énoncées dans la suite garantissent la portabilité du modèle sans sacrifier les performances.
\subsubsection{Communication Explicite et Localité}
La définition d'une tâche exprime à la fois la localité et la communication dans un programme. Lorsqu'une tâche s'exécute, l'ensemble de toutes les données référencées doivent rester dans un seul noeud de l'arbre abstrait de la machine. Ainsi une tâche doit s'exécuter dans un endroit précis de la machine. Les pointeurs et les références ne sont pas permises à l'intérieur d'une tâche ce qui permet de dire que l'ensemble des données traitées par la tâche est contenu dans sa définition.\\
L'implémentation contient un appel récursif dans lequel un sous-ensemble des données est passé en paramètre. Les communications sont encapsulées par les tâche en utilisant une sémantique de passage de paramètre dit \emph{call-by-value-result} qui est un passage de paramètres par valeur dans lequel les copies locales des données sont réécrites dans l'espace global à la fin de l'appel de la fonction. Chaque tâche s'exécute dans son espace d'adresses local, toutes les données d'entrée des tâches appelantes sont copiées dans l'espace mémoire de la fonction appelée et les résultats sont recopiées vers l'espace mémoire de la fonction appelantes après le retour de la fonction appelées.\\
Le mapping d'un programme Sequoia dicte quand une tâche appelée doit exécutée dans le même module mémoire que la tâche appelante ou alors assignées à une mémoire enfant.
\subsubsection{Isolation et Parallélisme}
La granularité du parallélisme dans \emph{\textbf{Sequoia}} et la \emph{tâche} et l'exécution parallèle résulte de l'appel de \emph{tâches} concurrentes. Une tâche s'exécute généralement sur une partie de la boucle sous forme de plusieurs \emph{sous-tâches} parallèles, chaque \emph{sous-tâche} s'exécutant en isolation, une propriété qui garantit la portabilité et la performance. Une des contraintes imposées au modèles et que les tâches s'exécutant en parallèle ne peuvent pas coopérer entre elles car elles n'ont aucun moyen de communiquer. Ceci limite le modèle de programmation au modèle SPMD mais évite le recours aux mécanismes de synchronisation coûteuses.
\subsubsection{Décomposition de Tâche}
\emph{\textbf{Sequoia}} introduit des primitives de décomposition de tableaux et de mapping de tâches, elles sont décrites ci-dessous:\\
\noindent \rule{\textwidth}{0.2mm}\\
\textbf{Sequoia Blocking Primitives}\\
\begin{itemize}
\item \texttt{\textbf{blkset}}\\
Un objet Sequoia opaque représentant une collection de blocks de tableaux.\\
\item \texttt{\textbf{rchop(A, len0, len1, ...)}}\\
Génere un \texttt{\textbf{blkset}} qui contient des blocks qui ne se recouvrent pas et qui tuilent le tableau multidimensionnel A. Chaque block est multidimensionnel de taille \texttt{len0xlen1x ...}.
\item \texttt{\textbf{rchop(A, rchop\_t(offset0, len0, stride0), ...)}}\\
Généralisation de  \item \texttt{\textbf{rchop}} qui génere des ensembles de blocks qui contiennent potentiellement des blocks qui se recouvrent. L'offset du tableau de départ, la taille du block, et le saut entre les blocks est spécifié pour toutes ls dimensions du tableau source.
\item \texttt{\textbf{ichop(A, Starts, Ends, N)}}\\
Génère un ensemble de blocks du tableau A de tailles non régulières. Les indices de départ et de fin du block sont donnés par les éléments dans le tableau de longueur N \texttt{Starts} et \texttt{Ends}. 
\item \texttt{\textbf{gather(A, IdxBlkset)}}\\
Génère un ensemble de blocks en rassemblant les éléments d'un tableau source A en utilisant des indices fournis dans les blocks de \texttt{IdxBlkset}. Le \texttt{blkset } résultant possède les mêmes nombre et taille que les blocks de \texttt{IdxBlkset}.\\
\end{itemize}
\rule{\textwidth}{0.2mm}\\
\textbf{Sequoia Mapping Primitives}\\
\begin{itemize}
\item \texttt{\textbf{mappar(i=i0 to iM, j=j0 to jN ...)   {...}}}\\
Une boule for multi-dimensionnelle contenant uniquement un appel à une \emph{sous-tâche} dans le corps de boucle. La tâche est mappée en parallèle en une collection de blocks.
\item \texttt{\textbf{mapseq(i=i0 to iM, j=j0 to jN ...)   {...}}}\\
Une boule multi-dimensionnelle contenant uniquement un appel à une \emph{sous-tâche} dans le corps de boucle. La tâche est mappée séquentiellement en une collection de blocks.
\item \texttt{\textbf{mapreduce(i=i0 to iM, j=j0 to jN ...)   {...}}}\\
Permet de faire le mapping en une collection de blocks, qui effectue une réduction sur au moins un argument de la tâche. Pour le support des réductions d'arbres parallèles, une tâche supplémentaires de
 recombinaison est requise.\\
\end{itemize}
\rule{\textwidth}{0.2mm}\\
\subsubsection{Variantes de Tâches}
\emph{\textbf{Sequoia}} inclut deux types de tâches qui servent essentiellement à distinguer le code de mapping du code de calcul, elles sont décrites ci-dessous:
\begin{itemize}
\item \emph{Inner Tasks}: se sont les tâches qui appellent des sous-tâches. Elles n'ont pas d'accès direct à leurs arguments de type tableau mais elles passent aux sous-tâches sous forme de blocks. Les \emph{Inner Tasks} utilisent les primitives de \emph{mapping} et de \emph{blocking} pour structurer les calculs sous forme de sous-tâches. La définition d'une \emph{Inner Task} n'est associée à aucun module mémoire particulier de la machine, elle peu s'exécuter dans n'importe quel niveau de la hiérarchie mémoire dans lequel les données traitées tiennent.
\item \emph{Leaf Tasks}: se sont des tâches qui ne font pas appel à des sous-tâches et qui opèrent directement sur des données résident dans les niveaux feuilles de la hiérarchie mémoire. 
\end{itemize}
\subsubsection{Paramètrisation de Tâches}
Les tâches sont écrite de manière à ce qu'elles soient paramêtrables pour la spécialisation à de multiples machines cibles. La spécialisation est le processus de de création d'instances d'une tâche qui est personnalisé pour s'exécuter sur un certain niveau de la hiérarchie mémoire de la machine. La paramétrisation des tâches permet à une stratégie de décomposition décrite par une variante de tâche d'être appliquée dans différents contextes, rendant la tâche portable sur différentes machines et sur différentes niveaux de la hiérarchie mémoire d'une cible donnée. L'utilisation de paramètres comme la taille des tableaux ainsi que les paramètres ajustable decouple l'expression d'un algorithme de son implémentation sur une machine donnée.
\subsubsection{Spécialisation de Tâches et Tunning}
Dans \emph{\textbf{Sequoia}} on donne au programmeur le contrôle complet sur les phases de spécialisation et de tunning du code, au travers d'une phase dite de \emph{task mapping and specification} qui est créée par l'utilisateur pour une machine donnée est maintenue indépendamment du code source. En plus, cette phase permet au programmeur de fournir des directives d'optimisation et de tunning qui sont propres à une cible donnée. Les spécification de mapping ont pour but de donner à l'utilisateur un contrôle précis sur le mapping d'une hiérarchie de  tâches sur une machine en isolant les optimisations spécifiques à une cible donnée dans un autre endroit. Au lieu de confier le travail à un compilateur, \emph{\textbf{Sequoia}} permet au programmeur d'optimiser son code lui même afin d'obtenir les meilleurs performances possibles.

\section{Implémentation}
Dans l'implémentation de \emph{\textbf{Sequoia}} un compilateur source-to-source génére du code C qui s'interface avec un runtime spécifique à la plate-forme. Les paramètres d'entrée du compilateur sont un program \emph{\textbf{Sequoia}} ainsi que des spécifications de mapping sur la machine cible.
\subsection{Compilateur Cell et Runtime}
Les instances de tâches \emph{Inner} correspondant à la mémoire principale sont exécutées par le PPE alors que les instances correspondant au niveau mémoire des Local Store sont exécutées par les SPE. Les codes sources PPE et SPE sont compilés séparemment, un code binaire est ainsi combiné pour l'exécution, si toutefois le code SPE dépasse la capacité du local store il est découpé sous forme d'overlays. Le runtime est \emph{event driven}: un système de notification via mailbox est mis en place entre le PPE est les SPES, les tâches sont assignée par le PPE au SPE. Une fois que la notification est reçue un mécanisme du runtime charge le morceau de code à exécuter dans les SPEs et initie les transfers de données via DMA. Le système permet la superposition de transferts et de calculs afin d'améliorer les performances. Les mécanismes de synchronisation ne sont pas constamment utilisées entre les tâches, un seul point de synchronisation est requis lors de la fin des sections parallèles,ce qui minimise  l'overhead.
\subsection{Optimisations}
En plus de permettre au programmeur d'optimiser son implémentation des tâches dans \emph{\textbf{Sequoia}}, certaines optimisations qui à utiliser efficacement la mémoire sont utilisées, notamment l'optimisation des transferts au niveau d'un même niveau la hiérarchie mémoire, ou les copies inutiles sont détectées et supprimées. D'autres optimisation incluant le \emph{software-pipelining} et le déplacement des invariants de boucle sont effectués de manière statique à la compilation.
\section{Conclusion}
\emph{\textbf{Sequoia}} est un modèle de programmation qui tente d'allier la portabilité avec la performance pour le portage d'algorithmes sur des architectures parallèles. La performance est assurée par l'octroi à l'utilisateur d'une grande liberté dans l'optimisation du code de calcul qui s'exécute sur les noeuds au plus bas niveau de la hiérarchie mémoire. La portabilité est garantie par le fait que l'expression de l'algorithme est découplée de l'implémentation. L'expression explicite des communications, du mouvement des données au travers de la hiérarchie mémoire, du calcul parallèle et la définition d'un ensemble de travail isolé sont effectués grâce à une seule abstraction, la \emph{tâche}. \emph{\textbf{Sequoia}} fournit des primitives de structuration des calcul en tant que hiérarchie de tâches afin d'améliorer la localité et laisse au programmeur le soin d'optimiser la tâche pour une architecture donnée. Toutefois il existe des limitations, en l'occurrence pour le type de parallélisme qui doit être SIMD ce qui limite le schéma de déploiement et le champ d'applications. Aussi, le mapping des applications est fait de manière manuelle et n'est pas contenue dans le code source.