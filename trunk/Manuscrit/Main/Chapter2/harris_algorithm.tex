
Dans ce chapitre nous rentrons dans le vif du sujet, à savoir, la parallélisation de code de traitement d'images pour le processeur Cell. L'algorithme considéré est celui de la détection de points d'intérêts de Harris. Le choix de cet algorithme s'est fait selon plusieurs critères qui sont les suivants:
\begin{itemize}
\item C'est un algorithme de traitement d'images bas niveaux qu'on retrouve dans plusieurs applications plus complexes, comme la reconstructions 3D et le suivi d'objets.
\item Il est composé de blocs de traitement de base qui sont représentatifs des algorithmes bas niveau comme les opérateurs de convolution est les opérateurs point à point.
\item C'est un algorithme qui ne peux pas s'exécuter en temps réel sans optimisations spécifiques.
\end{itemize}
Etant donné les caractéristiques de l'architecture du Cell ainsi que celles de l'algorithme le but est de trouver la meilleure implémentation qui permet d'exploiter au mieux les dispositifs haute performance de l'architecture. Le processeur Cell est un vrai concentré de dispositifs accélerateurs parmi lesquels les unités SPE purement SIMD, les controleurs DMA permettant un parallélisme entre transferts mémoire et tâches de calculs ainsi que la multiplicité des coeurs qui permettent de répartir la charge de calcul de plusieurs manières possible soit sous frome de parallélisme de donnée uniquement, ou alors de parallélisme de tâches ou un mélange des deux.
\section{Algorithme de Harris}
La détection de point d'intéréts de Harris et Stephen \cite{harris_corner} est utilisée dans les systèmes de vision par ordinateur pour l'extraction de connaissance comme la détection de mouvement, correspondance d'images, suivi d'objets, reconstruction 3D et reconnaissance d'objets. Cet algorithme fut proposé pour palier aux manques de l'algorithme de Moravec \cite{moravec} qui était sensible au bruit et pas invariant à la rotation. Un coin peut être définit comme étant l'intersection de deux contours lorsque un point d'intérêt peut être définit comme un point ayant une position bien déterminée qui peut être détecté de manière robuste. Ainsi, le point d'intérêt peut être un coin mais aussi un point isolé d'intensité maximum ou minimum localement, une terminaison de ligne ou un point de courbe où la courbure est localement maximale.

\subsection{Description de l'Algorithme}
Si l'on considère des zones de l'images de dimensions $u \times v$ (dans notre cas $3 \times 3$ dans une images 2-dimensions en niveaux de gris $I$  qui est décalée de $(x, y)$, l'opérateur de Harris est basé sur l'estimation de l'autocorrélation locale $S$ dont l'équation est la suivante:
\begin{equation}
\label{eq_00}
S(x,y) =\sum\limits_{u}\sum\limits_{v} w(u,v)\left( I(u,v) - I(u-x,v-y) \right)^{2}
\end{equation}
Par l'approximation de $S$ avec une série de Taylor du second ordre la matrice de Harris $M$ est donnée par :
\begin{equation}
\label{eq_01}
M=\sum\limits_{u}\sum\limits_{v}w(u,v)\begin{bmatrix}I_{x}^{2}& I_{x}I_{y}\\I_{x}I_{y}&I_{y}^{2}\end{bmatrix}
\end{equation}
Un point d'intérêt est caractérisé par une large variation de $S$ dans toutes les directions du vecteur $(x,y)$. En analysant les valeurs propres de $M$, cette caractérisation peut être exprimée de la manière suivante. Soit $\lambda_{1}$, $\lambda_{2}$ les valeurs propres de $M$:
\begin{enumerate}
	\item Si $\lambda_{1}$ $\approx 0$ et $\lambda_{2}$ $\approx 0$ alors il n'y a pas de point d'intérêt au pixel $(x,y)$.
	\item Si $\lambda_{1}$ $\approx 0$ and $\lambda_{2}$ a une grande valeur positive alors un contour est retrouvé.
	\item Si $\lambda_{1}$ and $\lambda_{2}$ sont deux grandes valeurs positives distinctes alors un coin est détecté.
\end{enumerate}
Harris et Stephens ont constaté que le calcul des valeurs propres est coûteux car elle requiert le calcul d'une racine carrée, et ont proposé à la place l'algorithme suivant : 

\begin{enumerate}
\item Pour chaque pixel $(x, y)$ de l'image calculer la matrice de corrélation $M$:\\
\begin{equation}
\label{eq_03}
M=\begin{bmatrix} S_{xx} & S_{xy} \\ S_{xy} & S_{yy} \end{bmatrix}; \mbox{où:} S_{xx}=\left(\frac{\partial I}{\partial x}\right)^{2}\otimes w, S_{yy}=\left(\frac{\partial I}{\partial y}\right)^{2}\otimes w, S_{xy} = \left(\frac{\partial I}{\partial x}\frac{\partial I}{\partial y}\right)\otimes w
\end{equation}

Où	$\otimes$ est l'opérateur de convolution $w$ un noyau Gaussien.\\
\item Construire la carte de coarsité en calculant la mesure de coarsité $C(x, y)$ pour chaque pixel $(x, y)$:\\
\begin{equation}
\label{eq_04}
C(x,y)=det(M)-k(trace(M))^{2}
\end{equation}
\begin{eqnarray*}
det(M)=S_{xx}.S_{yy}-S_{xy}^{2}\\
trace(M)=S_{xx}+S_{yy}
\end{eqnarray*}
et $k$ une constante empirique.\\
\end{enumerate}
Une illustration d'une détection de points d'intérêt sur une image 512$\times$512 en niveaux de gris est donné en figure \ref{fig_house}. Afin d'obtenir ce résultat, deux étapes supplémentaires sont nécessaires qui permettent d'extraire une information visuelle à partir de la matrice $C(x,y)$\footnote{Ces étapes ont pour but de visualiser le résultat et ne sont donc pas incluses dans le graphe de l'algorithme}. Ces étapes sont les suivantes :
\begin{enumerate}
\item Seuillage de la carte d'intérêt en mettant toute les valeurs de $C(x,y)$ inférieurs à un seuil donné à zéro.
\item Extraction des maxima locaux en gardant les points qui sont plus grand que tous leurs voisins dans un voisinage 3$\times$3.
\end{enumerate}
\begin{figure}[!htb]
	\centering
\begin{tabular}{cc}
	\includegraphics[width= 0.5\columnwidth]{Chapter2/figures/house1} & \includegraphics[width= 0.5\columnwidth]{Chapter2/figures/house_harris_map}
	\end{tabular}
	\caption{Illustration de la détection de points d'intérêts sur une image niveaux de gris 512$\times$512}
	\label{fig_house}
\end{figure}

\subsection{Détails de l'Implémentation}
\begin{figure}[!htb]
	\centering
	\includegraphics[width= \columnwidth]{Chapter2/figures/harris_NB}
	\caption{Implémentation de l'algorithme de Harris sous forme de graphe flot de données}
	\label{fig_HarrisAlgorithm}
\end{figure}
Les images en niveaux de gris sont typiquement des données stockées une des entiers 8-it non signés et la sortie de l'algorithme de Harris est dans ce cas là un entier 32 bit signé. Toutefois, pour des raisons de limitation du jeux d'instruction du SPU, et afin de garantir une comparaison objective avec les extension Altivec et SSE nous avons choisi le format flottant simple précision pour l'entrée et la sortie de l'algorithme. Dans notre implémentation nous avons divisé l'algorithme en 4 noyaux de traitement : un opérateur de \emph{Sobel} qui représente la dérivée dans les directions horizontale et verticale, un opérateur de multiplication, un noyau de lisage de \emph{Gauss} ($w$ dans l'équation \ref{eq_03} suivi d'un opérateur de coarsité. Nous avons fixé la constante $k$ à zéro (typiquement elle est fixée à 0.04) car ceci n'avait pas d'influence sur le résultat qualitatif. On obtient ainsi le graphe flot de données donné dans la figure \ref{fig_HarrisAlgorithm} qui est représentatif d'un algorithme de traitement d'images bas niveau car il englobe des noyaux de convolution et des opérateurs point à point. Les noyaux de convolution de Sobel ($GradX$ et $GradY$)et le noyau de $Gauss$ sont définis comme suit: 
\begin{eqnarray*}
Grad_{X} = \begin{bmatrix}-1 & 0 & 1 \\ -2 & 0 & 2 \\ -1 & 0 & 1 \end{bmatrix}; Grad_{Y} = \begin{bmatrix}-1 & -2 & -1 \\ 0 & 0 & 0 \\ 1 & 2 & 1 \end{bmatrix}; Gauss = \frac{1}{16}\begin{bmatrix}1 & 2 & 1 \\ 2 & 4 & 2 \\ 1 & 2 & 1 \end{bmatrix}
\end{eqnarray*}
Etant donnée qu'ils consomment plus d'entrée qu'ils ne produisent de sorties, les noyaux de convolution sont le goulot d'étranglement de l'algorithme car elles augmentent considérablement le trafic mémoire. Au vu de la nature des calculs effectués dans les différents noyaux, et qui sont très simples généralement (une suite de multiplications/accumulation) on peut considérer que les instructions mémoire sont prépondérantes dans l'application et de ce fait on peut qualifier l'algorithme de \emph{memory-bounded problem} (problème limité par la mémoire). C'est pour cela que les efforts d'optimisation sur l'algorithme de Harris sont faites par l'optimisation des accès mémoire à différent niveaux de la hiérarchie mémoire du processeur Cell. 
\section{Exploitation du Parallélisme et Optimisations Multi-niveau}
Les techniques d'optimisation démontrées ici sont multiples et variées. Certaines sont de nature algorithmique et relèvent plutôt du domaine du traitement du signal et des images. D'autres techniques génériques relèvent plutôt du domaine de l'optimisation logicielle est qu'on retrouve par fois dans certains compilateurs optimisants. Les techniques précédentes sont générales et peuvent être appliqués à la majorité des processeurs généralistes car elle ne tiennent pas compte des aspects spécifiques d'une architecture donnée. Par contre, des optimisations de plus haut niveau et qui sont spécifiques à l'architecture particulière du Cell ont aussi été employées. Celles-ci ne sont généralement pas reproductibles sur d'autres architectures parallèles car elle relèvent plus d'une adéquation entre l'algorithme et l'architecture qui contient certains dispositifs qui n'existent que sur le Cell et des fois elles résultent de contraintes de programmation spécifiques au Cell comme la taille limitée des mémoire locale des SPEs et par conséquent la gestion logicielle de l'utilisation de la mémoire.
\subsection{Techniques Spécifiques au Domaine}
Ces optimisations relèvent plutôt du domaine du traitement du signal et des images. Elles peuvent donc être appliquées à plusieurs algorithmes et sur n'importe quelle architecture. Celles que nous avons utilisé concernent les noyaux de convolution et sont : la séparabilité, le chevauchement (overlapping) et la factorisation des calculs.
\subsubsection{Séparabilité des Noyaux}
\begin{figure}[!htb]
	\centering
	\includegraphics[width= \columnwidth]{Chapter2/figures/convolution_sep}
	\caption{Exemple de convolution par un filtre Gaussien $3\times3$ (a)version avec noyaux 2D (b) version avec deux noyaux 1D , résultant de la séparation du noyau 2D.}
	\label{fig_convosep}
\end{figure}
Cette optimisation consiste à exploiter le fait que les noyaux de convolution 2D de \emph{Sobel} \emph{Gauss} soient séparables en deux filtre de convolution 1D (Fig. \ref{fig_convosep}). Ainsi, la matrice des coefficients peut être exprimée comme un produit de deux vecteur comme l'illustre les équations suivantes :
\begin{eqnarray*}
Grad_{X} =  \frac{1}{  8} \begin{bmatrix} -1 &  0 &   1  \\ -2 & 0 & 2 \\ -1 & 0 & 1 \end{bmatrix} =    \frac{1}{8} \begin{bmatrix} -1 \\ 0 \\ 1 \end{bmatrix} \times  \begin{bmatrix} 1 & 2 & 1 \end{bmatrix};
Grad_{Y} =  \frac{1}{  8} \begin{bmatrix} -1 & -2 & -1   \\  0 & 0 & 0 \\  1 & 2 & 1 \end{bmatrix}  =   \frac{1}{8} \begin{bmatrix} 1 \\ 2 \\ 1 \end{bmatrix} \times  \begin{bmatrix} -1 & 0 & 1 \end{bmatrix}\\
Gauss      =  \frac{1}{16} \begin{bmatrix}  1 &  2 &   1  \\  2 & 4 & 2 \\  1 & 2 & 1 \end{bmatrix} = \frac{1}{16}\begin{bmatrix}1 \\ 2 \\ 1 \end{bmatrix} \times \begin{bmatrix}1  & 2 & 1 \end{bmatrix}
\end{eqnarray*}
Lorsqu'on sépare les noyaux de convolutions le calcul se fait en deux passes une pour chaque vecteur. Grâce à la séparabilité des noyaux on arrive à réduire le nombre d'instructions mémoire ainsi que la complexité arithmétique. La comparaison est illustrée dans les tableaux \ref{tab_sepa_arith} et \ref{tab_sepa_mem}.
\begin{table}
\centering
\begin{tabular}{|c|c|c||c|c|c|c|}
\multicolumn{7}{c}{\textbf{Complexité arithmétique filtre de \emph{Sobel}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau}} & \emph{Gain \%}\\
\hline
\textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total}& \textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total}  & \multirow{2}{*}{\textbf{75}}\\
\cline{1-6}
 2  & 5 & 7  & 1  & 3 & 4  & \\
\hline
\multicolumn{7}{c}{\textbf{Complexité arithmétique filtre de \emph{Gauss}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau}}  & \emph{Gain \%} \\
\hline
\textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total}& \textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total} &   \multirow{2}{*}{\textbf{116}} \\
\cline{1-6}
 8  & 5 & 13  & 2  & 4 & 6  &  \\
\hline
\end{tabular}
\label{tab_sepa_arith}
\caption{Réduction de la complexité arithmétique par séparabilité des noyaux}
\end{table}

\begin{table}
\centering
\begin{tabular}{|c|c|c||c|c|c|c|}
\multicolumn{7}{c}{\textbf{Complexité mémoire filtre de \emph{Sobel}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau}} & \emph{Gain \%}\\
\hline
\textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}& \textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}  & \multirow{2}{*}{\textbf{0}}\\
\cline{1-6}
 6  & 1 & 7  & 1  & 5 & 2  & \\
\hline
\multicolumn{7}{c}{\textbf{Complexité mémoire filtre de \emph{Gauss}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau}}  & \emph{Gain \%} \\
\hline
\textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}& \textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total} &   \multirow{2}{*}{\textbf{25}} \\
\cline{1-6}
 9  & 1 & 10  & 6  & 1 & 8  &  \\
\hline
\end{tabular}
\label{tab_sepa_mem}
\caption{Réduction de la complexité mémoire par séparabilité des noyaux}
\end{table}

\subsubsection{Chevauchement des Noyaux}
\begin{figure}[!htb]
	\centering
	\includegraphics[width= \columnwidth]{Chapter2/figures/convolution_overlap}
	\caption{Chevauchement des données pour un calcul d'un filtre Gaussien $3\times3$, certaines données sont conservées en décalant le masque de convolution.}
	\label{fig_convoover}
\end{figure}
La deuxième particularité des noyaux de convolution est une notion de chevauchement qui permet d'avoir une redondance d'une partie des données (Fig. \ref{fig_convoover}). En effet, comme le démontre la figure \ref{fig_ovelapping}, à chaque itération du calcul de la convolution il n'y a qu'une seule nouvelle colonne chargée. Les colonnes redondantes sont copiées dans les registres en les décalant d'un pas à droite par rapport à leur position précédente (\emph{rotation de registres}). On notera que le même type d'optimisation peut se faire grâce à un \emph{déroulage de boucle}.
\begin{table}
\centering
\begin{tabular}{|c|c|c||c|c|c|c|}
\multicolumn{7}{c}{\textbf{Complexité mémoire filtre de \emph{Sobel}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans chevauchement du noyau}} & \multicolumn{3}{|c|}{\emph{Avec chevauchement du noyau}} & \emph{Gain \%}\\
\hline
\textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}& \textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}  & \multirow{2}{*}{\textbf{133}}\\
\cline{1-6}
 6  & 1 & 7  & 2  & 1 & 3  & \\
\hline
\multicolumn{7}{c}{\textbf{Complexité mémoire filtre de \emph{Gauss}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans chevauchement du noyau}} & \multicolumn{3}{|c|}{\emph{Avec chevauchement du noyau}}  & \emph{Gain \%} \\
\hline
\textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}& \textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total} &   \multirow{2}{*}{\textbf{150}} \\
\cline{1-6}
 9  & 1 & 10  & 3  & 1 & 4  &  \\
\hline
\end{tabular}
\label{tab_over_mem}
\caption{Réduction de la complexité mémoire par chevauchement des noyaux}
\end{table}
\subsubsection{Séparation des noyaux et chevauchement}
Cette optimisation n'est en fait qu'une combinaison des deux précédentes. En effet on profite d'une part du fait que les noyaux soient séparables pour réduire la complexité arithmétique, et d'autre part du chevauchement des noyaux pour mémoriser le résultat précédent. Ainsi, au lieu de mémoriser les deux dernières colonnes, on mémorise le résultat du filtrage par le premier filtre 1D pour le réutiliser à l'itération suivante de la boucle. Dans ce cas là; la compléxité arithmétique est la même que celle de la version avec séparation des noyaux, alors que la complexité mémoire est réduite d'avantage.
Les tableau \ref{tab_sepaover_arith} et \ref{tab_sepaover_mem} donnent la différence en terme de complexité arithmétique et mémoire entre la version de base de l'algorithme est la version tenant compte des deux optimisations combinées.
\begin{table}
\centering
\begin{tabular}{|c|c|c||c|c|c|c|}
\multicolumn{7}{c}{\textbf{Complexité arithmétique filtre de \emph{Sobel}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau + chevauchement}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau + chevauchement}} & \emph{Gain \%}\\
\hline
\textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total}& \textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total}  & \multirow{2}{*}{\textbf{75}}\\
\cline{1-6}
 2  & 5 & 7  & 1  & 3 & 4  & \\
\hline
\multicolumn{7}{c}{\textbf{Complexité arithmétique filtre de \emph{Gauss}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau + chevauchement}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau + chevauchement}}  & \emph{Gain \%} \\
\hline
\textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total}& \textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total} &   \multirow{2}{*}{\textbf{116}} \\
\cline{1-6}
 8  & 5 & 13  & 2  & 4 & 6  &  \\
\hline
\end{tabular}
\label{tab_sepaover_arith}
\caption{Réduction de la complexité arithmétique par séparabilité et chevauchement des noyaux}
\end{table}

\begin{table}
\centering
\begin{tabular}{|c|c|c||c|c|c|c|}
\multicolumn{7}{c}{\textbf{Complexité mémoire filtre de \emph{Sobel}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau + chevauchement}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau + chevauchement }} & \emph{Gain \%}\\
\hline
\textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}& \textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}  & \multirow{2}{*}{\textbf{250}}\\
\cline{1-6}
 6  & 1 & 7  & 1  & 1 & 2  & \\
\hline
\multicolumn{7}{c}{\textbf{Complexité mémoire filtre de \emph{Gauss}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau + chevauchement}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau + chevauchement }}  & \emph{Gain \%} \\
\hline
\textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}& \textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total} &   \multirow{2}{*}{\textbf{400}} \\
\cline{1-6}
 9  & 1 & 10  & 1  & 1 & 2  &  \\
\hline
\end{tabular}
\label{tab_sepaover_mem}
\caption{Réduction de la complexité mémoire par séparabilité et chevauchement des noyaux}
\end{table}
\subsubsection{Composition de Fonctions}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= \columnwidth]{Chapter2/figures/funccompo}
  	\label{fig_compo}
	\caption{Règle de composition de fonctions.\textbf{(a)} composition de deux opérateurs point à point \textbf{(b)} composition d'un noyaux de convolution suivi d'un opérateur point à point \textbf{(c)} composition d'un opérateur point à point  suivi d'un noyaux de convolution \textbf{(d)} composition de deux noyaux de convolution successifs}

\end{figure}
Cette technique d'optimisation s'avère très efficace surtout dans les codes ou les instructions mémoire sont prépondérantes. En effet, le fait de composer deux fonctions de calcul pour en faire une seule qui effectue les deux calculs réduit considérablement le nombre d'accès mémoire puisque les opérations de sauvegarde et de chargement intermédiaires entre les deux fonctions initiales sont supprimées, et la transaction se fait au niveaux des registres. De plus, le coût de l'appel de fonction (taille de la pile, et branchement) est également réduit, car le résultat de la composition de fonctions et une seule fonction. Dans les cas les plus simples, la mise en oeuvre de cette technique n'est pas difficile. Toutefois, lorsqu'il s'agit d'opérateurs de convolution comme dans notre cas, des nouvelles contraintes apparaissent afin de garantir la validité du résultat du calcul. Ainsi, des règles de composition s'imposent en fonction de l'ordre dans lequel s'enchaînent les fonctions. Ces règles sont illustrées sur la figure \ref{fig_compo}. On peut alors constater qu'il existe plusieurs règles de composition des fonctions selon d'une part : la nature des opérateurs mis en jeu et d'autre part l'ordre dans lequel il s'enchaînent. En terme d'apport de cette technique en terme de performances nous observons deux aspects distincts:
\begin{itemize}
\item \textbf{Complexité mémoire} : on observe en effet que ceux ci sont systématiquement réduits, car les opérations de \texttt{LOAD/STORE} intermédiaires sont supprimés, sauf dans le cas de la composition de deux noyaux de convolution (cas \textbf{(d)} sur la figure \ref{fig_compo})ou la présence de bords supplémentaires augmente considérablement le nombre des accès mémoire.
\item \textbf{Complexité arithmétique} : Cele-ci ne change pas dans le meilleurs des cas notamment lorsque les opérateurs composées sont point à point ou alors lorsque l'opérateur de convolution est placé devant un opérateur point à point (cas \textbf{(b)} sur la figure \ref{fig_compo}). Toutefois, si la convolution est placée à la suite d'un quelconque traitement, elle impose que l'opérateur qui la précède soit effectué sur tous les pixels de voisinage, ce qui augmente considérablement la complexité arithmétique, en particulier lorsque l'opérateur qui précède est une convolution (cas \textbf{(d)} sur la figure \ref{fig_compo}).
\end{itemize}
D'après les observations ci-dessus, la composition de fonction peut être un bon choix pour l'optimisation d'une chaîne de traitement telle que l'algorithme de detection de point d'intérêts de Harris. Toutefois, toutes les combinaisons n'apportent pas forcément une amélioration des performances, elle peuvent même dans certains cas les dégrader. Le tableau \ref{tab_memall} résume les complexité mémoire et arithmétiques des différents cas de composition sur la figure \ref{fig_compo} en incluant également les optimisations décrites auparavant.
\begin{table}
\centering
\begin{tabular}{|c||c|c|c|c|}
\hline
\multicolumn{5}{|c|}{\textbf{Version de base sans composition}}\\
\hline
\textbf{Opérateur} & \textbf{Occurrences} & \textbf{\texttt{LOADS}} & \textbf{\texttt{STORE}} & \textbf{Total}\\
\hline
\emph{Sobel} & 2 & 6 & 1 & 14\\
\hline
\emph{Mul} & 3 & 2 & 1 & 9\\
\hline
\emph{Gauss} & 3 & 9 & 1 & 30\\
\hline
\emph{Coarsity} & 1 & 3 & 1 & 4\\
\hline
\emph{Harris} & 1 & 48 & 9 & 57\\
\hline
\multicolumn{5}{|c|}{\textbf{Version avec chevauchement et séparation des noyaux sans composition}}\\
\hline
\textbf{Opérateur} & \textbf{Occurrences} & \textbf{\texttt{LOADS}} & \textbf{\texttt{STORE}} & \textbf{Total}\\
\hline
\emph{Sobel} & 1 & 3 & 2 & 5\\
\hline
\emph{Mul} & 3 & 2 & 1 & 6\\
\hline
\emph{Gauss} & 3 & 3 & 1 & 12\\
\hline
\emph{Coarsity} & 1 & 3 & 1 & 4\\
\hline
\emph{Harris} & 1 & 21 & 9 & 30\\
\hline
\multicolumn{5}{|c|}{\textbf{Version avec composition de Sobel$\circ$Mul et Gauss$\circ$Coarsity}}\\
\hline
\textbf{Opérateur} & \textbf{Occurrences} & \textbf{\texttt{LOADS}} & \textbf{\texttt{STORE}} & \textbf{Total}\\
\hline
\emph{Sobel$\circ$Mul} & 1 & 9 & 3 & 12\\
\hline
\emph{Gauss$\circ$Coarsity} & 3 & 9 & 1 & 28\\
\hline
\emph{Harris} & 1 & 36 & 4 & 40\\
\hline
\multicolumn{5}{|c|}{\textbf{Version avec chevauchement et séparation + composition de Sobel$\circ$Mul et Gauss$\circ$Coarsity}}\\
\hline
\textbf{Opérateur} & \textbf{Occurrences} & \textbf{\texttt{LOADS}} & \textbf{\texttt{STORE}} & \textbf{Total}\\
\hline
\emph{Sobel$\circ$Mul} & 1 & 3 & 3 & 6\\
\hline
\emph{Gauss$\circ$Coarsity} & 3 & 3 & 1 & 10\\
\hline
\emph{Harris} & 1 & 12 & 4 & 16\\
\hline
\multicolumn{5}{|c|}{\textbf{Version avec composition de Sobel$\circ$Mul$\circ$Gauss$\circ$Coarsity}}\\
\hline
\textbf{Opérateur} & \textbf{Occurrences} & \textbf{\texttt{LOADS}} & \textbf{\texttt{STORE}} & \textbf{Total}\\
\hline
\emph{Sobel$\circ$Mul$\circ$Gauss$\circ$Coarsity} & 1 & 25 & 1 & 26\\
\hline
\emph{Harris} & - & - & - & 26\\
\hline
\multicolumn{5}{|c|}{\textbf{Version avec chevauchement et séparation + composition de Sobel$\circ$Mul$\circ$Gauss$\circ$Coarsity}}\\
\hline
\textbf{Opérateur} & \textbf{Occurrences} & \textbf{\texttt{LOADS}} & \textbf{\texttt{STORE}} & \textbf{Total}\\
\hline
\emph{Sobel$\circ$Mul$\circ$Gauss$\circ$Coarsity} & 1 & 5 & 1 & 6\\
\hline
\emph{Harris} & - & - & - & 6\\
\hline
\end{tabular}
\label{tab_memall}
\caption{Tableau récapitulatif de l'optimisation des accès mémoire en combinant l'ensemble des optimisations}
\end{table}
\subsection{Optimisation des Transferts Mémoire}
Dans cette partie, nous abordons des techniques d'optimisations qui sont relatives au transferts de données présents dans l'application. On entend, par transfert de donnée, toute communication qui met en jeu deux mémoires physiques sur Cell. Cela comporte les transferts DMA entre la mémoire principale, et les mémoires locales des SPEs, comme les communications mettant en jeu deux mémoires privées de SPEs. Plusieurs aspects sont mis en avant. D'une part, les caractéristiques internes de l'architecture du réseaux de communications \cite{cellnoc} (\emph{Network On Chip (NoC)}) du Cell et d'autres part la nature des transferts de données imposées par l'algorithme et d'autre part la partition des données à plusieurs niveaux de la hiérarchie mémoire.
\subsubsection{Optimisation de la Bande-Passante du \emph{NoC}}
Dans le modèle de programmation utilisé qui est basé sur le \emph{SDK} du Cell et les librairies \emph{libspe}, les données présentes en mémoire centrale sont transférées au mémoires locales des SPEs avant d'être traitées. Ces transferts se font d'une manière explicite dans le logiciel par appel à des fonctions de l'API de gestion du \emph{MFC} et ils sont gérées par le \emph{Noc} au travers de contrôleurs mémoire et de l'arbitre de bus. L'architecture du Bus et la topologie du réseau impose quelques contraintes qui jouent un rôle primordial dans la minimisation des latences des communications point à point.
\paragraph{Taille du Transfert}
Le premier paramètre influant sur la bande passante est la taille du bloc de données transféré. 

\subsection{Schémas de Parallélisation}
\paragraph{SPMD Conventionnel}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= \columnwidth]{Chapter2/figures/harris-spmd}
  \label{harris-spmd}
	\caption{Scéma de Parallélisation SPMD Conventionnel}
\end{figure}
Dans ce schéma de déploiement l'image est divisée en 8 regions de même taille, afin que chacun des 8 SPEs ait une charge de calcul équivalente. Tous les SPEs exécutent le même code. Les opérateurs sont exécutés successivement sur l'image entière l'un après l'autre. A titre d'exemple l'opérateur de multiplication n'est exécuté que lorsque le calcul du filtre de \emph{Sobel} est achevé sur toute l'image. Ce modèle de calcul est dit \emph{data-parallel} car les données sont envoyées en parallèle sur les SPEs et traitées de manière complètement indépendantes les unes des autres. Toutefois, la bande passante sur le bus mémoire centrale vers \emph{locale store} est beaucoup sollicitées car les données sont systématiquement lues et écrites avant et après chaque opérateur.
\paragraph{Pipeline Conventionnel}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= \columnwidth]{Chapter2/figures/harris-pipeline}
	\caption{Scéma de Parallélisation Pipeline}
	\label{harris-pipeline}
\end{figure}
Cette implémentation de l'algorithme consiste à déployer le graphe d'opérateur sous forme de pipeline. L'image n'est pas subdivisée en régions de traitement mais chaque tuile traitée traverse le pipeline avant qu'une nouvelle tuile ne puisse l'être. L'algorithme est par conséquent fortement séquentialisé. Par contre la bande-passante inter-SPEs est bien exploitée car la majorité des transferts se font entre SPEs et par conséquent la pression exercée sur le bus précédemment est atténuée car elle est répartie sur l'ensemble de l'anneau.
\subsubsection{Chaînage d'opérateur par paires}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= \columnwidth]{Chapter2/figures/harris-hchain}
	\caption{Scéma de Parallélisation Chaînage d'opérateurs par paires}
	\label{harris-pipeline}
\end{figure}
Dans cette version deux opérateurs successifs sont placés sur le même SPE. Ainsi, les opérateur \emph{Sobel} et \emph{Mul} sont placé sur un même SPE et \emph{Gauss} et \emph{Coarsity} sont placés sur un autre SPE. Le nombre de SPEs dans un processeur Cell étant de 8, ce schéma permet d'avoir 4 regions de l'image traitées en parallèle. Si l'on compare cette version à la précédente, on notera que la pression sur le bus d'interconnexion est plus importantes car les transferts concurrents sont plus nombreux et par conséquent le risque de contention du bus est plus probable.
\subsubsection{Chaînage et fusion d'opérateur par paires}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= 0.6\columnwidth]{Chapter2/figures/harris-hchainhpipe}
	\caption{Scéma de Parallélisation Chaînage et fusion d'opérateurs par paires}
	\label{harris-pipeline}
\end{figure}
Cette version est une variante de celle qui la précède. L'idée étant de fusionner les opérateurs présent sur un même SPE, et ce afin d'éliminer les instructions de \texttt{LOAD} et \texttt{STORE} présent à la sortie de du premier et à l'entrée du second. De ce fait, le nombre de cycles peut être considérablement réduit, surtout lorsque l'on sait que la latence des instructions mémoire est de 6 cycles sur les SPE \cite{cell_handbook}.
\subsubsection{Chaînage entier et fusion d'opérateur par paires}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= 0.6\columnwidth]{Chapter2/figures/harris-hchainfpipe}
	\caption{Scéma de Parallélisation Chaînage et fusion d'opérateurs par paires}
	\label{harris-pipeline}
\end{figure}
Dans cette implémentation tous les opérateurs sont exécutés sur le même SPE. D'une part ceci permet d'éviter les transferts DMA entre SPE et minimise donc les transactions sur le bus d'interconnexion. 