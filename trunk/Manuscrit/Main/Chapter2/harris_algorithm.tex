
Dans ce chapitre nous rentrons dans le vif du sujet, à savoir, la parallélisation de code de traitement d'images pour le processeur Cell. L'algorithme considéré est celui de la détection de points d'intérêts de Harris. Le choix de cet algorithme s'est fait selon plusieurs critères qui sont les suivants:
\begin{itemize}
\item C'est un algorithme de traitement d'images bas niveaux qu'on retrouve dans plusieurs applications plus complexes, comme la reconstructions 3D et le suivi d'objets.
\item Il est composé de blocs de traitement de base qui sont représentatifs des algorithmes bas niveau comme les opérateurs de convolution est les opérateurs point à point.
\item C'est un algorithme qui ne peux pas s'exécuter en temps réel sans optimisations spécifiques.
\end{itemize}
Etant donné les caractéristiques de l'architecture du Cell ainsi que celles de l'algorithme le but est de trouver la meilleure implémentation qui permet d'exploiter au mieux les dispositifs haute performance de l'architecture. Le processeur Cell est un vrai concentré de dispositifs accélerateurs parmi lesquels les unités SPE purement SIMD, les controleurs DMA permettant un parallélisme entre transferts mémoire et tâches de calculs ainsi que la multiplicité des coeurs qui permettent de répartir la charge de calcul de plusieurs manières possible soit sous frome de parallélisme de donnée uniquement, ou alors de parallélisme de tâches ou un mélange des deux.
\section{Algorithme de Harris}
La détection de point d'intéréts de Harris et Stephen \cite{harris_corner} est utilisée dans les systèmes de vision par ordinateur pour l'extraction de connaissance comme la détection de mouvement, correspondance d'images, suivi d'objets, reconstruction 3D et reconnaissance d'objets. Cet algorithme fut proposé pour palier aux manques de l'algorithme de Moravec \cite{moravec} qui était sensible au bruit et pas invariant à la rotation. Un coin peut être définit comme étant l'intersection de deux contours lorsque un point d'intérêt peut être définit comme un point ayant une position bien déterminée qui peut être détecté de manière robuste. Ainsi, le point d'intérêt peut être un coin mais aussi un point isolé d'intensité maximum ou minimum localement, une terminaison de ligne ou un point de courbe où la courbure est localement maximale.

\subsection{Description de l'Algorithme}
Si l'on considère des zones de l'images de dimensions $u \times v$ (dans notre cas $3 \times 3$ dans une images 2-dimensions en niveaux de gris $I$  qui est décalée de $(x, y)$, l'opérateur de Harris est basé sur l'estimation de l'autocorrélation locale $S$ dont l'équation est la suivante:
\begin{equation}
\label{eq_00}
S(x,y) =\sum\limits_{u}\sum\limits_{v} w(u,v)\left( I(u,v) - I(u-x,v-y) \right)^{2}
\end{equation}
Par l'approximation de $S$ avec une série de Taylor du second ordre la matrice de Harris $M$ est donnée par :
\begin{equation}
\label{eq_01}
M=\sum\limits_{u}\sum\limits_{v}w(u,v)\begin{bmatrix}I_{x}^{2}& I_{x}I_{y}\\I_{x}I_{y}&I_{y}^{2}\end{bmatrix}
\end{equation}
Un point d'intérêt est caractérisé par une large variation de $S$ dans toutes les directions du vecteur $(x,y)$. En analysant les valeurs propres de $M$, cette caractérisation peut être exprimée de la manière suivante. Soit $\lambda_{1}$, $\lambda_{2}$ les valeurs propres de $M$:
\begin{enumerate}
	\item Si $\lambda_{1}$ $\approx 0$ et $\lambda_{2}$ $\approx 0$ alors il n'y a pas de point d'intérêt au pixel $(x,y)$.
	\item Si $\lambda_{1}$ $\approx 0$ and $\lambda_{2}$ a une grande valeur positive alors un contour est retrouvé.
	\item Si $\lambda_{1}$ and $\lambda_{2}$ sont deux grandes valeurs positives distinctes alors un coin est détecté.
\end{enumerate}
Harris et Stephens ont constaté que le calcul des valeurs propres est coûteux car elle requiert le calcul d'une racine carrée, et ont proposé à la place l'algorithme suivant : 

\begin{enumerate}
\item Pour chaque pixel $(x, y)$ de l'image calculer la matrice de corrélation $M$:\\
\begin{equation}
\label{eq_03}
M=\begin{bmatrix} S_{xx} & S_{xy} \\ S_{xy} & S_{yy} \end{bmatrix}; \mbox{où:} S_{xx}=\left(\frac{\partial I}{\partial x}\right)^{2}\otimes w, S_{yy}=\left(\frac{\partial I}{\partial y}\right)^{2}\otimes w, S_{xy} = \left(\frac{\partial I}{\partial x}\frac{\partial I}{\partial y}\right)\otimes w
\end{equation}

Où	$\otimes$ est l'opérateur de convolution $w$ un noyau Gaussien.\\
\item Construire la carte de coarsité en calculant la mesure de coarsité $C(x, y)$ pour chaque pixel $(x, y)$:\\
\begin{equation}
\label{eq_04}
C(x,y)=det(M)-k(trace(M))^{2}
\end{equation}
\begin{eqnarray*}
det(M)=S_{xx}.S_{yy}-S_{xy}^{2}\\
trace(M)=S_{xx}+S_{yy}
\end{eqnarray*}
et $k$ une constante empirique.\\
\end{enumerate}
Une illustration d'une détection de points d'intérêt sur une image 512$\times$512 en niveaux de gris est donné en figure \ref{fig_house}. Afin d'obtenir ce résultat, deux étapes supplémentaires sont nécessaires qui permettent d'extraire une information visuelle à partir de la matrice $C(x,y)$\footnote{Ces étapes ont pour but de visualiser le résultat et ne sont donc pas incluses dans le graphe de l'algorithme}. Ces étapes sont les suivantes :
\begin{enumerate}
\item Seuillage de la carte d'intérêt en mettant toute les valeurs de $C(x,y)$ inférieurs à un seuil donné à zéro.
\item Extraction des maxima locaux en gardant les points qui sont plus grand que tous leurs voisins dans un voisinage 3$\times$3.
\end{enumerate}
\begin{figure}[!htb]
	\centering
\begin{tabular}{cc}
	\includegraphics[width= 0.5\columnwidth]{Chapter2/figures/house1} & \includegraphics[width= 0.5\columnwidth]{Chapter2/figures/house_harris_map}
	\end{tabular}
	\caption{Illustration de la détection de points d'intérêts sur une image niveaux de gris 512$\times$512}
	\label{fig_house}
\end{figure}

\subsection{Détails de l'Implémentation}
\begin{figure}[!htb]
	\centering
	\includegraphics[width= \columnwidth]{Chapter2/figures/harris_NB}
	\caption{Implémentation de l'algorithme de Harris sous forme de graphe flot de données}
	\label{fig_HarrisAlgorithm}
\end{figure}
Les images en niveaux de gris sont typiquement des données stockées une des entiers 8-it non signés et la sortie de l'algorithme de Harris est dans ce cas là un entier 32 bit signé. Toutefois, pour des raisons de limitation du jeux d'instruction du SPU, et afin de garantir une comparaison objective avec les extension Altivec et SSE nous avons choisi le format flottant simple précision pour l'entrée et la sortie de l'algorithme. Dans notre implémentation nous avons divisé l'algorithme en 4 noyaux de traitement : un opérateur de \emph{Sobel} qui représente la dérivée dans les directions horizontale et verticale, un opérateur de multiplication, un noyau de lisage de \emph{Gauss} ($w$ dans l'équation \ref{eq_03} suivi d'un opérateur de coarsité. Nous avons fixé la constante $k$ à zéro (typiquement elle est fixée à 0.04) car ceci n'avait pas d'influence sur le résultat qualitatif. On obtient ainsi le graphe flot de données donné dans la figure \ref{fig_HarrisAlgorithm} qui est représentatif d'un algorithme de traitement d'images bas niveau car il englobe des noyaux de convolution et des opérateurs point à point. Les noyaux de convolution de Sobel ($GradX$ et $GradY$)et le noyau de $Gauss$ sont définis comme suit: 
\begin{eqnarray*}
Grad_{X} = \begin{bmatrix}-1 & 0 & 1 \\ -2 & 0 & 2 \\ -1 & 0 & 1 \end{bmatrix}; Grad_{Y} = \begin{bmatrix}-1 & -2 & -1 \\ 0 & 0 & 0 \\ 1 & 2 & 1 \end{bmatrix}; Gauss = \frac{1}{16}\begin{bmatrix}1 & 2 & 1 \\ 2 & 4 & 2 \\ 1 & 2 & 1 \end{bmatrix}
\end{eqnarray*}
Etant donnée qu'ils consomment plus d'entrée qu'ils ne produisent de sorties, les noyaux de convolution sont le goulot d'étranglement de l'algorithme car elles augmentent considérablement le trafic mémoire. Au vu de la nature des calculs effectués dans les différents noyaux, et qui sont très simples généralement (une suite de multiplications/accumulation) on peut considérer que les instructions mémoire sont prépondérantes dans l'application et de ce fait on peut qualifier l'algorithme de \emph{memory-bounded problem} (problème limité par la mémoire). C'est pour cela que les efforts d'optimisation sur l'algorithme de Harris sont faites par l'optimisation des accès mémoire à différent niveaux de la hiérarchie mémoire du processeur Cell. 
\section{Exploitation du Parallélisme et Optimisations Multi-niveau}
Les techniques d'optimisation démontrées ici sont multiples et variées. Certaines sont de nature algorithmique et relèvent plutôt du domaine du traitement du signal et des images. D'autres techniques génériques relèvent plutôt du domaine de l'optimisation logicielle est qu'on retrouve par fois dans certains compilateurs optimisants. Les techniques précédentes sont générales et peuvent être appliqués à la majorité des processeurs généralistes car elle ne tiennent pas compte des aspects spécifiques d'une architecture donnée. Par contre, des optimisations de plus haut niveau et qui sont spécifiques à l'architecture particulière du Cell ont aussi été employées. Celles-ci ne sont généralement pas reproductibles sur d'autres architectures parallèles car elle relèvent plus d'une adéquation entre l'algorithme et l'architecture qui contient certains dispositifs qui n'existent que sur le Cell et des fois elles résultent de contraintes de programmation spécifiques au Cell comme la taille limitée des mémoire locale des SPEs et par conséquent la gestion logicielle de l'utilisation de la mémoire.
\subsection{Techniques Spécifiques au Domaine}
Ces optimisations relèvent plutôt du domaine du traitement du signal et des images. Elles peuvent donc être appliquées à plusieurs algorithmes et sur n'importe quelle architecture. Celles que nous avons utilisé concernent les noyaux de convolution et sont : la séparabilité, le chevauchement (overlapping) et la factorisation des calculs.
\subsubsection{Séparabilité des Noyaux}
\begin{figure}[!htb]
	\centering
	\includegraphics[width= \columnwidth]{Chapter2/figures/convolution_sep}
	\caption{Exemple de convolution par un filtre Gaussien $3\times3$ (a)version avec noyaux 2D (b) version avec deux noyaux 1D , résultant de la séparation du noyau 2D.}
	\label{fig_convosep}
\end{figure}
Cette optimisation consiste à exploiter le fait que les noyaux de convolution 2D de \emph{Sobel} \emph{Gauss} soient séparables en deux filtre de convolution 1D (Fig. \ref{fig_convosep}). Ainsi, la matrice des coefficients peut être exprimée comme un produit de deux vecteur comme l'illustre les équations suivantes :
\begin{eqnarray*}
Grad_{X} =  \frac{1}{  8} \begin{bmatrix} -1 &  0 &   1  \\ -2 & 0 & 2 \\ -1 & 0 & 1 \end{bmatrix} =    \frac{1}{8} \begin{bmatrix} -1 \\ 0 \\ 1 \end{bmatrix} \times  \begin{bmatrix} 1 & 2 & 1 \end{bmatrix};
Grad_{Y} =  \frac{1}{  8} \begin{bmatrix} -1 & -2 & -1   \\  0 & 0 & 0 \\  1 & 2 & 1 \end{bmatrix}  =   \frac{1}{8} \begin{bmatrix} 1 \\ 2 \\ 1 \end{bmatrix} \times  \begin{bmatrix} -1 & 0 & 1 \end{bmatrix}\\
Gauss      =  \frac{1}{16} \begin{bmatrix}  1 &  2 &   1  \\  2 & 4 & 2 \\  1 & 2 & 1 \end{bmatrix} = \frac{1}{16}\begin{bmatrix}1 \\ 2 \\ 1 \end{bmatrix} \times \begin{bmatrix}1  & 2 & 1 \end{bmatrix}
\end{eqnarray*}
Lorsqu'on sépare les noyaux de convolutions le calcul se fait en deux passes une pour chaque vecteur. Grâce à la séparabilité des noyaux on arrive à réduire le nombre d'instructions mémoire ainsi que la complexité arithmétique. La comparaison est illustrée dans les tableaux \ref{tab_sepa_arith} et \ref{tab_sepa_mem}.
\begin{table}
\centering
\begin{tabular}{|c|c|c||c|c|c|c|}
\multicolumn{7}{c}{\textbf{Complexité arithmétique filtre de \emph{Sobel}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau}} & \emph{Gain \%}\\
\hline
\textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total}& \textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total}  & \multirow{2}{*}{\textbf{75}}\\
\cline{1-6}
 2  & 5 & 7  & 1  & 3 & 4  & \\
\hline
\multicolumn{7}{c}{\textbf{Complexité arithmétique filtre de \emph{Gauss}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau}}  & \emph{Gain \%} \\
\hline
\textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total}& \textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total} &   \multirow{2}{*}{\textbf{116}} \\
\cline{1-6}
 8  & 5 & 13  & 2  & 4 & 6  &  \\
\hline
\end{tabular}
\label{tab_sepa_arith}
\caption{Réduction de la complexité arithmétique par séparabilité des noyaux}
\end{table}

\begin{table}
\centering
\begin{tabular}{|c|c|c||c|c|c|c|}
\multicolumn{7}{c}{\textbf{Complexité mémoire filtre de \emph{Sobel}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau}} & \emph{Gain \%}\\
\hline
\textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}& \textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}  & \multirow{2}{*}{\textbf{0}}\\
\cline{1-6}
 6  & 1 & 7  & 1  & 5 & 2  & \\
\hline
\multicolumn{7}{c}{\textbf{Complexité mémoire filtre de \emph{Gauss}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau}}  & \emph{Gain \%} \\
\hline
\textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}& \textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total} &   \multirow{2}{*}{\textbf{25}} \\
\cline{1-6}
 9  & 1 & 10  & 6  & 1 & 8  &  \\
\hline
\end{tabular}
\label{tab_sepa_mem}
\caption{Réduction de la complexité mémoire par séparabilité des noyaux}
\end{table}

\subsubsection{Chevauchement des Noyaux}
\begin{figure}[!htb]
	\centering
	\includegraphics[width= \columnwidth]{Chapter2/figures/convolution_overlap}
	\caption{Chevauchement des données pour un calcul d'un filtre Gaussien $3\times3$, certaines données sont conservées en décalant le masque de convolution.}
	\label{fig_convoover}
\end{figure}
La deuxième particularité des noyaux de convolution est une notion de chevauchement qui permet d'avoir une redondance d'une partie des données (Fig. \ref{fig_convoover}). En effet, comme le démontre la figure \ref{fig_ovelapping}, à chaque itération du calcul de la convolution il n'y a qu'une seule nouvelle colonne chargée. Les colonnes redondantes sont copiées dans les registres en les décalant d'un pas à droite par rapport à leur position précédente (\emph{rotation de registres}). On notera que le même type d'optimisation peut se faire grâce à un \emph{déroulage de boucle}.
\begin{table}
\centering
\begin{tabular}{|c|c|c||c|c|c|c|}
\multicolumn{7}{c}{\textbf{Complexité mémoire filtre de \emph{Sobel}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans chevauchement du noyau}} & \multicolumn{3}{|c|}{\emph{Avec chevauchement du noyau}} & \emph{Gain \%}\\
\hline
\textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}& \textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}  & \multirow{2}{*}{\textbf{133}}\\
\cline{1-6}
 6  & 1 & 7  & 2  & 1 & 3  & \\
\hline
\multicolumn{7}{c}{\textbf{Complexité mémoire filtre de \emph{Gauss}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans chevauchement du noyau}} & \multicolumn{3}{|c|}{\emph{Avec chevauchement du noyau}}  & \emph{Gain \%} \\
\hline
\textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}& \textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total} &   \multirow{2}{*}{\textbf{150}} \\
\cline{1-6}
 9  & 1 & 10  & 3  & 1 & 4  &  \\
\hline
\end{tabular}
\label{tab_over_mem}
\caption{Réduction de la complexité mémoire par chevauchement des noyaux}
\end{table}
\subsubsection{Séparation des noyaux et chevauchement}
Cette optimisation n'est en fait qu'une combinaison des deux précédentes. En effet on profite d'une part du fait que les noyaux soient séparables pour réduire la complexité arithmétique, et d'autre part du chevauchement des noyaux pour mémoriser le résultat précédent. Ainsi, au lieu de mémoriser les deux dernières colonnes, on mémorise le résultat du filtrage par le premier filtre 1D pour le réutiliser à l'itération suivante de la boucle. Dans ce cas là; la compléxité arithmétique est la même que celle de la version avec séparation des noyaux, alors que la complexité mémoire est réduite d'avantage.
Les tableau \ref{tab_sepaover_arith} et \ref{tab_sepaover_mem} donnent la différence en terme de complexité arithmétique et mémoire entre la version de base de l'algorithme est la version tenant compte des deux optimisations combinées.
\begin{table}
\centering
\begin{tabular}{|c|c|c||c|c|c|c|}
\multicolumn{7}{c}{\textbf{Complexité arithmétique filtre de \emph{Sobel}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau + chevauchement}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau + chevauchement}} & \emph{Gain \%}\\
\hline
\textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total}& \textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total}  & \multirow{2}{*}{\textbf{75}}\\
\cline{1-6}
 2  & 5 & 7  & 1  & 3 & 4  & \\
\hline
\multicolumn{7}{c}{\textbf{Complexité arithmétique filtre de \emph{Gauss}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau + chevauchement}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau + chevauchement}}  & \emph{Gain \%} \\
\hline
\textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total}& \textbf{\texttt{MUL}} & \textbf{\texttt{ADD}} & \textbf{Total} &   \multirow{2}{*}{\textbf{116}} \\
\cline{1-6}
 8  & 5 & 13  & 2  & 4 & 6  &  \\
\hline
\end{tabular}
\label{tab_sepaover_arith}
\caption{Réduction de la complexité arithmétique par séparabilité et chevauchement des noyaux}
\end{table}

\begin{table}
\centering
\begin{tabular}{|c|c|c||c|c|c|c|}
\multicolumn{7}{c}{\textbf{Complexité mémoire filtre de \emph{Sobel}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau + chevauchement}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau + chevauchement }} & \emph{Gain \%}\\
\hline
\textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}& \textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}  & \multirow{2}{*}{\textbf{250}}\\
\cline{1-6}
 6  & 1 & 7  & 1  & 1 & 2  & \\
\hline
\multicolumn{7}{c}{\textbf{Complexité mémoire filtre de \emph{Gauss}}}\\
\hline
\multicolumn{3}{|c||}{\emph{Sans séparation du noyau + chevauchement}} & \multicolumn{3}{|c|}{\emph{Avec séparation du noyau + chevauchement }}  & \emph{Gain \%} \\
\hline
\textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total}& \textbf{\texttt{LOAD}} & \textbf{\texttt{STORE}} & \textbf{Total} &   \multirow{2}{*}{\textbf{400}} \\
\cline{1-6}
 9  & 1 & 10  & 1  & 1 & 2  &  \\
\hline
\end{tabular}
\label{tab_sepaover_mem}
\caption{Réduction de la complexité mémoire par séparabilité et chevauchement des noyaux}
\end{table}
\subsubsection{Composition de Fonctions}
\label{sectioncompo}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= \columnwidth]{Chapter2/figures/funccompo}
  	\label{fig_compo}
	\caption{Règle de composition de fonctions.\textbf{(a)} composition de deux opérateurs point à point \textbf{(b)} composition d'un noyaux de convolution suivi d'un opérateur point à point \textbf{(c)} composition d'un opérateur point à point  suivi d'un noyaux de convolution \textbf{(d)} composition de deux noyaux de convolution successifs}
\end{figure}

Cette technique d'optimisation s'avère très efficace surtout dans les codes ou les instructions mémoire sont prépondérantes. En effet, le fait de composer deux fonctions de calcul pour en faire une seule qui effectue les deux calculs réduit considérablement le nombre d'accès mémoire puisque les opérations de sauvegarde et de chargement intermédiaires entre les deux fonctions initiales sont supprimées, et la transaction se fait au niveaux des registres. De plus, le coût de l'appel de fonction (taille de la pile, et branchement) est également réduit, car le résultat de la composition de fonctions et une seule fonction. Dans les cas les plus simples, la mise en oeuvre de cette technique n'est pas difficile. Toutefois, lorsqu'il s'agit d'opérateurs de convolution comme dans notre cas, des nouvelles contraintes apparaissent afin de garantir la validité du résultat du calcul. Ainsi, des règles de composition s'imposent en fonction de l'ordre dans lequel s'enchaînent les fonctions. Ces règles sont illustrées sur la figure \ref{fig_compo}. On peut alors constater qu'il existe plusieurs règles de composition des fonctions selon d'une part : la nature des opérateurs mis en jeu et d'autre part l'ordre dans lequel il s'enchaînent. En terme d'apport de cette technique en terme de performances nous observons deux aspects distincts:
\begin{itemize}
\item \textbf{Complexité mémoire} : on observe en effet que ceux ci sont systématiquement réduits, car les opérations de \texttt{LOAD/STORE} intermédiaires sont supprimés, sauf dans le cas de la composition de deux noyaux de convolution (cas \textbf{(d)} sur la figure \ref{fig_compo})ou la présence de bords supplémentaires augmente considérablement le nombre des accès mémoire.
\item \textbf{Complexité arithmétique} : Cele-ci ne change pas dans le meilleurs des cas notamment lorsque les opérateurs composées sont point à point ou alors lorsque l'opérateur de convolution est placé devant un opérateur point à point (cas \textbf{(b)} sur la figure \ref{fig_compo}). Toutefois, si la convolution est placée à la suite d'un quelconque traitement, elle impose que l'opérateur qui la précède soit effectué sur tous les pixels de voisinage, ce qui augmente considérablement la complexité arithmétique, en particulier lorsque l'opérateur qui précède est une convolution (cas \textbf{(d)} sur la figure \ref{fig_compo}).
\end{itemize}
D'après les observations ci-dessus, la composition de fonction peut être un bon choix pour l'optimisation d'une chaîne de traitement telle que l'algorithme de detection de point d'intérêts de Harris. Toutefois, toutes les combinaisons n'apportent pas forcément une amélioration des performances, elle peuvent même dans certains cas les dégrader. Le tableau \ref{tab_memall} résume les complexité mémoire et arithmétiques des différents cas de composition sur la figure \ref{fig_compo} en incluant également les optimisations décrites auparavant.
\begin{table}
\centering
\begin{tabular}{|c||c|c|c|c|}
\hline
\multicolumn{5}{|c|}{\textbf{Version de base sans composition}}\\
\hline
\textbf{Opérateur} & \textbf{Occurrences} & \textbf{\texttt{LOADS}} & \textbf{\texttt{STORE}} & \textbf{Total}\\
\hline
\emph{Sobel} & 2 & 6 & 1 & 14\\
\hline
\emph{Mul} & 3 & 2 & 1 & 9\\
\hline
\emph{Gauss} & 3 & 9 & 1 & 30\\
\hline
\emph{Coarsity} & 1 & 3 & 1 & 4\\
\hline
\emph{Harris} & 1 & 48 & 9 & 57\\
\hline
\multicolumn{5}{|c|}{\textbf{Version avec chevauchement et séparation des noyaux sans composition}}\\
\hline
\textbf{Opérateur} & \textbf{Occurrences} & \textbf{\texttt{LOADS}} & \textbf{\texttt{STORE}} & \textbf{Total}\\
\hline
\emph{Sobel} & 1 & 3 & 2 & 5\\
\hline
\emph{Mul} & 3 & 2 & 1 & 6\\
\hline
\emph{Gauss} & 3 & 3 & 1 & 12\\
\hline
\emph{Coarsity} & 1 & 3 & 1 & 4\\
\hline
\emph{Harris} & 1 & 21 & 9 & 30\\
\hline
\multicolumn{5}{|c|}{\textbf{Version avec composition de Sobel$\circ$Mul et Gauss$\circ$Coarsity}}\\
\hline
\textbf{Opérateur} & \textbf{Occurrences} & \textbf{\texttt{LOADS}} & \textbf{\texttt{STORE}} & \textbf{Total}\\
\hline
\emph{Sobel$\circ$Mul} & 1 & 9 & 3 & 12\\
\hline
\emph{Gauss$\circ$Coarsity} & 3 & 9 & 1 & 28\\
\hline
\emph{Harris} & 1 & 36 & 4 & 40\\
\hline
\multicolumn{5}{|c|}{\textbf{Version avec chevauchement et séparation + composition de Sobel$\circ$Mul et Gauss$\circ$Coarsity}}\\
\hline
\textbf{Opérateur} & \textbf{Occurrences} & \textbf{\texttt{LOADS}} & \textbf{\texttt{STORE}} & \textbf{Total}\\
\hline
\emph{Sobel$\circ$Mul} & 1 & 3 & 3 & 6\\
\hline
\emph{Gauss$\circ$Coarsity} & 3 & 3 & 1 & 10\\
\hline
\emph{Harris} & 1 & 12 & 4 & 16\\
\hline
\multicolumn{5}{|c|}{\textbf{Version avec composition de Sobel$\circ$Mul$\circ$Gauss$\circ$Coarsity}}\\
\hline
\textbf{Opérateur} & \textbf{Occurrences} & \textbf{\texttt{LOADS}} & \textbf{\texttt{STORE}} & \textbf{Total}\\
\hline
\emph{Sobel$\circ$Mul$\circ$Gauss$\circ$Coarsity} & 1 & 25 & 1 & 26\\
\hline
\emph{Harris} & - & - & - & 26\\
\hline
\multicolumn{5}{|c|}{\textbf{Version avec chevauchement et séparation + composition de Sobel$\circ$Mul$\circ$Gauss$\circ$Coarsity}}\\
\hline
\textbf{Opérateur} & \textbf{Occurrences} & \textbf{\texttt{LOADS}} & \textbf{\texttt{STORE}} & \textbf{Total}\\
\hline
\emph{Sobel$\circ$Mul$\circ$Gauss$\circ$Coarsity} & 1 & 5 & 1 & 6\\
\hline
\emph{Harris} & - & - & - & 6\\
\hline
\end{tabular}
\label{tab_memall}
\caption{Tableau récapitulatif de l'optimisation des accès mémoire en combinant l'ensemble des optimisations}
\end{table}
\subsection{Optimisation des Transferts Mémoire}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= \columnwidth]{Chapter2/figures/cellnoc}
  \label{fignoc}
	\caption{Réseau d'interconnection du Cell}
\end{figure}
Dans cette partie, nous abordons des techniques d'optimisations qui sont relatives au transferts de données présents dans l'application. On entend, par transfert de donnée, toute communication qui met en jeu deux mémoires physiques sur Cell. Cela comporte les transferts DMA entre la mémoire principale, et les mémoires locales des SPEs, comme les communications mettant en jeu deux mémoires privées de SPEs. Plusieurs aspects sont mis en avant. D'une part, les caractéristiques internes de l'architecture du réseaux de communications \cite{cellnoc} (\emph{Network On Chip (NoC)}) du Cell et d'autres part la nature des transferts de données imposées par l'algorithme et d'autre part la partition des données à plusieurs niveaux de la hiérarchie mémoire.
\subsubsection{Optimisation de la Bande-Passante du \emph{NoC}}
Dans le modèle de programmation utilisé qui est basé sur le \emph{SDK} du Cell et les librairies \emph{libspe}, les données présentes en mémoire centrale sont transférées au mémoires locales des SPEs avant d'être traitées. Ces transferts se font d'une manière explicite dans le logiciel par appel à des fonctions de l'API de gestion du \emph{MFC} et ils sont gérées par le \emph{Noc} au travers de contrôleurs mémoire et de l'arbitre de bus. L'architecture du Bus et la topologie du réseau impose quelques contraintes qui jouent un rôle primordial dans la minimisation des latences des communications point à point.
\paragraph{Taille du Transfert}
\begin{figure}[htb]
  \centering
  \includegraphics[width= 0.8\columnwidth]{Chapter2/figures/bwsize}
  \label{figbwsize}
  \caption{Influence de la taille du transfert DMA sur la bande-passante}
\end{figure}
%\begin{figure}[!htb]
%	\centering
%  \includegraphics[width= 0.8\columnwidth]{Chapter2/figures/grapheBW}
%  \label{graphbw}
%	\caption{Bande-passante cumulée }
%\end{figure}

Le premier paramètre influant sur la bande passante est la taille du bloc de données transféré. D'une part, il y a des contraintes imposées par l'API de transfert qui limitent les tailles d'un bloc transféré par une commande DMA à 1, 2, 4, 8 octets ou tout multiple de 16 \emph{bytes} et la taille de données maximale transférée en une seule commande est de 16 \emph{KB}. Des plus les adresses doivent obligatoirement être alignées sur 16 \emph{bytes} et un alignement sur 128 \emph{bytes} est préférable à cause de la taille de la ligne de cache sur la mémoire locale du SPE qui est de 128 \emph{bytes}. D'autre part l'espace mémoire disponible sur les SPEs pour stocker données et instructions est limité à 256 KB. Toutes ces contraintes, imposent une attention des contraintes fortes en termes de taille de bloc transféré et d'alignement des données qui en sont pas du ressort du développeur dans les architectures à mémoire partagée. Plusieurs \emph{benchmarks} ont été effectués dans \cite{cellnoc} et \cite{cell_bw02} et qui démontrent la relation entre taille et à la fois le débit et la latence des transferts sur le Cell. Le graphe \ref{graphbw} donne les résultats sur un benchmark de bande-passante que nous avons effectué sur une BladeCenter QS20 et démontrent que celle ci est proportionnelle à la taille des données transférées. Ceci s'explique par le fait que la \emph{latence} du transfert qui représente le temps d'initialisation d'un transfert, cette durée étant la même quelque soit la taille du paquet jusqu'à 16 KB.
\paragraph{Nombre de Transferts Concurrents}
\begin{figure}[htb]
  \centering
  \includegraphics[width= 0.8\columnwidth]{Chapter2/figures/bwcontention}
  \label{figbwncontention}
  \caption{Influence du nombre de transferts dans le cas d'une communication LS<->LS}
\end{figure}

\begin{figure}[htb]
  \centering
  \includegraphics[width= 0.8\columnwidth]{Chapter2/figures/bwnspes}
  \label{figbwnspes}
  \caption{Influence du nombre de transferts dans le cas d'une communication MS<->LS}
\end{figure}

Les second facteur qui influe sur l'efficacité du réseau lors des transferts est le nombre de transferts s'exécutante en parallèle. En effet, l'architecture du réseau dont la topologie est tu type \emph{token ring} contient quatre anneaux d'une largeur de 128-bit : deux dans le sens d'une aiguille d'une montre et les deux autres dans le sens contraire. En observant la topologie du réseau ainsi que le sens de circulation des données sur les anneaux du bus, il s'avère évident qu'il peut y avoir collision entre deux transferts s'exécutant de manière concurrente (\ref{fignoc}). Sachant qu'un anneau peut gérer 3 transferts concurrents tant que ceux-ci n'entrent pas en collision. Ce risque est d'autant plus important si le nombre de transferts concurrents augmente (au-delà de 12). Lorsqu'un tel conflit est détecté l'arbitre de bus le résout avant un surcoût qui divise globalement la bande-passante par deux. La courbe sur le figure \ref{figbwncontention} permet de constater l'influence du nombre de transferts concurrents, on peut ainsi observer que la courbe perd sa linéarité quand au delà de 4 SPEs et ceci car le nombre de transferts devient trop important pour ne pas provoquer de collisions sur le bus.\\
\indent Dans le cas d'une communication du PPE vers le SPE, la bande passante maximale qui peut être atteinte est de 25.6 GB/s. Dans le cas où plusieurs SPEs font une requête vers la mémoire principale les transferts ne peuvent être que sérialisés car il existe q'une seule liaison vers le MS (\emph{Main Storage}). On observe alors que le graphique de la figure \ref{bwnspes} que la bande passante n'est atteinte que lorsqu'au moins 4 SPEs font un transfert de la mémoire centrale vers leurs mémoires privée. 

\subsubsection{Optimisation de la localité temporelle par chaînage des opérateurs}
Le but visé par cette technique est de rapprocher le plus possible les données des unités de traitement. En effet, les coûts liés au transfert des données de la mémoire centrale vers les mémoires locales étant important, il est pertinent de garder les données en mémoire locale après chaque traitement au lieu de multiplier les lectures/écritures vers la mémoire centrale. Les règles de chaînage des opérateurs au niveaux des accès mémoires, sont les mêmes que pour la composition des opérateurs citée dans la section \ref{sectioncompo}. Cette optimisation apporte beaucoup à la performance globale car l'application est caractérisée par un ratio transfert/calcul important et la différence de bande-passante entre l'accès en mémoire locale et l'accès à une mémoire distante par DMA est d'un facteur dix \cite{cell_bw02}.

\subsubsection{Optimisation du \emph{Tiling} des données}
Le \emph{loop tiling} \cite{wolfetiling}ou \emph{loop blocking} est une technique d'optimisation très utilisée que cela soit par les programmeurs ou par les compilateurs optimisants. Cette technique consiste en un découpage des données à différents niveaux de la hiérarchie mémoire de telle sorte à ce que la latence d'accès soit la plus petite possible. Dans une architecture mémoire partagée contenant des caches, ceci revient à un découpage qui garantit que les données utilisées par un traitement donné tiennent toujours dans le cache. Ainsi, le temps d'accès au données est de l'ordre du cycle et les défauts de cache (\emph{cache misses}) sont quasi inexistant quelque soit la taille des données.\\
\indent Au vu de la nature de la hiérarchie mémoire du processeur Cell, le \emph{tiling} est une obligation. D'une part, il n'existe pas de mémoire cache pour gérer les mémoires privée des SPEs, le découpage des données est une tâche confiée au programmeur. D'autre part l'espace de stockage étant limité dans les \emph{local store} (256 KB), le découpage des données en tuiles pouvant tenir dans le cache est obligatoire. L'unité de données atomique devient alors la tuile qui représente le morceau de donné le plus petit qui va être traitée par le code du SPE.
\paragraph{Taille de la Tuile}
La taille de la tuile est un paramètre primordial lorsqu'il s'agit de découper les données de manière optimale. Dans le cas du processeur Cell, les contraintes imposées par l'architecture font que le choix de la taille optimale est restreint. En effet, la taille limitée du \emph{local store} pour le code source et les données, impose que la taille de la tuile ne dépasse pas la capacité de stockage qui est de 256 KB. L'autre paramètre dont on doit tenir compte est le nombre d'entrée et de sorties des fonctions de traitement car celui-ci donne le nombre de tuiles. On peut en déduire globalement, que la taille de la tuile est égale à la capacité de stockage restante pour les données, divisée par le nombre de tuiles en entrée et en sortie de la chaîne de traitement mise en jeu. D'autre part, selon ce qui a été vu precedemment, la taille de transfert qui garantit une bande-passante maximale sur le bus est de 16 KB ou un multiple de cette taille.
\paragraph{Dimensions de la Tuile}
\begin{figure}[htb]
  \centering
  \includegraphics[width=\columnwidth]{Chapter2/figures/qreloads}
  \label{qreloads}
  \caption{Redondances de données pour un opérateur de convolution $3 \times 3$}
\end{figure}
Les tuile que l'on traite dans notre cas sont en général d'une forme rectangulaire. Toutefois, à cause de la présence d'opérateurs de convolution, un nouvel aspect doit être considéré qui sont les dimensions hauteur et largeur de la tuile ($h$ et $w$). En effet, dans le cas d'opérateurs de convolution les bords qui représentent les voisinage des pixels traités augmentent la quantité de données transférées de la mémoire. Cette quantité peut être réduite avec un choix judicieux des dimensions de la Tuile. Comme le montre la figure \ref{qreloads}certains des pixels sont rechargés, nous démontrons dans la suite l'influence des dimensions de la tuile sur ce nombre de pixels redondants.\\
\indent Si l'on considère une image de hauteur $H$ et de largeur de $W$, une tuile de dimensions $h$ et $w$ et un opérateur de convolution nécessitant un voisinage pour chaque pixel. On suppose pour simplifier le calcul, que la matrice de convolutions est carrée, ce qui fait que les bords des deux côtés sont égaux. La quantité totale de pixels transférées pour le traitement est alors :
\begin{equation}
Q = (h+2b)\times(w+2b)\times nb_{tiles}\nonumber
\end{equation}
où $nb_{tiles}$ est le nombres de tuiles dans l'image.
\begin{equation}
nb_{tiles} = \frac{H \times W}{h \times w} \nonumber
\end{equation}
Le but étant de trouver à taille de tuile constante $h\times w$ quels sont les dimensions $h$ et $w$ qui minimisent $Q$
\begin{equation}
Q = (h+2b)\times(w+2b)\times\frac{H \times W}{h \times w} \nonumber
\end{equation}

Posons alors $\lambda = h \times w = C^{te}$, la fonction à minimiser devient alors :
\begin{equation}
Q = (h+2b)\times(w+2b)\times\frac{H \times W}{\lambda} \nonumber
\end{equation}
Calculons alors les dérivées  : \begin{equation}\frac{\partial Q}{\partial h} \mbox{ et } \frac{\partial Q}{\partial w} \nonumber\end{equation}

\begin{equation} Q = \frac{H \times W}{\lambda} (h+2b) \times (\frac{\lambda}{h}+2b) \mbox{  et symétriquement  } Q = \frac{H \times W}{\lambda} (w+2b) \times (\frac{\lambda}{w}+2b) \nonumber\end{equation}

\begin{equation}
%$\frac{\partial Q}{\partial h} = \frac{H \times W \times 2b}{\lambda \times h^{2}}(h^{2}-\lambda)$
\frac{\partial Q}{\partial h} = \frac{H \times W \times 2b}{\lambda \times h^{2}}(h^{2}-\lambda) \nonumber \\
\end{equation}
\begin{equation}
\frac{\partial Q}{\partial w} = \frac{H \times W \times 2b}{\lambda \times w^{2}}(w^{2}-\lambda) \nonumber
\end{equation}
Le minimum de la fonction $Q$ est atteint lorsque : \begin{equation}\frac{\partial Q}{\partial h} = 0 \mbox{ et } \frac{\partial Q}{\partial w}  = 0\nonumber\end{equation}

ce qui donne \begin{equation}h = w = \sqrt{\lambda} \nonumber \end{equation}
Ce qui permet de déduire que la forme de la tuile qui minimise la quantité de données transférée et une forme carrée.\\
\indent Ce résultat nous a permis de démontrer que la forme de la tuile avait une influence sur la quantité de données transférées et par conséquent sur la performance globale de l'application. Cependant, ce découpage n'est pas forcément optimal lorsqu'on passe à l'implémentation. En effet, des tuiles de formes carrées signifies des accès à des zones non-contigues de la mémoire. Ce type d'accès est en général coûteux car il provoque des sauts dans la mémoire. De plus, sur le processeur Cell, ceci se traduit en commandes DMA sur des zones non-contigues de la mémoire ce qui nécessitent des commandes du type \emph{DMA list}. Ces dernières requièrent la création d'une liste qui contient chaque DMA élémentaire et qui est d'autant plus grande que le nombre de transferts est important. Cette liste doit également être mise à jour lors de chaque nouveau transfert. Toutes ces contraintes nous ont poussé dans un premier temps d'adopter un découpage en bandes qui consiste à ce que les tuiles aient une largeur égale à celle de l'image. Ceci permet des accès uniquement à des zones contigues de la mémoire et les transferts peuvent se faire avec une seule commande DMA. De plus, lorsqu'une tuile ne contient pas de bords latéraux comme dans notre cas, les problème d'alignement des transferts est également contourné. Par contre, ce choix induit des limitations en terme de taille d'image pouvant être traitée. En effet, sachant que la taille de la tuile est limitée et que sa largeur est égale celle de l'image, la hauteur de la tuile elle, diminue au fur et à mesure que la largeur de l'image augmente. De ce fait, les accès non-contigus sont nécessaires pour des taille d'images très grandes.
\subsection{Schémas de Parallélisation}
Dans ce qui suit, nous abordons l'optimisation de notre algorithme à un niveau d'abstraction plus haut qui est celui des tâches. L'architecture du Cell permet plusieurs placements possibles du graphe d'opérateurs par la présence de 8 SPEs et la possibilité de mettre en place différents schémas de communication. Dans les figures qui suivent les opérateurs sont représentés par des cercles, les processeurs par des rectangles à coins arrondis, les tuiles sont de forme rectangulaire et peuvent contenir des bords. Les flèches à trait fin représentent des instruction \texttt{LOAD/STORE} dans la mémoire privée du SPE alors que les flèches plus épaisses représentent des commandes DMA inter-SPE ou alors entre la mémoire centrale et le \emph{local store} d'un SPE.
\subsubsection{SPMD Conventionnel}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= \columnwidth]{Chapter2/figures/harris-spmd}
  \label{harris-spmd}
	\caption{Schéma de Parallélisation SPMD Conventionnel}
\end{figure}
Dans ce schéma de déploiement l'image est divisée en 8 regions de même taille, afin que chacun des 8 SPEs ait une charge de calcul équivalente. Tous les SPEs exécutent le même code. Les opérateurs sont exécutés successivement sur l'image entière l'un après l'autre. A titre d'exemple l'opérateur de multiplication n'est exécuté que lorsque le calcul du filtre de \emph{Sobel} est achevé sur toute l'image. Ce modèle de calcul est dit \emph{data-parallel} car les données sont envoyées en parallèle sur les SPEs et traitées de manière complètement indépendantes les unes des autres. Toutefois, la bande passante sur le bus mémoire centrale vers \emph{locale store} est beaucoup sollicitées car les données sont systématiquement lues et écrites avant et après chaque opérateur.
\subsubsection{Pipeline Conventionnel}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= \columnwidth]{Chapter2/figures/harris-pipeline}
	\caption{Schéma de Parallélisation Pipeline}
	\label{harris-pipeline}
\end{figure}
Cette implémentation de l'algorithme consiste à déployer le graphe d'opérateur sous forme de pipeline. L'image n'est pas subdivisée en régions de traitement mais chaque tuile traitée traverse le pipeline avant qu'une nouvelle tuile ne puisse l'être. L'algorithme est par conséquent fortement séquentialisé. Par contre la bande-passante inter-SPEs est bien exploitée car la majorité des transferts se font entre SPEs et par conséquent la pression exercée sur le bus précédemment est atténuée car elle est répartie sur l'ensemble de l'anneau.
\subsubsection{Chaînage d'opérateur par paires}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= \columnwidth]{Chapter2/figures/harris-hchain}
	\caption{Schéma de Parallélisation Chaînage d'opérateurs par paires}
	\label{harris-pipeline}
\end{figure}
Dans cette version deux opérateurs successifs sont placés sur le même SPE. Ainsi, les opérateur \emph{Sobel} et \emph{Mul} sont placé sur un même SPE et \emph{Gauss} et \emph{Coarsity} sont placés sur un autre SPE. Le nombre de SPEs dans un processeur Cell étant de 8, ce schéma permet d'avoir 4 regions de l'image traitées en parallèle. Si l'on compare cette version à la précédente, on notera que la pression sur le bus d'interconnexion est plus importantes car les transferts concurrents sont plus nombreux et par conséquent le risque de contention du bus est plus probable.
\subsubsection{Chaînage et fusion d'opérateur par paires}
\begin{figure}[!htb]
	\centering
  \includegraphics[width= 0.6\columnwidth]{Chapter2/figures/harris-hchainhpipe}
	\caption{Schéma de Parallélisation Chaînage et fusion d'opérateurs par paires}
	\label{harris-pipeline}
\end{figure}
Cette version est une variante de celle qui la précède. L'idée étant de fusionner les opérateurs présent sur un même SPE, et ce afin d'éliminer les instructions de \texttt{LOAD} et \texttt{STORE} présent à la sortie de du premier et à l'entrée du second. De ce fait, le nombre de cycles peut être considérablement réduit, surtout lorsque l'on sait que la latence des instructions mémoire est de 6 cycles sur les SPE \cite{cell_handbook}.
\subsubsection{Chaînage entier et fusion d'opérateur par paires}
\begin{figure}[htb]
	\centering
  \includegraphics[width= 0.6\columnwidth]{Chapter2/figures/harris-hchainfpipe}
	\caption{Schéma de Parallélisation Chaînage et fusion d'opérateurs par paires}
	\label{harris-pipeline}
\end{figure}
Dans cette implémentation tous les opérateurs sont exécutés sur le même SPE. D'une part ceci permet d'éviter les transferts DMA entre SPE et minimise donc les transactions sur le bus d'interconnexion.
\subsection{Evaluation des Performances}
après avoir exposé les différentes techniques d'optimisations nous procédons à la mesure de performance pour les différents modèles de déploiement précédents. Il s'agit ici de comparer les modèles en terme de temps d'exécution sur le processeur Cell. Dans un deuxième temps nous évaluons l'influence des transferts sur la performance globale de chacun des modèles.
\subsubsection{Métriques de Mesure}
La métrique que nous avons choisi d'utiliser pour la mesure de performance, est le nombre de cycles moyen par pixel ou $cpp$, \begin{equation}cpp = \frac{nombre_{cyles \mbox{ } cpu}}{nombre_{pixels}} = \frac{nombre_{cyles \mbox{ } cpu}}{H \times W} \nonumber\end{equation}. Les bancs de tests ont été conçus de telle sorte à mesurer d'une part la performance brute ainsi que d'autres métriques spécifiques aux architectures qui sont les métriques de passage à l'échelle \emph{scalability} et qui sont l'accélération
\emph{speedup} et l'efficacité \emph{efficiency}.
\subsubsection{Comparaison des Schémas de Parallélisation}
\begin{figure}[htb]
	\centering
  \includegraphics[width= 0.9\columnwidth]{Chapter2/figures/BenchCompareModels}
	\caption{Comparaison des Modèles}
	\label{comparemodels}
\end{figure}

Fig. 12 gives the comparison between the dierent implementation models of the Harris algorithm
on the Cell processor. The rst observation that can be made is that the conventional pipeline
version gives the worst performances, which was expected: this version is deliberately serialized
and does not fully exploit the TLP (Thread Level Parallelism) oered by the target architecture.
The other observations match our expectations:
{ Our memory optimization techniques improve global performances as the fastest implemen-
tation is the Half pipeline+Full chaining version where operators are pipelined and chained
inside an SPE.